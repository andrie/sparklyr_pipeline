17/12/14 12:00:25 INFO SparkContext: Running Spark version 2.1.0
17/12/14 12:00:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/14 12:00:25 INFO SecurityManager: Changing view acls to: edgar
17/12/14 12:00:25 INFO SecurityManager: Changing modify acls to: edgar
17/12/14 12:00:25 INFO SecurityManager: Changing view acls groups to: 
17/12/14 12:00:25 INFO SecurityManager: Changing modify acls groups to: 
17/12/14 12:00:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(edgar); groups with view permissions: Set(); users  with modify permissions: Set(edgar); groups with modify permissions: Set()
17/12/14 12:00:26 INFO Utils: Successfully started service 'sparkDriver' on port 54530.
17/12/14 12:00:26 INFO SparkEnv: Registering MapOutputTracker
17/12/14 12:00:26 INFO SparkEnv: Registering BlockManagerMaster
17/12/14 12:00:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/14 12:00:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/14 12:00:26 INFO DiskBlockManager: Created local directory at C:\Users\edgar\AppData\Local\Temp\blockmgr-4b5a4834-4fde-4069-aea6-ccd632979728
17/12/14 12:00:26 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/12/14 12:00:26 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/14 12:00:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/14 12:00:26 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/14 12:00:26 INFO SparkContext: Added JAR file:/C:/Users/edgar/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:54530/jars/sparklyr-2.1-2.11.jar with timestamp 1513274426457
17/12/14 12:00:26 INFO Executor: Starting executor ID driver on host localhost
17/12/14 12:00:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54571.
17/12/14 12:00:26 INFO NettyBlockTransferService: Server created on 127.0.0.1:54571
17/12/14 12:00:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/14 12:00:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54571, None)
17/12/14 12:00:26 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54571 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54571, None)
17/12/14 12:00:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54571, None)
17/12/14 12:00:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54571, None)
17/12/14 12:00:26 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/14 12:00:26 INFO SharedState: Warehouse path is 'C:UsersedgarAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/14 12:00:27 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/14 12:00:27 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/14 12:00:27 INFO ObjectStore: ObjectStore, initialize called
17/12/14 12:00:27 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/14 12:00:27 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/14 12:00:28 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/14 12:00:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:30 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/14 12:00:30 INFO ObjectStore: Initialized ObjectStore
17/12/14 12:00:30 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/14 12:00:30 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/14 12:00:30 INFO HiveMetaStore: Added admin role in metastore
17/12/14 12:00:30 INFO HiveMetaStore: Added public role in metastore
17/12/14 12:00:30 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/14 12:00:30 INFO HiveMetaStore: 0: get_all_databases
17/12/14 12:00:30 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/14 12:00:30 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/14 12:00:30 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/14 12:00:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:31 INFO SessionState: Created local directory: C:/Users/edgar/AppData/Local/Temp/abcba01f-e31b-49b7-800b-504947a21f9e_resources
17/12/14 12:00:31 INFO SessionState: Created HDFS directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/edgar/abcba01f-e31b-49b7-800b-504947a21f9e
17/12/14 12:00:31 INFO SessionState: Created local directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/abcba01f-e31b-49b7-800b-504947a21f9e
17/12/14 12:00:31 INFO SessionState: Created HDFS directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/edgar/abcba01f-e31b-49b7-800b-504947a21f9e/_tmp_space.db
17/12/14 12:00:31 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersedgarAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/14 12:00:31 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:31 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:31 INFO HiveMetaStore: 0: get_database: global_temp
17/12/14 12:00:31 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/14 12:00:31 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/14 12:00:31 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:00:33 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:33 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:33 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:33 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:00:33 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:00:33 INFO CodeGenerator: Code generated in 218.51398 ms
17/12/14 12:00:33 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/14 12:00:33 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/14 12:00:33 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/14 12:00:33 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:33 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:33 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
17/12/14 12:00:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/12/14 12:00:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/12/14 12:00:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54571 (size: 4.6 KB, free: 366.3 MB)
17/12/14 12:00:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
17/12/14 12:00:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/14 12:00:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/14 12:00:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/14 12:00:34 INFO Executor: Fetching spark://127.0.0.1:54530/jars/sparklyr-2.1-2.11.jar with timestamp 1513274426457
17/12/14 12:00:34 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54530 after 11 ms (0 ms spent in bootstraps)
17/12/14 12:00:34 INFO Utils: Fetching spark://127.0.0.1:54530/jars/sparklyr-2.1-2.11.jar to C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a\userFiles-a31c2f61-890d-4450-9230-6049fb3c8370\fetchFileTemp3941743637142074845.tmp
17/12/14 12:00:35 INFO Executor: Adding file:/C:/Users/edgar/AppData/Local/Temp/spark-73be84ad-e2ea-42de-a499-a939a4c0355a/userFiles-a31c2f61-890d-4450-9230-6049fb3c8370/sparklyr-2.1-2.11.jar to class loader
17/12/14 12:00:35 INFO CodeGenerator: Code generated in 9.725293 ms
17/12/14 12:00:35 INFO CodeGenerator: Code generated in 9.75935 ms
17/12/14 12:00:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/14 12:00:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 972 ms on localhost (executor driver) (1/1)
17/12/14 12:00:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/14 12:00:35 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.992 s
17/12/14 12:00:35 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 2.091892 s
17/12/14 12:00:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:36 INFO ContextCleaner: Cleaned accumulator 0
17/12/14 12:00:36 INFO ContextCleaner: Cleaned accumulator 1
17/12/14 12:00:36 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:54571 in memory (size: 4.6 KB, free: 366.3 MB)
17/12/14 12:00:36 INFO SparkSqlParser: Parsing command: mtcars
17/12/14 12:00:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
17/12/14 12:00:36 INFO SparkSqlParser: Parsing command: `mtcars`
17/12/14 12:00:36 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:00:36 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:00:36 INFO FileSourceStrategy: Output Data Schema: struct<mpg: double, cyl: double, disp: double, hp: double, drat: double ... 9 more fields>
17/12/14 12:00:36 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:00:36 INFO CodeGenerator: Code generated in 5.722462 ms
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/12/14 12:00:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54571 (size: 23.9 KB, free: 366.3 MB)
17/12/14 12:00:36 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/14 12:00:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:00:36 INFO CodeGenerator: Code generated in 9.642717 ms
17/12/14 12:00:36 INFO CodeGenerator: Code generated in 7.124853 ms
17/12/14 12:00:36 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/14 12:00:36 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
17/12/14 12:00:36 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/14 12:00:36 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
17/12/14 12:00:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/12/14 12:00:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/12/14 12:00:36 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 23.2 KB, free 366.0 MB)
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KB, free 366.0 MB)
17/12/14 12:00:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54571 (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:00:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0)
17/12/14 12:00:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/14 12:00:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/14 12:00:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/14 12:00:36 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/AppData/Local/Temp/RtmpSmNnJO/spark_serialize_600df8759318fe0d3e7cd227dfb889264b9395236a2336b9c1d32f83ed509279.csv, range: 0-1336, partition values: [empty row]
17/12/14 12:00:36 INFO CodeGenerator: Code generated in 11.827479 ms
17/12/14 12:00:36 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
17/12/14 12:00:36 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:54571 (size: 4.2 KB, free: 366.3 MB)
17/12/14 12:00:36 INFO CodeGenerator: Code generated in 3.446727 ms
17/12/14 12:00:36 INFO CodeGenerator: Code generated in 15.186032 ms
17/12/14 12:00:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2907 bytes result sent to driver
17/12/14 12:00:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 196 ms on localhost (executor driver) (1/1)
17/12/14 12:00:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/14 12:00:36 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.197 s
17/12/14 12:00:36 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:36 INFO DAGScheduler: running: Set()
17/12/14 12:00:36 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/12/14 12:00:36 INFO DAGScheduler: failed: Set()
17/12/14 12:00:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/12/14 12:00:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54571 (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:00:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/14 12:00:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/12/14 12:00:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/14 12:00:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/14 12:00:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/12/14 12:00:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1952 bytes result sent to driver
17/12/14 12:00:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (executor driver) (1/1)
17/12/14 12:00:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/14 12:00:36 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.028 s
17/12/14 12:00:36 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.276472 s
17/12/14 12:00:36 INFO CodeGenerator: Code generated in 5.284856 ms
17/12/14 12:00:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:36 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
17/12/14 12:00:36 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:36 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:210)
17/12/14 12:00:36 INFO DAGScheduler: Got job 2 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:00:36 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:210)
17/12/14 12:00:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/12/14 12:00:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/12/14 12:00:36 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 23.2 KB, free 365.9 MB)
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/12/14 12:00:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54571 (size: 11.0 KB, free: 366.2 MB)
17/12/14 12:00:36 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210)
17/12/14 12:00:36 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/14 12:00:36 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/12/14 12:00:36 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/12/14 12:00:36 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:00:36 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2098 bytes result sent to driver
17/12/14 12:00:36 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 15 ms on localhost (executor driver) (1/1)
17/12/14 12:00:36 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/14 12:00:36 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:210) finished in 0.015 s
17/12/14 12:00:36 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:36 INFO DAGScheduler: running: Set()
17/12/14 12:00:36 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/12/14 12:00:36 INFO DAGScheduler: failed: Set()
17/12/14 12:00:36 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/12/14 12:00:36 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/12/14 12:00:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54571 (size: 3.7 KB, free: 366.2 MB)
17/12/14 12:00:36 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210)
17/12/14 12:00:36 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/12/14 12:00:36 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/14 12:00:36 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/12/14 12:00:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:36 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1873 bytes result sent to driver
17/12/14 12:00:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/12/14 12:00:36 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:210) finished in 0.006 s
17/12/14 12:00:36 INFO DAGScheduler: Job 2 finished: collect at utils.scala:210, took 0.036917 s
17/12/14 12:00:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz1`
WHERE (0 = 1)
17/12/14 12:00:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars`
17/12/14 12:00:37 INFO SparkSqlParser: Parsing command: sparklyr_tmp_22b845364bdd
17/12/14 12:00:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b845364bdd` AS `zzz2`
WHERE (0 = 1)
17/12/14 12:00:37 INFO SparkSqlParser: Parsing command: sparklyr_tmp_22b83a1711b2
17/12/14 12:00:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b83a1711b2` AS `zzz3`
WHERE (0 = 1)
17/12/14 12:00:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:00:38 INFO CodeGenerator: Code generated in 9.187383 ms
17/12/14 12:00:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:00:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:00:38 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:00:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:54571 in memory (size: 3.7 KB, free: 366.2 MB)
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 54
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 55
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 56
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 57
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 58
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 59
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 60
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 61
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 62
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 63
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 64
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 65
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 66
17/12/14 12:00:38 INFO ContextCleaner: Cleaned shuffle 0
17/12/14 12:00:38 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:54571 in memory (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:00:38 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:54571 in memory (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:00:38 INFO ContextCleaner: Cleaned accumulator 163
17/12/14 12:00:38 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54571 in memory (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:00:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b845364bdd`
17/12/14 12:00:39 INFO CodeGenerator: Code generated in 48.950236 ms
17/12/14 12:00:40 INFO CodeGenerator: Code generated in 29.602754 ms
17/12/14 12:00:40 INFO Instrumentation: LogisticRegression-logistic_regression_22b83a2c52da-1235924337-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
17/12/14 12:00:40 INFO Instrumentation: LogisticRegression-logistic_regression_22b83a2c52da-1235924337-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:352
17/12/14 12:00:40 INFO DAGScheduler: Got job 3 (treeAggregate at LogisticRegression.scala:352) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 5 (treeAggregate at LogisticRegression.scala:352)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[37] at treeAggregate at LogisticRegression.scala:352), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 41.3 KB, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[37] at treeAggregate at LogisticRegression.scala:352)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:00:40 INFO CodeGenerator: Code generated in 18.573042 ms
17/12/14 12:00:40 INFO CodeGenerator: Code generated in 21.220602 ms
17/12/14 12:00:40 INFO CodeGenerator: Code generated in 7.478016 ms
17/12/14 12:00:40 INFO CodeGenerator: Code generated in 6.076092 ms
17/12/14 12:00:40 INFO MemoryStore: Block rdd_36_0 stored as values in memory (estimated size 1024.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added rdd_36_0 in memory on 127.0.0.1:54571 (size: 1024.0 B, free: 366.3 MB)
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 3873 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 138 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 5 (treeAggregate at LogisticRegression.scala:352) finished in 0.139 s
17/12/14 12:00:40 INFO DAGScheduler: Job 3 finished: treeAggregate at LogisticRegression.scala:352, took 0.146753 s
17/12/14 12:00:40 INFO Instrumentation: LogisticRegression-logistic_regression_22b83a2c52da-1235924337-1: {"numClasses":2}
17/12/14 12:00:40 INFO Instrumentation: LogisticRegression-logistic_regression_22b83a2c52da-1235924337-1: {"numFeatures":2}
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 56.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 85.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54571 (size: 85.0 B, free: 366.3 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 7 from broadcast at LogisticRegression.scala:435
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 150.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54571 (size: 150.0 B, free: 366.3 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 8 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 4 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 6 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[38] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 41.5 KB, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[38] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 3464 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 18 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 6 (treeAggregate at LogisticRegression.scala:1670) finished in 0.019 s
17/12/14 12:00:40 INFO DAGScheduler: Job 4 finished: treeAggregate at LogisticRegression.scala:1670, took 0.026050 s
17/12/14 12:00:40 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/12/14 12:00:40 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(8) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:54571 in memory (size: 150.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 10 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 5 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 7 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[39] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[39] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 3385 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 7 (treeAggregate at LogisticRegression.scala:1670) finished in 0.008 s
17/12/14 12:00:40 INFO DAGScheduler: Job 5 finished: treeAggregate at LogisticRegression.scala:1670, took 0.013665 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(10) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 12 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 6 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 8 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[40] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[40] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 3306 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 8 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
17/12/14 12:00:40 INFO DAGScheduler: Job 6 finished: treeAggregate at LogisticRegression.scala:1670, took 0.012130 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO StrongWolfeLineSearch: Line search t: 0.1776127606846963 fval: 0.6733274538695492 rhs: 0.6931415503338504 cdd: 0.0879774286555366
17/12/14 12:00:40 INFO LBFGS: Step Size: 0.1776
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.673327 (rel: 0.0286) 0.223430
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 14 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 7 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 9 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.7 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 3393 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 9 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
17/12/14 12:00:40 INFO DAGScheduler: Job 7 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009266 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(14) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.669489 (rel: 0.00570) 0.125932
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 80.0 B, free 365.7 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.7 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 16 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 8 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 3385 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 10 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
17/12/14 12:00:40 INFO DAGScheduler: Job 8 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010839 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(16) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.665411 (rel: 0.00609) 0.140194
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 18 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 9 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 11 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 41.5 KB, free 365.6 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 3385 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 11 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:40 INFO DAGScheduler: Job 9 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011020 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(18) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.651362 (rel: 0.0211) 0.319702
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 20 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 10 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 12 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 41.5 KB, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 3396 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 12 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
17/12/14 12:00:40 INFO DAGScheduler: Job 10 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011988 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(20) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.621056 (rel: 0.0465) 0.585898
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.3 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.3 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 22 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 11 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 13 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 41.5 KB, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 3306 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 13 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:40 INFO DAGScheduler: Job 11 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010116 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(22) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.555344 (rel: 0.106) 0.836803
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.9 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 24 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 3385 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 14 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
17/12/14 12:00:40 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:1670, took 0.012246 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(24) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.452434 (rel: 0.185) 0.771843
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 26 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 15 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 3396 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 15 (treeAggregate at LogisticRegression.scala:1670) finished in 0.008 s
17/12/14 12:00:40 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1670, took 0.014915 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(26) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.348155 (rel: 0.230) 0.418736
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 28 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.7 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 3385 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 16 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
17/12/14 12:00:40 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010521 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(28) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.300996 (rel: 0.135) 0.182304
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 80.0 B, free 365.7 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.7 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 30 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 17 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 3385 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 17 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
17/12/14 12:00:40 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011662 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(30) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.280335 (rel: 0.0686) 0.0587078
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 32 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 41.5 KB, free 365.6 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/14 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:40 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
17/12/14 12:00:40 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:40 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 3483 bytes result sent to driver
17/12/14 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/14 12:00:40 INFO DAGScheduler: ResultStage 18 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
17/12/14 12:00:40 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011877 s
17/12/14 12:00:40 INFO TorrentBroadcast: Destroying Broadcast(32) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:40 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:40 INFO LBFGS: Val and Grad Norm: 0.267735 (rel: 0.0449) 0.0688679
17/12/14 12:00:40 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:00:40 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:00:40 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:40 INFO SparkContext: Created broadcast 34 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:40 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:40 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:40 INFO DAGScheduler: Final stage: ResultStage 19 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:40 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:40 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:40 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 41.5 KB, free 365.5 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.5 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 19 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
17/12/14 12:00:41 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011705 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(34) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.258824 (rel: 0.0333) 0.143815
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 80.0 B, free 365.5 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.5 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 20 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 41.5 KB, free 365.5 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.5 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 20 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
17/12/14 12:00:41 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010837 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.250546 (rel: 0.0320) 0.211652
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 80.0 B, free 365.5 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.5 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 38 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 21 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 41.5 KB, free 365.4 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.4 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 21 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
17/12/14 12:00:41 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010948 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.237399 (rel: 0.0525) 0.268147
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 80.0 B, free 365.4 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.4 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 40 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 41.5 KB, free 365.4 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.3 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008604 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(40) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.201139 (rel: 0.153) 0.252263
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 80.0 B, free 365.3 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.3 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 41.5 KB, free 365.3 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.3 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
17/12/14 12:00:41 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010587 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.137662 (rel: 0.316) 0.0260344
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 80.0 B, free 365.3 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.3 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 44 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 41.5 KB, free 365.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
17/12/14 12:00:41 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010060 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(44) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.0905963 (rel: 0.342) 0.0731905
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 80.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 46 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 41.5 KB, free 365.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
17/12/14 12:00:41 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007181 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.0698391 (rel: 0.229) 0.0226923
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 80.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 41.5 KB, free 365.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:41 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008910 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.0487205 (rel: 0.302) 0.0261139
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 80.0 B, free 365.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 50 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 41.5 KB, free 365.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007993 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.0461676 (rel: 0.0524) 0.182264
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 80.0 B, free 365.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 52 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 41.5 KB, free 365.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007003 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(52) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.0154802 (rel: 0.665) 0.0528357
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 80.0 B, free 365.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 54 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 41.5 KB, free 365.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:41 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009290 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.00837459 (rel: 0.459) 0.0229670
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 80.0 B, free 364.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 56 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 41.5 KB, free 364.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008386 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.00413193 (rel: 0.507) 0.00833735
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 80.0 B, free 364.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 58 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 41.5 KB, free 364.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:41 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010024 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(58) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.00212536 (rel: 0.486) 0.00298267
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 80.0 B, free 364.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 60 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 41.5 KB, free 364.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:41 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009872 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(60) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.00107718 (rel: 0.493) 0.000889391
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 80.0 B, free 364.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 62 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 31 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 41.5 KB, free 364.7 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.7 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:41 INFO DAGScheduler: Job 31 finished: treeAggregate at LogisticRegression.scala:1670, took 0.017743 s
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(62) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.000548960 (rel: 0.490) 0.000162723
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 80.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 64 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 32 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 41.5 KB, free 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
17/12/14 12:00:41 INFO DAGScheduler: Job 32 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007734 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(64) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.000275613 (rel: 0.498) 2.66003e-05
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 66 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 33 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 35.0 (TID 35)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 33 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007466 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(66) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 0.000138415 (rel: 0.498) 0.000187595
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 68 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 34 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 34 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007672 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(68) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 6.75793e-05 (rel: 0.512) 4.74734e-05
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 70 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 35 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.7 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 37.0 (TID 37)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 37.0 (TID 37). 3475 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 35 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008796 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(70) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 3.45971e-05 (rel: 0.488) 1.78101e-05
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 80.0 B, free 365.7 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.7 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 72 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 36 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 38.0 (TID 38)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 38.0 (TID 38). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:41 INFO DAGScheduler: Job 36 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008349 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(72) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 1.77894e-05 (rel: 0.486) 4.26350e-05
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 74 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 37 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 41.5 KB, free 365.6 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 39.0 (TID 39)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 39.0 (TID 39). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 37 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007163 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(74) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 1.62550e-05 (rel: 0.0863) 8.68351e-05
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 76 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 38 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 41.5 KB, free 365.5 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.5 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 40.0 (TID 40)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 40.0 (TID 40). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 40) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:00:41 INFO DAGScheduler: Job 38 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009887 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 4.07355e-06 (rel: 0.749) 1.90302e-05
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 80.0 B, free 365.5 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.5 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 78 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 39 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 41.5 KB, free 365.5 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.5 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 41.0 (TID 41)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 41.0 (TID 41). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 41) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 41 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 39 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007745 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(78) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 2.70590e-06 (rel: 0.336) 1.16880e-05
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 80.0 B, free 365.5 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.5 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 80 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 40 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 41.5 KB, free 365.4 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.4 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 42.0 (TID 42)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 42.0 (TID 42). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 42) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 42 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 40 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007718 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(80) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 1.31553e-06 (rel: 0.514) 4.59630e-06
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 80.0 B, free 365.4 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.4 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 82 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 41 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 43 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 41.5 KB, free 365.4 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.3 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 43.0 (TID 43)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 43.0 (TID 43). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 43) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 43 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
17/12/14 12:00:41 INFO DAGScheduler: Job 41 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011004 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(82) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 7.35495e-07 (rel: 0.441) 1.94600e-06
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 80.0 B, free 365.3 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.3 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 84 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 42 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 44 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 41.5 KB, free 365.3 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.3 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 44.0 (TID 44)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 44.0 (TID 44). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 44) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 44 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
17/12/14 12:00:41 INFO DAGScheduler: Job 42 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007318 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(84) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 3.95720e-07 (rel: 0.462) 6.30164e-07
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 80.0 B, free 365.3 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.3 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 86 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 43 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 45 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 41.5 KB, free 365.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 45.0 (TID 45)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 3475 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 45 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 43 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008542 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(86) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 2.18064e-07 (rel: 0.256) 1.09547e-07
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 80.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 88 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 44 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 46 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 41.5 KB, free 365.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 46.0 (TID 46)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 46.0 (TID 46). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 46) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 46 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
17/12/14 12:00:41 INFO DAGScheduler: Job 44 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006487 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(88) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 1.18719e-07 (rel: 0.143) 6.85495e-08
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 80.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 90 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 45 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 47 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[79] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 41.5 KB, free 365.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[79] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 47.0 (TID 47)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 47.0 (TID 47). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 47) in 2 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 47 (treeAggregate at LogisticRegression.scala:1670) finished in 0.002 s
17/12/14 12:00:41 INFO DAGScheduler: Job 45 finished: treeAggregate at LogisticRegression.scala:1670, took 0.005919 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(90) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 6.26454e-08 (rel: 0.0809) 8.36238e-08
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 80.0 B, free 365.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 92 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 46 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 48 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 41.5 KB, free 365.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 48.0 (TID 48)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 48.0 (TID 48). 3385 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 48) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 48 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 46 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007025 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(92) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 5.41246e-08 (rel: 0.0123) 2.58601e-07
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 80.0 B, free 365.1 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 94 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 47 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 49 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[81] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 41.5 KB, free 365.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[81] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 49.0 (TID 49)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 49.0 (TID 49). 3464 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 49) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 49 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
17/12/14 12:00:41 INFO DAGScheduler: Job 47 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008967 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(94) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 2.04071e-08 (rel: 0.0486) 7.25863e-08
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 80.0 B, free 365.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 96 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 48 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 50 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 41.5 KB, free 365.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 50.0 (TID 50)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 50.0 (TID 50). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 50) in 2 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 50 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
17/12/14 12:00:41 INFO DAGScheduler: Job 48 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006767 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(96) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 1.24982e-08 (rel: 0.0114) 3.75787e-08
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 80.0 B, free 364.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 98 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 49 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 51 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[83] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 41.5 KB, free 364.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[83] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 51.0 (TID 51)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 51.0 (TID 51). 3306 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 51 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 49 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007697 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(98) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 6.11281e-09 (rel: 0.00921) 1.43541e-08
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 80.0 B, free 364.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:54571 (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 100 from broadcast at LogisticRegression.scala:1657
17/12/14 12:00:41 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:00:41 INFO DAGScheduler: Got job 50 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 52 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 41.5 KB, free 364.8 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.8 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:54571 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 52.0 (TID 52)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_36_0 locally
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 52.0 (TID 52). 3396 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 52) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 52 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 50 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008716 s
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(100) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:00:41 INFO LBFGS: Step Size: 1.000
17/12/14 12:00:41 INFO LBFGS: Val and Grad Norm: 3.19547e-09 (rel: 0.00421) 5.96583e-09
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:54571 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO LBFGS: Converged because gradient converged
17/12/14 12:00:41 INFO TorrentBroadcast: Destroying Broadcast(7) (from destroy at LogisticRegression.scala:566)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54571 in memory (size: 85.0 B, free: 365.9 MB)
17/12/14 12:00:41 INFO MapPartitionsRDD: Removing RDD 36 from persistence list
17/12/14 12:00:41 INFO BlockManager: Removing RDD 36
17/12/14 12:00:41 INFO CodeGenerator: Code generated in 24.107959 ms
17/12/14 12:00:41 INFO Instrumentation: LogisticRegression-logistic_regression_22b83a2c52da-1235924337-1: training finished
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO DAGScheduler: Registering RDD 89 (map at LogisticRegression.scala:1176)
17/12/14 12:00:41 INFO DAGScheduler: Registering RDD 90 (combineByKey at BinaryClassificationMetrics.scala:151)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO DAGScheduler: Got job 51 (count at BinaryClassificationMetrics.scala:163) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 55 (count at BinaryClassificationMetrics.scala:163)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
17/12/14 12:00:41 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[89] at map at LogisticRegression.scala:1176), which has no missing parents
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 272
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 273
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 274
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 275
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 276
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 277
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 278
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 279
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 280
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 281
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 282
17/12/14 12:00:41 INFO ContextCleaner: Cleaned accumulator 283
17/12/14 12:00:41 INFO BlockManager: Removing RDD 36
17/12/14 12:00:41 INFO ContextCleaner: Cleaned RDD 36
17/12/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:54571 in memory (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 51.0 KB, free 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 22.0 KB, free 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:54571 (size: 22.0 KB, free: 366.3 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[89] at map at LogisticRegression.scala:1176)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6554 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 53.0 (TID 53)
17/12/14 12:00:41 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:00:41 INFO CodeGenerator: Code generated in 6.355077 ms
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 53.0 (TID 53). 2432 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 53) in 46 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ShuffleMapStage 53 (map at LogisticRegression.scala:1176) finished in 0.047 s
17/12/14 12:00:41 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:41 INFO DAGScheduler: running: Set()
17/12/14 12:00:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 54, ResultStage 55)
17/12/14 12:00:41 INFO DAGScheduler: failed: Set()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ShuffleMapStage 54 (ShuffledRDD[90] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 3.4 KB, free 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 1886.0 B, free 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:54571 (size: 1886.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (ShuffledRDD[90] at combineByKey at BinaryClassificationMetrics.scala:151)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 54, localhost, executor driver, partition 0, ANY, 5715 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 54.0 (TID 54)
17/12/14 12:00:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 54.0 (TID 54). 1956 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 54) in 22 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ShuffleMapStage 54 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.022 s
17/12/14 12:00:41 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:41 INFO DAGScheduler: running: Set()
17/12/14 12:00:41 INFO DAGScheduler: waiting: Set(ResultStage 55)
17/12/14 12:00:41 INFO DAGScheduler: failed: Set()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 55 (ShuffledRDD[91] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 1842.0 B, free 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:54571 (size: 1842.0 B, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (ShuffledRDD[91] at sortByKey at BinaryClassificationMetrics.scala:155)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55, localhost, executor driver, partition 0, ANY, 5726 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 55.0 (TID 55)
17/12/14 12:00:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 55.0 (TID 55). 1591 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 11 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 55 (count at BinaryClassificationMetrics.scala:163) finished in 0.012 s
17/12/14 12:00:41 INFO DAGScheduler: Job 51 finished: count at BinaryClassificationMetrics.scala:163, took 0.104343 s
17/12/14 12:00:41 INFO BinaryClassificationMetrics: Curve is too small (7) for 100 bins to be useful
17/12/14 12:00:41 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
17/12/14 12:00:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 143 bytes
17/12/14 12:00:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
17/12/14 12:00:41 INFO DAGScheduler: Got job 52 (collect at BinaryClassificationMetrics.scala:192) with 1 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 58 (collect at BinaryClassificationMetrics.scala:192)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[93] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 4.0 KB, free 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 2.2 KB, free 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:54571 (size: 2.2 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[93] at mapPartitions at BinaryClassificationMetrics.scala:188)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 56, localhost, executor driver, partition 0, ANY, 5812 bytes)
17/12/14 12:00:41 INFO Executor: Running task 0.0 in stage 58.0 (TID 56)
17/12/14 12:00:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:41 INFO Executor: Finished task 0.0 in stage 58.0 (TID 56). 1808 bytes result sent to driver
17/12/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 56) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
17/12/14 12:00:41 INFO DAGScheduler: ResultStage 58 (collect at BinaryClassificationMetrics.scala:192) finished in 0.004 s
17/12/14 12:00:41 INFO DAGScheduler: Job 52 finished: collect at BinaryClassificationMetrics.scala:192, took 0.010367 s
17/12/14 12:00:41 INFO BinaryClassificationMetrics: Total counts: {numPos: 6, numNeg: 6}
17/12/14 12:00:41 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
17/12/14 12:00:41 INFO DAGScheduler: Got job 53 (collect at SlidingRDD.scala:81) with 3 output partitions
17/12/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 61 (collect at SlidingRDD.scala:81)
17/12/14 12:00:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
17/12/14 12:00:41 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[101] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 6.0 KB, free 365.9 MB)
17/12/14 12:00:41 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 3.1 KB, free 365.9 MB)
17/12/14 12:00:41 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:54571 (size: 3.1 KB, free: 366.2 MB)
17/12/14 12:00:41 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:41 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 61 (MapPartitionsRDD[101] at mapPartitions at SlidingRDD.scala:78)
17/12/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 61.0 with 3 tasks
17/12/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 6251 bytes)
17/12/14 12:00:42 INFO TaskSetManager: Starting task 2.0 in stage 61.0 (TID 58, localhost, executor driver, partition 2, PROCESS_LOCAL, 6251 bytes)
17/12/14 12:00:42 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 59, localhost, executor driver, partition 1, ANY, 5923 bytes)
17/12/14 12:00:42 INFO Executor: Running task 0.0 in stage 61.0 (TID 57)
17/12/14 12:00:42 INFO Executor: Running task 2.0 in stage 61.0 (TID 58)
17/12/14 12:00:42 INFO Executor: Running task 1.0 in stage 61.0 (TID 59)
17/12/14 12:00:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/12/14 12:00:42 INFO Executor: Finished task 2.0 in stage 61.0 (TID 58). 990 bytes result sent to driver
17/12/14 12:00:42 INFO Executor: Finished task 0.0 in stage 61.0 (TID 57). 990 bytes result sent to driver
17/12/14 12:00:42 INFO TaskSetManager: Finished task 2.0 in stage 61.0 (TID 58) in 5 ms on localhost (executor driver) (1/3)
17/12/14 12:00:42 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 57) in 6 ms on localhost (executor driver) (2/3)
17/12/14 12:00:42 INFO MemoryStore: Block rdd_94_0 stored as values in memory (estimated size 608.0 B, free 365.9 MB)
17/12/14 12:00:42 INFO BlockManagerInfo: Added rdd_94_0 in memory on 127.0.0.1:54571 (size: 608.0 B, free: 366.2 MB)
17/12/14 12:00:42 INFO Executor: Finished task 1.0 in stage 61.0 (TID 59). 2509 bytes result sent to driver
17/12/14 12:00:42 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 59) in 7 ms on localhost (executor driver) (3/3)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
17/12/14 12:00:42 INFO DAGScheduler: ResultStage 61 (collect at SlidingRDD.scala:81) finished in 0.010 s
17/12/14 12:00:42 INFO DAGScheduler: Job 53 finished: collect at SlidingRDD.scala:81, took 0.015256 s
17/12/14 12:00:42 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
17/12/14 12:00:42 INFO DAGScheduler: Got job 54 (aggregate at AreaUnderCurve.scala:45) with 2 output partitions
17/12/14 12:00:42 INFO DAGScheduler: Final stage: ResultStage 64 (aggregate at AreaUnderCurve.scala:45)
17/12/14 12:00:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
17/12/14 12:00:42 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:42 INFO DAGScheduler: Submitting ResultStage 64 (SlidingRDD[100] at RDD at SlidingRDD.scala:50), which has no missing parents
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 6.1 KB, free 365.9 MB)
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 3.2 KB, free 365.9 MB)
17/12/14 12:00:42 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:54571 (size: 3.2 KB, free: 366.2 MB)
17/12/14 12:00:42 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 64 (SlidingRDD[100] at RDD at SlidingRDD.scala:50)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks
17/12/14 12:00:42 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 60, localhost, executor driver, partition 1, PROCESS_LOCAL, 6462 bytes)
17/12/14 12:00:42 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/12/14 12:00:42 INFO Executor: Running task 0.0 in stage 64.0 (TID 61)
17/12/14 12:00:42 INFO Executor: Running task 1.0 in stage 64.0 (TID 60)
17/12/14 12:00:42 INFO BlockManager: Found block rdd_94_0 locally
17/12/14 12:00:42 INFO Executor: Finished task 0.0 in stage 64.0 (TID 61). 796 bytes result sent to driver
17/12/14 12:00:42 INFO Executor: Finished task 1.0 in stage 64.0 (TID 60). 956 bytes result sent to driver
17/12/14 12:00:42 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 61) in 6 ms on localhost (executor driver) (1/2)
17/12/14 12:00:42 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 60) in 9 ms on localhost (executor driver) (2/2)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
17/12/14 12:00:42 INFO DAGScheduler: ResultStage 64 (aggregate at AreaUnderCurve.scala:45) finished in 0.009 s
17/12/14 12:00:42 INFO DAGScheduler: Job 54 finished: aggregate at AreaUnderCurve.scala:45, took 0.012937 s
17/12/14 12:00:42 INFO CodeGenerator: Code generated in 7.581119 ms
17/12/14 12:00:42 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:42 INFO DAGScheduler: Got job 55 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:00:42 INFO DAGScheduler: Final stage: ResultStage 67 (collect at utils.scala:210)
17/12/14 12:00:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
17/12/14 12:00:42 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:42 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[105] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 10.0 KB, free 365.9 MB)
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 4.7 KB, free 365.9 MB)
17/12/14 12:00:42 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:54571 (size: 4.7 KB, free: 366.2 MB)
17/12/14 12:00:42 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[105] at collect at utils.scala:210)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
17/12/14 12:00:42 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
17/12/14 12:00:42 INFO Executor: Running task 0.0 in stage 67.0 (TID 62)
17/12/14 12:00:42 INFO BlockManager: Found block rdd_94_0 locally
17/12/14 12:00:42 INFO Executor: Finished task 0.0 in stage 67.0 (TID 62). 1480 bytes result sent to driver
17/12/14 12:00:42 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 62) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
17/12/14 12:00:42 INFO DAGScheduler: ResultStage 67 (collect at utils.scala:210) finished in 0.006 s
17/12/14 12:00:42 INFO DAGScheduler: Job 55 finished: collect at utils.scala:210, took 0.010185 s
17/12/14 12:00:42 INFO CodeGenerator: Code generated in 4.24356 ms
17/12/14 12:00:42 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:42 INFO DAGScheduler: Got job 56 (collect at utils.scala:210) with 2 output partitions
17/12/14 12:00:42 INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:210)
17/12/14 12:00:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)
17/12/14 12:00:42 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:42 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[111] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 10.7 KB, free 365.9 MB)
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 5.1 KB, free 365.9 MB)
17/12/14 12:00:42 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:54571 (size: 5.1 KB, free: 366.2 MB)
17/12/14 12:00:42 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 70 (MapPartitionsRDD[111] at collect at utils.scala:210)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks
17/12/14 12:00:42 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 63, localhost, executor driver, partition 1, PROCESS_LOCAL, 5950 bytes)
17/12/14 12:00:42 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
17/12/14 12:00:42 INFO Executor: Running task 0.0 in stage 70.0 (TID 64)
17/12/14 12:00:42 INFO Executor: Running task 1.0 in stage 70.0 (TID 63)
17/12/14 12:00:42 INFO BlockManager: Found block rdd_94_0 locally
17/12/14 12:00:42 INFO Executor: Finished task 0.0 in stage 70.0 (TID 64). 1048 bytes result sent to driver
17/12/14 12:00:42 INFO Executor: Finished task 1.0 in stage 70.0 (TID 63). 1276 bytes result sent to driver
17/12/14 12:00:42 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 64) in 4 ms on localhost (executor driver) (1/2)
17/12/14 12:00:42 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 63) in 4 ms on localhost (executor driver) (2/2)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
17/12/14 12:00:42 INFO DAGScheduler: ResultStage 70 (collect at utils.scala:210) finished in 0.004 s
17/12/14 12:00:42 INFO DAGScheduler: Job 56 finished: collect at utils.scala:210, took 0.008265 s
17/12/14 12:00:42 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:42 INFO DAGScheduler: Got job 57 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:00:42 INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:210)
17/12/14 12:00:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
17/12/14 12:00:42 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:42 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[115] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 9.9 KB, free 365.8 MB)
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 4.7 KB, free 365.8 MB)
17/12/14 12:00:42 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:54571 (size: 4.7 KB, free: 366.2 MB)
17/12/14 12:00:42 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[115] at collect at utils.scala:210)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
17/12/14 12:00:42 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
17/12/14 12:00:42 INFO Executor: Running task 0.0 in stage 73.0 (TID 65)
17/12/14 12:00:42 INFO BlockManager: Found block rdd_94_0 locally
17/12/14 12:00:42 INFO Executor: Finished task 0.0 in stage 73.0 (TID 65). 1395 bytes result sent to driver
17/12/14 12:00:42 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 65) in 2 ms on localhost (executor driver) (1/1)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
17/12/14 12:00:42 INFO DAGScheduler: ResultStage 73 (collect at utils.scala:210) finished in 0.002 s
17/12/14 12:00:42 INFO DAGScheduler: Job 57 finished: collect at utils.scala:210, took 0.005519 s
17/12/14 12:00:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_22b81c6b5a09
17/12/14 12:00:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b81c6b5a09` AS `zzz4`
WHERE (0 = 1)
17/12/14 12:00:42 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:42 INFO DAGScheduler: Got job 58 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:00:42 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:210)
17/12/14 12:00:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
17/12/14 12:00:42 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:42 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[120] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 9.9 KB, free 365.8 MB)
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 4.7 KB, free 365.8 MB)
17/12/14 12:00:42 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:54571 (size: 4.7 KB, free: 366.2 MB)
17/12/14 12:00:42 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[120] at collect at utils.scala:210)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
17/12/14 12:00:42 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
17/12/14 12:00:42 INFO Executor: Running task 0.0 in stage 76.0 (TID 66)
17/12/14 12:00:42 INFO BlockManager: Found block rdd_94_0 locally
17/12/14 12:00:42 INFO Executor: Finished task 0.0 in stage 76.0 (TID 66). 1379 bytes result sent to driver
17/12/14 12:00:42 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 66) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
17/12/14 12:00:42 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:210) finished in 0.003 s
17/12/14 12:00:42 INFO DAGScheduler: Job 58 finished: collect at utils.scala:210, took 0.007444 s
17/12/14 12:00:42 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:42 INFO DAGScheduler: Got job 59 (collect at utils.scala:210) with 3 output partitions
17/12/14 12:00:42 INFO DAGScheduler: Final stage: ResultStage 79 (collect at utils.scala:210)
17/12/14 12:00:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
17/12/14 12:00:42 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:42 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[127] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 10.8 KB, free 365.8 MB)
17/12/14 12:00:42 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 5.1 KB, free 365.8 MB)
17/12/14 12:00:42 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:54571 (size: 5.1 KB, free: 366.2 MB)
17/12/14 12:00:42 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:42 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 79 (MapPartitionsRDD[127] at collect at utils.scala:210)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Adding task set 79.0 with 3 tasks
17/12/14 12:00:42 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 67, localhost, executor driver, partition 1, PROCESS_LOCAL, 5950 bytes)
17/12/14 12:00:42 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
17/12/14 12:00:42 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 69, localhost, executor driver, partition 2, PROCESS_LOCAL, 6278 bytes)
17/12/14 12:00:42 INFO Executor: Running task 0.0 in stage 79.0 (TID 68)
17/12/14 12:00:42 INFO Executor: Running task 2.0 in stage 79.0 (TID 69)
17/12/14 12:00:42 INFO Executor: Running task 1.0 in stage 79.0 (TID 67)
17/12/14 12:00:42 INFO BlockManager: Found block rdd_94_0 locally
17/12/14 12:00:42 INFO Executor: Finished task 2.0 in stage 79.0 (TID 69). 1055 bytes result sent to driver
17/12/14 12:00:42 INFO Executor: Finished task 1.0 in stage 79.0 (TID 67). 1262 bytes result sent to driver
17/12/14 12:00:42 INFO Executor: Finished task 0.0 in stage 79.0 (TID 68). 1047 bytes result sent to driver
17/12/14 12:00:42 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 69) in 3 ms on localhost (executor driver) (1/3)
17/12/14 12:00:42 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 67) in 4 ms on localhost (executor driver) (2/3)
17/12/14 12:00:42 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 68) in 3 ms on localhost (executor driver) (3/3)
17/12/14 12:00:42 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
17/12/14 12:00:42 INFO DAGScheduler: ResultStage 79 (collect at utils.scala:210) finished in 0.004 s
17/12/14 12:00:42 INFO DAGScheduler: Job 59 finished: collect at utils.scala:210, took 0.007752 s
17/12/14 12:00:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b83a1711b2`
17/12/14 12:00:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_22b83add4506
17/12/14 12:00:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b83add4506` AS `zzz5`
WHERE (0 = 1)
17/12/14 12:00:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b83add4506`
LIMIT 25
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 49.412101 ms
17/12/14 12:00:43 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:43 INFO DAGScheduler: Got job 60 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:00:43 INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:210)
17/12/14 12:00:43 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:43 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:43 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[131] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 71.7 KB, free 365.7 MB)
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 26.0 KB, free 365.7 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:54571 (size: 26.0 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[131] at collect at utils.scala:210)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
17/12/14 12:00:43 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/12/14 12:00:43 INFO Executor: Running task 0.0 in stage 80.0 (TID 70)
17/12/14 12:00:43 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:00:43 INFO Executor: Finished task 0.0 in stage 80.0 (TID 70). 3793 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 70) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
17/12/14 12:00:43 INFO DAGScheduler: ResultStage 80 (collect at utils.scala:210) finished in 0.016 s
17/12/14 12:00:43 INFO DAGScheduler: Job 60 finished: collect at utils.scala:210, took 0.021055 s
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 9.252698 ms
17/12/14 12:00:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:00:43 INFO SparkSqlParser: Parsing command: SELECT `guzzler`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_22b83add4506`
GROUP BY `guzzler`, `prediction`
LIMIT 1000
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 19.221053 ms
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 36.015214 ms
17/12/14 12:00:43 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:43 INFO DAGScheduler: Registering RDD 134 (collect at utils.scala:210)
17/12/14 12:00:43 INFO DAGScheduler: Got job 61 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:00:43 INFO DAGScheduler: Final stage: ResultStage 82 (collect at utils.scala:210)
17/12/14 12:00:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
17/12/14 12:00:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
17/12/14 12:00:43 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[134] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 57.6 KB, free 365.7 MB)
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 25.3 KB, free 365.6 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:54571 (size: 25.3 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[134] at collect at utils.scala:210)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
17/12/14 12:00:43 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 6584 bytes)
17/12/14 12:00:43 INFO Executor: Running task 0.0 in stage 81.0 (TID 71)
17/12/14 12:00:43 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 3.957111 ms
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 4.211836 ms
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 4.95502 ms
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 10.56738 ms
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 5.318447 ms
17/12/14 12:00:43 INFO Executor: Finished task 0.0 in stage 81.0 (TID 71). 2711 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 71) in 84 ms on localhost (executor driver) (1/1)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
17/12/14 12:00:43 INFO DAGScheduler: ShuffleMapStage 81 (collect at utils.scala:210) finished in 0.084 s
17/12/14 12:00:43 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:43 INFO DAGScheduler: running: Set()
17/12/14 12:00:43 INFO DAGScheduler: waiting: Set(ResultStage 82)
17/12/14 12:00:43 INFO DAGScheduler: failed: Set()
17/12/14 12:00:43 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[137] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 31.2 KB, free 365.6 MB)
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 14.2 KB, free 365.6 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:54571 (size: 14.2 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[137] at collect at utils.scala:210)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
17/12/14 12:00:43 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/14 12:00:43 INFO Executor: Running task 0.0 in stage 82.0 (TID 72)
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:43 INFO Executor: Finished task 0.0 in stage 82.0 (TID 72). 3012 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 72) in 8 ms on localhost (executor driver) (1/1)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
17/12/14 12:00:43 INFO DAGScheduler: ResultStage 82 (collect at utils.scala:210) finished in 0.008 s
17/12/14 12:00:43 INFO DAGScheduler: Job 61 finished: collect at utils.scala:210, took 0.100733 s
17/12/14 12:00:43 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 149 bytes
17/12/14 12:00:43 INFO DAGScheduler: Got job 62 (collect at utils.scala:210) with 4 output partitions
17/12/14 12:00:43 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:210)
17/12/14 12:00:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
17/12/14 12:00:43 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:43 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[137] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 31.2 KB, free 365.6 MB)
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 14.2 KB, free 365.5 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:54571 (size: 14.2 KB, free: 366.1 MB)
17/12/14 12:00:43 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 84 (MapPartitionsRDD[137] at collect at utils.scala:210)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Adding task set 84.0 with 4 tasks
17/12/14 12:00:43 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 73, localhost, executor driver, partition 2, PROCESS_LOCAL, 5861 bytes)
17/12/14 12:00:43 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 74, localhost, executor driver, partition 3, PROCESS_LOCAL, 5861 bytes)
17/12/14 12:00:43 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 75, localhost, executor driver, partition 4, PROCESS_LOCAL, 5861 bytes)
17/12/14 12:00:43 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 76, localhost, executor driver, partition 1, ANY, 5861 bytes)
17/12/14 12:00:43 INFO Executor: Running task 1.0 in stage 84.0 (TID 73)
17/12/14 12:00:43 INFO Executor: Running task 3.0 in stage 84.0 (TID 75)
17/12/14 12:00:43 INFO Executor: Running task 2.0 in stage 84.0 (TID 74)
17/12/14 12:00:43 INFO Executor: Running task 0.0 in stage 84.0 (TID 76)
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:43 INFO Executor: Finished task 1.0 in stage 84.0 (TID 73). 3012 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 73) in 8 ms on localhost (executor driver) (1/4)
17/12/14 12:00:43 INFO Executor: Finished task 3.0 in stage 84.0 (TID 75). 3012 bytes result sent to driver
17/12/14 12:00:43 INFO Executor: Finished task 2.0 in stage 84.0 (TID 74). 3012 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 75) in 8 ms on localhost (executor driver) (2/4)
17/12/14 12:00:43 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 74) in 8 ms on localhost (executor driver) (3/4)
17/12/14 12:00:43 INFO Executor: Finished task 0.0 in stage 84.0 (TID 76). 2953 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 76) in 10 ms on localhost (executor driver) (4/4)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
17/12/14 12:00:43 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:210) finished in 0.011 s
17/12/14 12:00:43 INFO DAGScheduler: Job 62 finished: collect at utils.scala:210, took 0.015160 s
17/12/14 12:00:43 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:00:43 INFO DAGScheduler: Got job 63 (collect at utils.scala:210) with 3 output partitions
17/12/14 12:00:43 INFO DAGScheduler: Final stage: ResultStage 86 (collect at utils.scala:210)
17/12/14 12:00:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
17/12/14 12:00:43 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:43 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[137] at collect at utils.scala:210), which has no missing parents
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 31.2 KB, free 365.5 MB)
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 14.2 KB, free 365.5 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:54571 (size: 14.2 KB, free: 366.1 MB)
17/12/14 12:00:43 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:43 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 86 (MapPartitionsRDD[137] at collect at utils.scala:210)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Adding task set 86.0 with 3 tasks
17/12/14 12:00:43 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 77, localhost, executor driver, partition 5, PROCESS_LOCAL, 5861 bytes)
17/12/14 12:00:43 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 78, localhost, executor driver, partition 7, PROCESS_LOCAL, 5861 bytes)
17/12/14 12:00:43 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 79, localhost, executor driver, partition 6, ANY, 5861 bytes)
17/12/14 12:00:43 INFO Executor: Running task 2.0 in stage 86.0 (TID 78)
17/12/14 12:00:43 INFO Executor: Running task 1.0 in stage 86.0 (TID 79)
17/12/14 12:00:43 INFO Executor: Running task 0.0 in stage 86.0 (TID 77)
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:43 INFO Executor: Finished task 1.0 in stage 86.0 (TID 79). 3055 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 79) in 6 ms on localhost (executor driver) (1/3)
17/12/14 12:00:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:43 INFO Executor: Finished task 2.0 in stage 86.0 (TID 78). 2933 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 78) in 8 ms on localhost (executor driver) (2/3)
17/12/14 12:00:43 INFO Executor: Finished task 0.0 in stage 86.0 (TID 77). 3023 bytes result sent to driver
17/12/14 12:00:43 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 77) in 9 ms on localhost (executor driver) (3/3)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
17/12/14 12:00:43 INFO DAGScheduler: ResultStage 86 (collect at utils.scala:210) finished in 0.010 s
17/12/14 12:00:43 INFO DAGScheduler: Job 63 finished: collect at utils.scala:210, took 0.013216 s
17/12/14 12:00:43 INFO CodeGenerator: Code generated in 5.626823 ms
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:54571 in memory (size: 14.2 KB, free: 366.1 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:54571 in memory (size: 22.0 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:54571 in memory (size: 1886.0 B, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:54571 in memory (size: 1842.0 B, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:54571 in memory (size: 2.2 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:54571 in memory (size: 3.1 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:54571 in memory (size: 3.2 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:54571 in memory (size: 4.7 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:54571 in memory (size: 5.1 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:54571 in memory (size: 4.7 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:54571 in memory (size: 4.7 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:54571 in memory (size: 5.1 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:54571 in memory (size: 26.0 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO ContextCleaner: Cleaned accumulator 3330
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:54571 in memory (size: 25.3 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:54571 in memory (size: 14.2 KB, free: 366.3 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:54571 in memory (size: 14.2 KB, free: 366.3 MB)
17/12/14 12:00:43 INFO PipelineModel$PipelineModelWriter: Path C:\Users\edgar\Documents\ml_pipeline\new_model already exists. It will be overwritten.
17/12/14 12:00:43 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/12/14 12:00:43 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/12/14 12:00:43 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/12/14 12:00:43 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/12/14 12:00:43 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/12/14 12:00:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:43 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:00:43 INFO DAGScheduler: Got job 64 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:00:43 INFO DAGScheduler: Final stage: ResultStage 87 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:43 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:43 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:43 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[139] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 72.1 KB, free 365.9 MB)
17/12/14 12:00:43 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.9 MB)
17/12/14 12:00:43 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:54571 (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:00:43 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[139] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:43 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
17/12/14 12:00:43 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 6264 bytes)
17/12/14 12:00:43 INFO Executor: Running task 0.0 in stage 87.0 (TID 80)
17/12/14 12:00:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120043_0087_m_000000_80' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/metadata/_temporary/0/task_20171214120043_0087_m_000000
17/12/14 12:00:44 INFO SparkHadoopMapRedUtil: attempt_20171214120043_0087_m_000000_80: Committed
17/12/14 12:00:44 INFO Executor: Finished task 0.0 in stage 87.0 (TID 80). 1180 bytes result sent to driver
17/12/14 12:00:44 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 80) in 138 ms on localhost (executor driver) (1/1)
17/12/14 12:00:44 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
17/12/14 12:00:44 INFO DAGScheduler: ResultStage 87 (saveAsTextFile at ReadWrite.scala:275) finished in 0.139 s
17/12/14 12:00:44 INFO DAGScheduler: Job 64 finished: saveAsTextFile at ReadWrite.scala:275, took 0.151864 s
17/12/14 12:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:00:44 INFO DAGScheduler: Got job 65 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:00:44 INFO DAGScheduler: Final stage: ResultStage 88 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:44 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:44 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:44 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[141] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:00:44 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 72.1 KB, free 365.8 MB)
17/12/14 12:00:44 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.8 MB)
17/12/14 12:00:44 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:54571 (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:00:44 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[141] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:44 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
17/12/14 12:00:44 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
17/12/14 12:00:44 INFO Executor: Running task 0.0 in stage 88.0 (TID 81)
17/12/14 12:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120044_0088_m_000000_81' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/0_binarizer_22b832a93f9d/metadata/_temporary/0/task_20171214120044_0088_m_000000
17/12/14 12:00:44 INFO SparkHadoopMapRedUtil: attempt_20171214120044_0088_m_000000_81: Committed
17/12/14 12:00:44 INFO Executor: Finished task 0.0 in stage 88.0 (TID 81). 1014 bytes result sent to driver
17/12/14 12:00:44 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 81) in 114 ms on localhost (executor driver) (1/1)
17/12/14 12:00:44 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
17/12/14 12:00:44 INFO DAGScheduler: ResultStage 88 (saveAsTextFile at ReadWrite.scala:275) finished in 0.114 s
17/12/14 12:00:44 INFO DAGScheduler: Job 65 finished: saveAsTextFile at ReadWrite.scala:275, took 0.127313 s
17/12/14 12:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:00:44 INFO DAGScheduler: Got job 66 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:00:44 INFO DAGScheduler: Final stage: ResultStage 89 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:44 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:44 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:44 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[143] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:00:44 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 72.1 KB, free 365.7 MB)
17/12/14 12:00:44 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.7 MB)
17/12/14 12:00:44 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:54571 (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:00:44 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[143] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:44 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
17/12/14 12:00:44 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 6218 bytes)
17/12/14 12:00:44 INFO Executor: Running task 0.0 in stage 89.0 (TID 82)
17/12/14 12:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120044_0089_m_000000_82' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/metadata/_temporary/0/task_20171214120044_0089_m_000000
17/12/14 12:00:44 INFO SparkHadoopMapRedUtil: attempt_20171214120044_0089_m_000000_82: Committed
17/12/14 12:00:44 INFO Executor: Finished task 0.0 in stage 89.0 (TID 82). 924 bytes result sent to driver
17/12/14 12:00:44 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 82) in 120 ms on localhost (executor driver) (1/1)
17/12/14 12:00:44 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
17/12/14 12:00:44 INFO DAGScheduler: ResultStage 89 (saveAsTextFile at ReadWrite.scala:275) finished in 0.120 s
17/12/14 12:00:44 INFO DAGScheduler: Job 66 finished: saveAsTextFile at ReadWrite.scala:275, took 0.133258 s
17/12/14 12:00:44 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:44 INFO CodeGenerator: Code generated in 8.725052 ms
17/12/14 12:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:44 INFO SparkContext: Starting job: parquet at RFormula.scala:325
17/12/14 12:00:44 INFO DAGScheduler: Registering RDD 146 (parquet at RFormula.scala:325)
17/12/14 12:00:44 INFO DAGScheduler: Got job 67 (parquet at RFormula.scala:325) with 1 output partitions
17/12/14 12:00:44 INFO DAGScheduler: Final stage: ResultStage 91 (parquet at RFormula.scala:325)
17/12/14 12:00:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
17/12/14 12:00:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
17/12/14 12:00:44 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[146] at parquet at RFormula.scala:325), which has no missing parents
17/12/14 12:00:44 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 4.9 KB, free 365.7 MB)
17/12/14 12:00:44 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 2.9 KB, free 365.7 MB)
17/12/14 12:00:44 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:54571 (size: 2.9 KB, free: 366.2 MB)
17/12/14 12:00:44 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[146] at parquet at RFormula.scala:325)
17/12/14 12:00:44 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
17/12/14 12:00:44 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 6341 bytes)
17/12/14 12:00:44 INFO Executor: Running task 0.0 in stage 90.0 (TID 83)
17/12/14 12:00:44 INFO Executor: Finished task 0.0 in stage 90.0 (TID 83). 1385 bytes result sent to driver
17/12/14 12:00:44 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 83) in 12 ms on localhost (executor driver) (1/1)
17/12/14 12:00:44 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
17/12/14 12:00:44 INFO DAGScheduler: ShuffleMapStage 90 (parquet at RFormula.scala:325) finished in 0.012 s
17/12/14 12:00:44 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:44 INFO DAGScheduler: running: Set()
17/12/14 12:00:44 INFO DAGScheduler: waiting: Set(ResultStage 91)
17/12/14 12:00:44 INFO DAGScheduler: failed: Set()
17/12/14 12:00:44 INFO DAGScheduler: Submitting ResultStage 91 (ShuffledRowRDD[147] at parquet at RFormula.scala:325), which has no missing parents
17/12/14 12:00:44 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 77.2 KB, free 365.6 MB)
17/12/14 12:00:44 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 28.7 KB, free 365.6 MB)
17/12/14 12:00:44 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:54571 (size: 28.7 KB, free: 366.2 MB)
17/12/14 12:00:44 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (ShuffledRowRDD[147] at parquet at RFormula.scala:325)
17/12/14 12:00:44 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
17/12/14 12:00:44 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 84, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/14 12:00:44 INFO Executor: Running task 0.0 in stage 91.0 (TID 84)
17/12/14 12:00:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
17/12/14 12:00:45 INFO CodecPool: Got brand-new compressor [.snappy]
17/12/14 12:00:45 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120044_0091_m_000000_0' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/data/_temporary/0/task_20171214120044_0091_m_000000
17/12/14 12:00:45 INFO SparkHadoopMapRedUtil: attempt_20171214120044_0091_m_000000_0: Committed
17/12/14 12:00:45 INFO Executor: Finished task 0.0 in stage 91.0 (TID 84). 1932 bytes result sent to driver
17/12/14 12:00:45 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 84) in 998 ms on localhost (executor driver) (1/1)
17/12/14 12:00:45 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
17/12/14 12:00:45 INFO DAGScheduler: ResultStage 91 (parquet at RFormula.scala:325) finished in 0.999 s
17/12/14 12:00:45 INFO DAGScheduler: Job 67 finished: parquet at RFormula.scala:325, took 1.027023 s
17/12/14 12:00:46 INFO FileFormatWriter: Job null committed.
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:00:46 INFO DAGScheduler: Got job 68 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:00:46 INFO DAGScheduler: Final stage: ResultStage 92 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:46 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:46 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:46 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[150] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 72.1 KB, free 365.5 MB)
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.5 MB)
17/12/14 12:00:46 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:54571 (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:00:46 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[150] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
17/12/14 12:00:46 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 6267 bytes)
17/12/14 12:00:46 INFO Executor: Running task 0.0 in stage 92.0 (TID 85)
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120046_0092_m_000000_85' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/metadata/_temporary/0/task_20171214120046_0092_m_000000
17/12/14 12:00:46 INFO SparkHadoopMapRedUtil: attempt_20171214120046_0092_m_000000_85: Committed
17/12/14 12:00:46 INFO Executor: Finished task 0.0 in stage 92.0 (TID 85). 1014 bytes result sent to driver
17/12/14 12:00:46 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 85) in 120 ms on localhost (executor driver) (1/1)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
17/12/14 12:00:46 INFO DAGScheduler: ResultStage 92 (saveAsTextFile at ReadWrite.scala:275) finished in 0.122 s
17/12/14 12:00:46 INFO DAGScheduler: Job 68 finished: saveAsTextFile at ReadWrite.scala:275, took 0.134230 s
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:00:46 INFO DAGScheduler: Got job 69 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:00:46 INFO DAGScheduler: Final stage: ResultStage 93 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:46 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:46 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:46 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[152] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 72.1 KB, free 365.4 MB)
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.4 MB)
17/12/14 12:00:46 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:54571 (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:00:46 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[152] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
17/12/14 12:00:46 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 6224 bytes)
17/12/14 12:00:46 INFO Executor: Running task 0.0 in stage 93.0 (TID 86)
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120046_0093_m_000000_86' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/0_r_formula_22b821e83bb4/metadata/_temporary/0/task_20171214120046_0093_m_000000
17/12/14 12:00:46 INFO SparkHadoopMapRedUtil: attempt_20171214120046_0093_m_000000_86: Committed
17/12/14 12:00:46 INFO Executor: Finished task 0.0 in stage 93.0 (TID 86). 924 bytes result sent to driver
17/12/14 12:00:46 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 86) in 114 ms on localhost (executor driver) (1/1)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
17/12/14 12:00:46 INFO DAGScheduler: ResultStage 93 (saveAsTextFile at ReadWrite.scala:275) finished in 0.114 s
17/12/14 12:00:46 INFO DAGScheduler: Job 69 finished: saveAsTextFile at ReadWrite.scala:275, took 0.126324 s
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:00:46 INFO DAGScheduler: Got job 70 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:00:46 INFO DAGScheduler: Final stage: ResultStage 94 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:46 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:46 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:46 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[154] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 72.1 KB, free 365.3 MB)
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.3 MB)
17/12/14 12:00:46 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:54571 (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:00:46 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[154] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
17/12/14 12:00:46 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 6194 bytes)
17/12/14 12:00:46 INFO Executor: Running task 0.0 in stage 94.0 (TID 87)
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120046_0094_m_000000_87' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/metadata/_temporary/0/task_20171214120046_0094_m_000000
17/12/14 12:00:46 INFO SparkHadoopMapRedUtil: attempt_20171214120046_0094_m_000000_87: Committed
17/12/14 12:00:46 INFO Executor: Finished task 0.0 in stage 94.0 (TID 87). 924 bytes result sent to driver
17/12/14 12:00:46 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 87) in 116 ms on localhost (executor driver) (1/1)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
17/12/14 12:00:46 INFO DAGScheduler: ResultStage 94 (saveAsTextFile at ReadWrite.scala:275) finished in 0.116 s
17/12/14 12:00:46 INFO DAGScheduler: Job 70 finished: saveAsTextFile at ReadWrite.scala:275, took 0.128616 s
17/12/14 12:00:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:46 INFO CodeGenerator: Code generated in 7.687488 ms
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:46 INFO SparkContext: Starting job: parquet at RFormula.scala:490
17/12/14 12:00:46 INFO DAGScheduler: Registering RDD 157 (parquet at RFormula.scala:490)
17/12/14 12:00:46 INFO DAGScheduler: Got job 71 (parquet at RFormula.scala:490) with 1 output partitions
17/12/14 12:00:46 INFO DAGScheduler: Final stage: ResultStage 96 (parquet at RFormula.scala:490)
17/12/14 12:00:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
17/12/14 12:00:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 95)
17/12/14 12:00:46 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[157] at parquet at RFormula.scala:490), which has no missing parents
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 4.8 KB, free 365.3 MB)
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 2.9 KB, free 365.3 MB)
17/12/14 12:00:46 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:54571 (size: 2.9 KB, free: 366.1 MB)
17/12/14 12:00:46 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[157] at parquet at RFormula.scala:490)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
17/12/14 12:00:46 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 6261 bytes)
17/12/14 12:00:46 INFO Executor: Running task 0.0 in stage 95.0 (TID 88)
17/12/14 12:00:46 INFO Executor: Finished task 0.0 in stage 95.0 (TID 88). 1385 bytes result sent to driver
17/12/14 12:00:46 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 88) in 10 ms on localhost (executor driver) (1/1)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
17/12/14 12:00:46 INFO DAGScheduler: ShuffleMapStage 95 (parquet at RFormula.scala:490) finished in 0.010 s
17/12/14 12:00:46 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:46 INFO DAGScheduler: running: Set()
17/12/14 12:00:46 INFO DAGScheduler: waiting: Set(ResultStage 96)
17/12/14 12:00:46 INFO DAGScheduler: failed: Set()
17/12/14 12:00:46 INFO DAGScheduler: Submitting ResultStage 96 (ShuffledRowRDD[158] at parquet at RFormula.scala:490), which has no missing parents
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 77.1 KB, free 365.2 MB)
17/12/14 12:00:46 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 28.7 KB, free 365.2 MB)
17/12/14 12:00:46 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:54571 (size: 28.7 KB, free: 366.1 MB)
17/12/14 12:00:46 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (ShuffledRowRDD[158] at parquet at RFormula.scala:490)
17/12/14 12:00:46 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
17/12/14 12:00:46 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 89, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/14 12:00:46 INFO Executor: Running task 0.0 in stage 96.0 (TID 89)
17/12/14 12:00:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
17/12/14 12:00:46 INFO CodecPool: Got brand-new compressor [.snappy]
17/12/14 12:00:47 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120046_0096_m_000000_0' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/data/_temporary/0/task_20171214120046_0096_m_000000
17/12/14 12:00:47 INFO SparkHadoopMapRedUtil: attempt_20171214120046_0096_m_000000_0: Committed
17/12/14 12:00:47 INFO Executor: Finished task 0.0 in stage 96.0 (TID 89). 1856 bytes result sent to driver
17/12/14 12:00:47 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 89) in 122 ms on localhost (executor driver) (1/1)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
17/12/14 12:00:47 INFO DAGScheduler: ResultStage 96 (parquet at RFormula.scala:490) finished in 0.122 s
17/12/14 12:00:47 INFO DAGScheduler: Job 71 finished: parquet at RFormula.scala:490, took 0.147134 s
17/12/14 12:00:47 INFO FileFormatWriter: Job null committed.
17/12/14 12:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:47 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:00:47 INFO DAGScheduler: Got job 72 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:00:47 INFO DAGScheduler: Final stage: ResultStage 97 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:47 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:47 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:47 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[161] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:00:47 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 72.1 KB, free 365.1 MB)
17/12/14 12:00:47 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 26.0 KB, free 365.1 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:54571 (size: 26.0 KB, free: 366.0 MB)
17/12/14 12:00:47 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[161] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
17/12/14 12:00:47 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 6177 bytes)
17/12/14 12:00:47 INFO Executor: Running task 0.0 in stage 97.0 (TID 90)
17/12/14 12:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:47 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120047_0097_m_000000_90' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/metadata/_temporary/0/task_20171214120047_0097_m_000000
17/12/14 12:00:47 INFO SparkHadoopMapRedUtil: attempt_20171214120047_0097_m_000000_90: Committed
17/12/14 12:00:47 INFO Executor: Finished task 0.0 in stage 97.0 (TID 90). 1003 bytes result sent to driver
17/12/14 12:00:47 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 90) in 116 ms on localhost (executor driver) (1/1)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
17/12/14 12:00:47 INFO DAGScheduler: ResultStage 97 (saveAsTextFile at ReadWrite.scala:275) finished in 0.116 s
17/12/14 12:00:47 INFO DAGScheduler: Job 72 finished: saveAsTextFile at ReadWrite.scala:275, took 0.133185 s
17/12/14 12:00:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:47 INFO CodeGenerator: Code generated in 4.741348 ms
17/12/14 12:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:47 INFO SparkContext: Starting job: parquet at RFormula.scala:399
17/12/14 12:00:47 INFO DAGScheduler: Registering RDD 164 (parquet at RFormula.scala:399)
17/12/14 12:00:47 INFO DAGScheduler: Got job 73 (parquet at RFormula.scala:399) with 1 output partitions
17/12/14 12:00:47 INFO DAGScheduler: Final stage: ResultStage 99 (parquet at RFormula.scala:399)
17/12/14 12:00:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
17/12/14 12:00:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 98)
17/12/14 12:00:47 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[164] at parquet at RFormula.scala:399), which has no missing parents
17/12/14 12:00:47 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 4.8 KB, free 365.1 MB)
17/12/14 12:00:47 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 2.9 KB, free 365.1 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:54571 (size: 2.9 KB, free: 366.0 MB)
17/12/14 12:00:47 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[164] at parquet at RFormula.scala:399)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
17/12/14 12:00:47 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 6229 bytes)
17/12/14 12:00:47 INFO Executor: Running task 0.0 in stage 98.0 (TID 91)
17/12/14 12:00:47 INFO Executor: Finished task 0.0 in stage 98.0 (TID 91). 1385 bytes result sent to driver
17/12/14 12:00:47 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 91) in 11 ms on localhost (executor driver) (1/1)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
17/12/14 12:00:47 INFO DAGScheduler: ShuffleMapStage 98 (parquet at RFormula.scala:399) finished in 0.011 s
17/12/14 12:00:47 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:47 INFO DAGScheduler: running: Set()
17/12/14 12:00:47 INFO DAGScheduler: waiting: Set(ResultStage 99)
17/12/14 12:00:47 INFO DAGScheduler: failed: Set()
17/12/14 12:00:47 INFO DAGScheduler: Submitting ResultStage 99 (ShuffledRowRDD[165] at parquet at RFormula.scala:399), which has no missing parents
17/12/14 12:00:47 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 77.0 KB, free 365.0 MB)
17/12/14 12:00:47 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 28.6 KB, free 365.0 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:54571 (size: 28.6 KB, free: 366.0 MB)
17/12/14 12:00:47 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (ShuffledRowRDD[165] at parquet at RFormula.scala:399)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
17/12/14 12:00:47 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 92, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/14 12:00:47 INFO Executor: Running task 0.0 in stage 99.0 (TID 92)
17/12/14 12:00:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
17/12/14 12:00:47 INFO CodecPool: Got brand-new compressor [.snappy]
17/12/14 12:00:47 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120047_0099_m_000000_0' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/data/_temporary/0/task_20171214120047_0099_m_000000
17/12/14 12:00:47 INFO SparkHadoopMapRedUtil: attempt_20171214120047_0099_m_000000_0: Committed
17/12/14 12:00:47 INFO Executor: Finished task 0.0 in stage 99.0 (TID 92). 1766 bytes result sent to driver
17/12/14 12:00:47 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 92) in 114 ms on localhost (executor driver) (1/1)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
17/12/14 12:00:47 INFO DAGScheduler: ResultStage 99 (parquet at RFormula.scala:399) finished in 0.115 s
17/12/14 12:00:47 INFO DAGScheduler: Job 73 finished: parquet at RFormula.scala:399, took 0.141840 s
17/12/14 12:00:47 INFO FileFormatWriter: Job null committed.
17/12/14 12:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:54571 in memory (size: 28.6 KB, free: 366.0 MB)
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 3803
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:54571 in memory (size: 2.9 KB, free: 366.0 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:54571 in memory (size: 28.7 KB, free: 366.1 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:54571 in memory (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 4048
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:54571 in memory (size: 26.0 KB, free: 366.1 MB)
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 4194
17/12/14 12:00:47 INFO ContextCleaner: Cleaned shuffle 7
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:54571 in memory (size: 2.9 KB, free: 366.1 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:54571 in memory (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 3805
17/12/14 12:00:47 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:00:47 INFO ContextCleaner: Cleaned shuffle 5
17/12/14 12:00:47 INFO ContextCleaner: Cleaned shuffle 6
17/12/14 12:00:47 INFO DAGScheduler: Got job 74 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:00:47 INFO DAGScheduler: Final stage: ResultStage 100 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:47 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:54571 in memory (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:00:47 INFO DAGScheduler: Missing parents: List()
17/12/14 12:00:47 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[168] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:54571 in memory (size: 2.9 KB, free: 366.2 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:54571 in memory (size: 28.7 KB, free: 366.2 MB)
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 3804
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:54571 in memory (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 4046
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 4047
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 4193
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:54571 in memory (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:54571 in memory (size: 25.9 KB, free: 366.3 MB)
17/12/14 12:00:47 INFO ContextCleaner: Cleaned accumulator 4195
17/12/14 12:00:47 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 72.1 KB, free 365.9 MB)
17/12/14 12:00:47 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.9 MB)
17/12/14 12:00:47 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:54571 (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:00:47 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[168] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
17/12/14 12:00:47 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
17/12/14 12:00:47 INFO Executor: Running task 0.0 in stage 100.0 (TID 93)
17/12/14 12:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:47 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120047_0100_m_000000_93' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/metadata/_temporary/0/task_20171214120047_0100_m_000000
17/12/14 12:00:47 INFO SparkHadoopMapRedUtil: attempt_20171214120047_0100_m_000000_93: Committed
17/12/14 12:00:47 INFO Executor: Finished task 0.0 in stage 100.0 (TID 93). 1003 bytes result sent to driver
17/12/14 12:00:47 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 93) in 111 ms on localhost (executor driver) (1/1)
17/12/14 12:00:47 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
17/12/14 12:00:47 INFO DAGScheduler: ResultStage 100 (saveAsTextFile at ReadWrite.scala:275) finished in 0.111 s
17/12/14 12:00:47 INFO DAGScheduler: Job 74 finished: saveAsTextFile at ReadWrite.scala:275, took 0.124353 s
17/12/14 12:00:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:48 INFO CodeGenerator: Code generated in 12.561331 ms
17/12/14 12:00:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:48 INFO SparkContext: Starting job: parquet at LogisticRegression.scala:965
17/12/14 12:00:48 INFO DAGScheduler: Registering RDD 171 (parquet at LogisticRegression.scala:965)
17/12/14 12:00:48 INFO DAGScheduler: Got job 75 (parquet at LogisticRegression.scala:965) with 1 output partitions
17/12/14 12:00:48 INFO DAGScheduler: Final stage: ResultStage 102 (parquet at LogisticRegression.scala:965)
17/12/14 12:00:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
17/12/14 12:00:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 101)
17/12/14 12:00:48 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[171] at parquet at LogisticRegression.scala:965), which has no missing parents
17/12/14 12:00:48 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 5.1 KB, free 365.9 MB)
17/12/14 12:00:48 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 3.0 KB, free 365.9 MB)
17/12/14 12:00:48 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:54571 (size: 3.0 KB, free: 366.2 MB)
17/12/14 12:00:48 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[171] at parquet at LogisticRegression.scala:965)
17/12/14 12:00:48 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
17/12/14 12:00:48 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 6413 bytes)
17/12/14 12:00:48 INFO Executor: Running task 0.0 in stage 101.0 (TID 94)
17/12/14 12:00:48 INFO Executor: Finished task 0.0 in stage 101.0 (TID 94). 1464 bytes result sent to driver
17/12/14 12:00:48 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 94) in 12 ms on localhost (executor driver) (1/1)
17/12/14 12:00:48 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
17/12/14 12:00:48 INFO DAGScheduler: ShuffleMapStage 101 (parquet at LogisticRegression.scala:965) finished in 0.012 s
17/12/14 12:00:48 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:00:48 INFO DAGScheduler: running: Set()
17/12/14 12:00:48 INFO DAGScheduler: waiting: Set(ResultStage 102)
17/12/14 12:00:48 INFO DAGScheduler: failed: Set()
17/12/14 12:00:48 INFO DAGScheduler: Submitting ResultStage 102 (ShuffledRowRDD[172] at parquet at LogisticRegression.scala:965), which has no missing parents
17/12/14 12:00:48 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 78.7 KB, free 365.8 MB)
17/12/14 12:00:48 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 29.1 KB, free 365.8 MB)
17/12/14 12:00:48 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:54571 (size: 29.1 KB, free: 366.2 MB)
17/12/14 12:00:48 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:996
17/12/14 12:00:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (ShuffledRowRDD[172] at parquet at LogisticRegression.scala:965)
17/12/14 12:00:48 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
17/12/14 12:00:48 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 95, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/14 12:00:48 INFO Executor: Running task 0.0 in stage 102.0 (TID 95)
17/12/14 12:00:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:00:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:00:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:00:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:00:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "numClasses",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "numFeatures",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "interceptVector",
    "type" : {
      "type" : "udt",
      "class" : "org.apache.spark.ml.linalg.VectorUDT",
      "pyClass" : "pyspark.ml.linalg.VectorUDT",
      "sqlType" : {
        "type" : "struct",
        "fields" : [ {
          "name" : "type",
          "type" : "byte",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "size",
          "type" : "integer",
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "indices",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "values",
          "type" : {
            "type" : "array",
            "elementType" : "double",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        } ]
      }
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "coefficientMatrix",
    "type" : {
      "type" : "udt",
      "class" : "org.apache.spark.ml.linalg.MatrixUDT",
      "pyClass" : "pyspark.ml.linalg.MatrixUDT",
      "sqlType" : {
        "type" : "struct",
        "fields" : [ {
          "name" : "type",
          "type" : "byte",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "numRows",
          "type" : "integer",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "numCols",
          "type" : "integer",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "colPtrs",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "rowIndices",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "values",
          "type" : {
            "type" : "array",
            "elementType" : "double",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "isTransposed",
          "type" : "boolean",
          "nullable" : false,
          "metadata" : { }
        } ]
      }
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isMultinomial",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

       
17/12/14 12:00:48 INFO CodecPool: Got brand-new compressor [.snappy]
17/12/14 12:00:48 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120048_0102_m_000000_0' to file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/data/_temporary/0/task_20171214120048_0102_m_000000
17/12/14 12:00:48 INFO SparkHadoopMapRedUtil: attempt_20171214120048_0102_m_000000_0: Committed
17/12/14 12:00:48 INFO Executor: Finished task 0.0 in stage 102.0 (TID 95). 1845 bytes result sent to driver
17/12/14 12:00:48 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 95) in 144 ms on localhost (executor driver) (1/1)
17/12/14 12:00:48 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
17/12/14 12:00:48 INFO DAGScheduler: ResultStage 102 (parquet at LogisticRegression.scala:965) finished in 0.144 s
17/12/14 12:00:48 INFO DAGScheduler: Job 75 finished: parquet at LogisticRegression.scala:965, took 0.174799 s
17/12/14 12:00:48 INFO FileFormatWriter: Job null committed.
17/12/14 12:00:48 INFO SparkContext: Invoking stop() from shutdown hook
17/12/14 12:00:48 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/14 12:00:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/14 12:00:48 INFO MemoryStore: MemoryStore cleared
17/12/14 12:00:48 INFO BlockManager: BlockManager stopped
17/12/14 12:00:48 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/14 12:00:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/14 12:00:48 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a\userFiles-a31c2f61-890d-4450-9230-6049fb3c8370
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a\userFiles-a31c2f61-890d-4450-9230-6049fb3c8370
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:00:48 INFO SparkContext: Successfully stopped SparkContext
17/12/14 12:00:48 INFO ShutdownHookManager: Shutdown hook called
17/12/14 12:00:48 INFO ShutdownHookManager: Deleting directory C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a\userFiles-a31c2f61-890d-4450-9230-6049fb3c8370
17/12/14 12:00:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a\userFiles-a31c2f61-890d-4450-9230-6049fb3c8370
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a\userFiles-a31c2f61-890d-4450-9230-6049fb3c8370
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:00:48 INFO ShutdownHookManager: Deleting directory C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a
17/12/14 12:00:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-73be84ad-e2ea-42de-a499-a939a4c0355a
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:00:52 INFO SparkContext: Running Spark version 2.1.0
17/12/14 12:00:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/14 12:00:53 INFO SecurityManager: Changing view acls to: edgar
17/12/14 12:00:53 INFO SecurityManager: Changing modify acls to: edgar
17/12/14 12:00:53 INFO SecurityManager: Changing view acls groups to: 
17/12/14 12:00:53 INFO SecurityManager: Changing modify acls groups to: 
17/12/14 12:00:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(edgar); groups with view permissions: Set(); users  with modify permissions: Set(edgar); groups with modify permissions: Set()
17/12/14 12:00:53 INFO Utils: Successfully started service 'sparkDriver' on port 54634.
17/12/14 12:00:53 INFO SparkEnv: Registering MapOutputTracker
17/12/14 12:00:53 INFO SparkEnv: Registering BlockManagerMaster
17/12/14 12:00:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/14 12:00:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/14 12:00:53 INFO DiskBlockManager: Created local directory at C:\Users\edgar\AppData\Local\Temp\blockmgr-ab5d4326-ee16-4cb1-bc5f-5cb30f594c6a
17/12/14 12:00:53 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/12/14 12:00:53 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/14 12:00:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/14 12:00:53 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/14 12:00:53 INFO SparkContext: Added JAR file:/C:/Users/edgar/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:54634/jars/sparklyr-2.1-2.11.jar with timestamp 1513274453457
17/12/14 12:00:53 INFO Executor: Starting executor ID driver on host localhost
17/12/14 12:00:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54675.
17/12/14 12:00:53 INFO NettyBlockTransferService: Server created on 127.0.0.1:54675
17/12/14 12:00:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/14 12:00:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54675, None)
17/12/14 12:00:53 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54675 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54675, None)
17/12/14 12:00:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54675, None)
17/12/14 12:00:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54675, None)
17/12/14 12:00:53 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/14 12:00:53 INFO SharedState: Warehouse path is 'C:UsersedgarAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/14 12:00:53 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/14 12:00:54 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/14 12:00:54 INFO ObjectStore: ObjectStore, initialize called
17/12/14 12:00:54 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/14 12:00:54 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/14 12:00:55 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/14 12:00:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:56 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/14 12:00:56 INFO ObjectStore: Initialized ObjectStore
17/12/14 12:00:56 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/14 12:00:56 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/14 12:00:57 INFO HiveMetaStore: Added admin role in metastore
17/12/14 12:00:57 INFO HiveMetaStore: Added public role in metastore
17/12/14 12:00:57 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/14 12:00:57 INFO HiveMetaStore: 0: get_all_databases
17/12/14 12:00:57 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/14 12:00:57 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/14 12:00:57 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/14 12:00:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:00:57 INFO SessionState: Created local directory: C:/Users/edgar/AppData/Local/Temp/f76dbf55-e68b-4b03-bef0-f502325f4409_resources
17/12/14 12:00:57 INFO SessionState: Created HDFS directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/edgar/f76dbf55-e68b-4b03-bef0-f502325f4409
17/12/14 12:00:57 INFO SessionState: Created local directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/f76dbf55-e68b-4b03-bef0-f502325f4409
17/12/14 12:00:57 INFO SessionState: Created HDFS directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/edgar/f76dbf55-e68b-4b03-bef0-f502325f4409/_tmp_space.db
17/12/14 12:00:57 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersedgarAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/14 12:00:57 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:57 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:57 INFO HiveMetaStore: 0: get_database: global_temp
17/12/14 12:00:57 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/14 12:00:57 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/14 12:00:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:00:59 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:59 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:59 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:00:59 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:00:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:00:59 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:00:59 INFO CodeGenerator: Code generated in 212.32732 ms
17/12/14 12:01:00 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/14 12:01:00 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/14 12:01:00 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/14 12:01:00 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:00 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:00 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
17/12/14 12:01:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/12/14 12:01:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/12/14 12:01:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54675 (size: 4.6 KB, free: 366.3 MB)
17/12/14 12:01:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
17/12/14 12:01:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/14 12:01:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/14 12:01:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/14 12:01:00 INFO Executor: Fetching spark://127.0.0.1:54634/jars/sparklyr-2.1-2.11.jar with timestamp 1513274453457
17/12/14 12:01:00 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54634 after 11 ms (0 ms spent in bootstraps)
17/12/14 12:01:00 INFO Utils: Fetching spark://127.0.0.1:54634/jars/sparklyr-2.1-2.11.jar to C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3\userFiles-e909ba03-7d27-477d-9332-5939cfca316d\fetchFileTemp2914651051094933840.tmp
17/12/14 12:01:00 INFO Executor: Adding file:/C:/Users/edgar/AppData/Local/Temp/spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3/userFiles-e909ba03-7d27-477d-9332-5939cfca316d/sparklyr-2.1-2.11.jar to class loader
17/12/14 12:01:00 INFO CodeGenerator: Code generated in 10.129308 ms
17/12/14 12:01:00 INFO CodeGenerator: Code generated in 9.201845 ms
17/12/14 12:01:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/12/14 12:01:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 303 ms on localhost (executor driver) (1/1)
17/12/14 12:01:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/14 12:01:00 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.319 s
17/12/14 12:01:00 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.456213 s
17/12/14 12:01:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:00 INFO SparkSqlParser: Parsing command: mtcars
17/12/14 12:01:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:00 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
17/12/14 12:01:00 INFO SparkSqlParser: Parsing command: `mtcars`
17/12/14 12:01:00 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:01:00 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:01:00 INFO FileSourceStrategy: Output Data Schema: struct<mpg: double, cyl: double, disp: double, hp: double, drat: double ... 9 more fields>
17/12/14 12:01:00 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:01:00 INFO CodeGenerator: Code generated in 6.79968 ms
17/12/14 12:01:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/12/14 12:01:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/12/14 12:01:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54675 (size: 23.9 KB, free: 366.3 MB)
17/12/14 12:01:00 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/14 12:01:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:01:01 INFO CodeGenerator: Code generated in 8.916329 ms
17/12/14 12:01:01 INFO CodeGenerator: Code generated in 7.108057 ms
17/12/14 12:01:01 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/14 12:01:01 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
17/12/14 12:01:01 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/14 12:01:01 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
17/12/14 12:01:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/12/14 12:01:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/12/14 12:01:01 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 23.2 KB, free 366.0 MB)
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/12/14 12:01:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54675 (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:01:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/14 12:01:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/14 12:01:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/14 12:01:01 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/AppData/Local/Temp/RtmpSmNnJO/spark_serialize_600df8759318fe0d3e7cd227dfb889264b9395236a2336b9c1d32f83ed509279.csv, range: 0-1336, partition values: [empty row]
17/12/14 12:01:01 INFO CodeGenerator: Code generated in 10.743262 ms
17/12/14 12:01:01 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 4.2 KB, free 365.9 MB)
17/12/14 12:01:01 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:54675 (size: 4.2 KB, free: 366.3 MB)
17/12/14 12:01:01 INFO CodeGenerator: Code generated in 3.668328 ms
17/12/14 12:01:01 INFO CodeGenerator: Code generated in 15.38384 ms
17/12/14 12:01:01 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:54675 in memory (size: 4.6 KB, free: 366.3 MB)
17/12/14 12:01:01 INFO ContextCleaner: Cleaned accumulator 54
17/12/14 12:01:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2980 bytes result sent to driver
17/12/14 12:01:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 208 ms on localhost (executor driver) (1/1)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/14 12:01:01 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.209 s
17/12/14 12:01:01 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:01:01 INFO DAGScheduler: running: Set()
17/12/14 12:01:01 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/12/14 12:01:01 INFO DAGScheduler: failed: Set()
17/12/14 12:01:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/12/14 12:01:01 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54675 (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:01:01 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/12/14 12:01:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/14 12:01:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/14 12:01:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:01:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/12/14 12:01:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1952 bytes result sent to driver
17/12/14 12:01:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on localhost (executor driver) (1/1)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/14 12:01:01 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.027 s
17/12/14 12:01:01 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.281682 s
17/12/14 12:01:01 INFO CodeGenerator: Code generated in 4.845851 ms
17/12/14 12:01:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:01 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
17/12/14 12:01:01 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:01:01 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:210)
17/12/14 12:01:01 INFO DAGScheduler: Got job 2 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:01:01 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:210)
17/12/14 12:01:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/12/14 12:01:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/12/14 12:01:01 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210), which has no missing parents
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 23.2 KB, free 365.9 MB)
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/12/14 12:01:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54675 (size: 11.0 KB, free: 366.2 MB)
17/12/14 12:01:01 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/14 12:01:01 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/12/14 12:01:01 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/12/14 12:01:01 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:01:01 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2098 bytes result sent to driver
17/12/14 12:01:01 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 17 ms on localhost (executor driver) (1/1)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/14 12:01:01 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:210) finished in 0.018 s
17/12/14 12:01:01 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:01:01 INFO DAGScheduler: running: Set()
17/12/14 12:01:01 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/12/14 12:01:01 INFO DAGScheduler: failed: Set()
17/12/14 12:01:01 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210), which has no missing parents
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/12/14 12:01:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54675 (size: 3.7 KB, free: 366.2 MB)
17/12/14 12:01:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/12/14 12:01:01 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/14 12:01:01 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/12/14 12:01:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:01:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:01:01 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1963 bytes result sent to driver
17/12/14 12:01:01 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/12/14 12:01:01 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:210) finished in 0.006 s
17/12/14 12:01:01 INFO DAGScheduler: Job 2 finished: collect at utils.scala:210, took 0.040000 s
17/12/14 12:01:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz6`
WHERE (0 = 1)
17/12/14 12:01:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:01:01 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:01:01 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:01:01 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:01:01 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:01:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:01:01 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:01:01 INFO CodeGenerator: Code generated in 8.929392 ms
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 238.6 KB, free 365.7 MB)
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.6 MB)
17/12/14 12:01:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:01 INFO SparkContext: Created broadcast 6 from textFile at ReadWrite.scala:379
17/12/14 12:01:01 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:01 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:01 INFO DAGScheduler: Got job 3 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:01 INFO DAGScheduler: Final stage: ResultStage 5 (first at ReadWrite.scala:379)
17/12/14 12:01:01 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:01 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:01 INFO DAGScheduler: Submitting ResultStage 5 (C:/Users/edgar/Documents/ml_pipeline/new_model/metadata MapPartitionsRDD[25] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.3 KB, free 365.6 MB)
17/12/14 12:01:01 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1993.0 B, free 365.6 MB)
17/12/14 12:01:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54675 (size: 1993.0 B, free: 366.2 MB)
17/12/14 12:01:01 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (C:/Users/edgar/Documents/ml_pipeline/new_model/metadata MapPartitionsRDD[25] at textFile at ReadWrite.scala:379)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/12/14 12:01:01 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6079 bytes)
17/12/14 12:01:01 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/14 12:01:01 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/metadata/part-00000:0+237
17/12/14 12:01:01 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/12/14 12:01:01 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/12/14 12:01:01 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/12/14 12:01:01 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/12/14 12:01:01 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/12/14 12:01:01 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1324 bytes result sent to driver
17/12/14 12:01:01 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 24 ms on localhost (executor driver) (1/1)
17/12/14 12:01:01 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/14 12:01:01 INFO DAGScheduler: ResultStage 5 (first at ReadWrite.scala:379) finished in 0.025 s
17/12/14 12:01:01 INFO DAGScheduler: Job 3 finished: first at ReadWrite.scala:379, took 0.031649 s
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 1
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 0
17/12/14 12:01:02 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54675 in memory (size: 11.0 KB, free: 366.2 MB)
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 55
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 56
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 57
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 58
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 59
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 60
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 61
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 62
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 63
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 64
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 65
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 66
17/12/14 12:01:02 INFO ContextCleaner: Cleaned shuffle 0
17/12/14 12:01:02 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:54675 in memory (size: 11.0 KB, free: 366.2 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:54675 in memory (size: 3.7 KB, free: 366.2 MB)
17/12/14 12:01:02 INFO ContextCleaner: Cleaned accumulator 163
17/12/14 12:01:02 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:54675 in memory (size: 3.7 KB, free: 366.2 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.3 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54675 in memory (size: 1993.0 B, free: 366.3 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 238.7 KB, free 365.8 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.7 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 8 from textFile at ReadWrite.scala:379
17/12/14 12:01:02 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:02 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:02 INFO DAGScheduler: Got job 4 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:02 INFO DAGScheduler: Final stage: ResultStage 6 (first at ReadWrite.scala:379)
17/12/14 12:01:02 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:02 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:02 INFO DAGScheduler: Submitting ResultStage 6 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/0_binarizer_22b832a93f9d/metadata MapPartitionsRDD[27] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.3 KB, free 365.7 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 2025.0 B, free 365.7 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54675 (size: 2025.0 B, free: 366.2 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/0_binarizer_22b832a93f9d/metadata MapPartitionsRDD[27] at textFile at ReadWrite.scala:379)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/14 12:01:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6111 bytes)
17/12/14 12:01:02 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
17/12/14 12:01:02 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/0_binarizer_22b832a93f9d/metadata/part-00000:0+199
17/12/14 12:01:02 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1117 bytes result sent to driver
17/12/14 12:01:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/14 12:01:02 INFO DAGScheduler: ResultStage 6 (first at ReadWrite.scala:379) finished in 0.008 s
17/12/14 12:01:02 INFO DAGScheduler: Job 4 finished: first at ReadWrite.scala:379, took 0.011783 s
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 238.7 KB, free 365.5 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.5 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 10 from textFile at ReadWrite.scala:379
17/12/14 12:01:02 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:02 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:02 INFO DAGScheduler: Got job 5 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:02 INFO DAGScheduler: Final stage: ResultStage 7 (first at ReadWrite.scala:379)
17/12/14 12:01:02 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:02 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:02 INFO DAGScheduler: Submitting ResultStage 7 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/0_binarizer_22b832a93f9d/metadata MapPartitionsRDD[29] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.3 KB, free 365.5 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2026.0 B, free 365.5 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54675 (size: 2026.0 B, free: 366.2 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/0_binarizer_22b832a93f9d/metadata MapPartitionsRDD[29] at textFile at ReadWrite.scala:379)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/12/14 12:01:02 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6111 bytes)
17/12/14 12:01:02 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
17/12/14 12:01:02 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/0_binarizer_22b832a93f9d/metadata/part-00000:0+199
17/12/14 12:01:02 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1117 bytes result sent to driver
17/12/14 12:01:02 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/12/14 12:01:02 INFO DAGScheduler: ResultStage 7 (first at ReadWrite.scala:379) finished in 0.006 s
17/12/14 12:01:02 INFO DAGScheduler: Job 5 finished: first at ReadWrite.scala:379, took 0.009757 s
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 238.7 KB, free 365.2 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.2 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 12 from textFile at ReadWrite.scala:379
17/12/14 12:01:02 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:02 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:02 INFO DAGScheduler: Got job 6 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:02 INFO DAGScheduler: Final stage: ResultStage 8 (first at ReadWrite.scala:379)
17/12/14 12:01:02 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:02 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:02 INFO DAGScheduler: Submitting ResultStage 8 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/metadata MapPartitionsRDD[31] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.3 KB, free 365.2 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2025.0 B, free 365.2 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54675 (size: 2025.0 B, free: 366.2 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/metadata MapPartitionsRDD[31] at textFile at ReadWrite.scala:379)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/14 12:01:02 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6111 bytes)
17/12/14 12:01:02 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/14 12:01:02 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/metadata/part-00000:0+191
17/12/14 12:01:02 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1109 bytes result sent to driver
17/12/14 12:01:02 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/14 12:01:02 INFO DAGScheduler: ResultStage 8 (first at ReadWrite.scala:379) finished in 0.006 s
17/12/14 12:01:02 INFO DAGScheduler: Job 6 finished: first at ReadWrite.scala:379, took 0.011649 s
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 238.7 KB, free 365.0 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.9 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 14 from textFile at ReadWrite.scala:379
17/12/14 12:01:02 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:02 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:02 INFO DAGScheduler: Got job 7 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:02 INFO DAGScheduler: Final stage: ResultStage 9 (first at ReadWrite.scala:379)
17/12/14 12:01:02 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:02 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:02 INFO DAGScheduler: Submitting ResultStage 9 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/metadata MapPartitionsRDD[33] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.3 KB, free 364.9 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2024.0 B, free 364.9 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54675 (size: 2024.0 B, free: 366.2 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/metadata MapPartitionsRDD[33] at textFile at ReadWrite.scala:379)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/12/14 12:01:02 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6111 bytes)
17/12/14 12:01:02 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
17/12/14 12:01:02 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/metadata/part-00000:0+191
17/12/14 12:01:02 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1109 bytes result sent to driver
17/12/14 12:01:02 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/12/14 12:01:02 INFO DAGScheduler: ResultStage 9 (first at ReadWrite.scala:379) finished in 0.007 s
17/12/14 12:01:02 INFO DAGScheduler: Job 7 finished: first at ReadWrite.scala:379, took 0.011483 s
17/12/14 12:01:02 INFO SparkContext: Starting job: parquet at RFormula.scala:341
17/12/14 12:01:02 INFO DAGScheduler: Got job 8 (parquet at RFormula.scala:341) with 1 output partitions
17/12/14 12:01:02 INFO DAGScheduler: Final stage: ResultStage 10 (parquet at RFormula.scala:341)
17/12/14 12:01:02 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:02 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:02 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[35] at parquet at RFormula.scala:341), which has no missing parents
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.3 KB, free 364.9 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.4 KB, free 364.8 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54675 (size: 25.4 KB, free: 366.1 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at parquet at RFormula.scala:341)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/14 12:01:02 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6268 bytes)
17/12/14 12:01:02 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
17/12/14 12:01:02 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1990 bytes result sent to driver
17/12/14 12:01:02 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 90 ms on localhost (executor driver) (1/1)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/14 12:01:02 INFO DAGScheduler: ResultStage 10 (parquet at RFormula.scala:341) finished in 0.090 s
17/12/14 12:01:02 INFO DAGScheduler: Job 8 finished: parquet at RFormula.scala:341, took 0.108912 s
17/12/14 12:01:02 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:01:02 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:01:02 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
17/12/14 12:01:02 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:01:02 INFO CodeGenerator: Code generated in 14.389664 ms
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 284.0 KB, free 364.6 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 24.7 KB, free 364.5 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54675 (size: 24.7 KB, free: 366.1 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 17 from head at RFormula.scala:341
17/12/14 12:01:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:01:02 INFO SparkContext: Starting job: head at RFormula.scala:341
17/12/14 12:01:02 INFO DAGScheduler: Got job 9 (head at RFormula.scala:341) with 1 output partitions
17/12/14 12:01:02 INFO DAGScheduler: Final stage: ResultStage 11 (head at RFormula.scala:341)
17/12/14 12:01:02 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:02 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:02 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[38] at head at RFormula.scala:341), which has no missing parents
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 9.8 KB, free 364.5 MB)
17/12/14 12:01:02 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.7 KB, free 364.5 MB)
17/12/14 12:01:02 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54675 (size: 4.7 KB, free: 366.1 MB)
17/12/14 12:01:02 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[38] at head at RFormula.scala:341)
17/12/14 12:01:02 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/12/14 12:01:02 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6611 bytes)
17/12/14 12:01:02 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/12/14 12:01:02 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/data/part-00000-8c7c7f43-5650-4b1e-a388-17faafc6b3b4.snappy.parquet, range: 0-914, partition values: [empty row]
17/12/14 12:01:02 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
17/12/14 12:01:03 INFO CodeGenerator: Code generated in 10.058396 ms
17/12/14 12:01:03 INFO CodecPool: Got brand-new decompressor [.snappy]
17/12/14 12:01:03 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1418 bytes result sent to driver
17/12/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 208 ms on localhost (executor driver) (1/1)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/12/14 12:01:03 INFO DAGScheduler: ResultStage 11 (head at RFormula.scala:341) finished in 0.209 s
17/12/14 12:01:03 INFO DAGScheduler: Job 9 finished: head at RFormula.scala:341, took 0.216744 s
17/12/14 12:01:03 INFO CodeGenerator: Code generated in 17.066616 ms
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 238.7 KB, free 364.3 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.3 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 19 from textFile at ReadWrite.scala:379
17/12/14 12:01:03 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:03 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:03 INFO DAGScheduler: Got job 10 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:03 INFO DAGScheduler: Final stage: ResultStage 12 (first at ReadWrite.scala:379)
17/12/14 12:01:03 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:03 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:03 INFO DAGScheduler: Submitting ResultStage 12 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/metadata MapPartitionsRDD[40] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.3 KB, free 364.3 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 2030.0 B, free 364.3 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:54675 (size: 2030.0 B, free: 366.1 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/metadata MapPartitionsRDD[40] at textFile at ReadWrite.scala:379)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6125 bytes)
17/12/14 12:01:03 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/12/14 12:01:03 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/metadata/part-00000:0+240
17/12/14 12:01:03 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1161 bytes result sent to driver
17/12/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/14 12:01:03 INFO DAGScheduler: ResultStage 12 (first at ReadWrite.scala:379) finished in 0.007 s
17/12/14 12:01:03 INFO DAGScheduler: Job 10 finished: first at ReadWrite.scala:379, took 0.010732 s
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 238.7 KB, free 364.0 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.0 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 21 from textFile at ReadWrite.scala:379
17/12/14 12:01:03 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:03 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:03 INFO DAGScheduler: Got job 11 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:03 INFO DAGScheduler: Final stage: ResultStage 13 (first at ReadWrite.scala:379)
17/12/14 12:01:03 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:03 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:03 INFO DAGScheduler: Submitting ResultStage 13 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/0_r_formula_22b821e83bb4/metadata MapPartitionsRDD[42] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 3.3 KB, free 364.0 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 2035.0 B, free 364.0 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:54675 (size: 2035.0 B, free: 366.1 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/0_r_formula_22b821e83bb4/metadata MapPartitionsRDD[42] at textFile at ReadWrite.scala:379)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/12/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6158 bytes)
17/12/14 12:01:03 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/12/14 12:01:03 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/0_r_formula_22b821e83bb4/metadata/part-00000:0+197
17/12/14 12:01:03 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1115 bytes result sent to driver
17/12/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/12/14 12:01:03 INFO DAGScheduler: ResultStage 13 (first at ReadWrite.scala:379) finished in 0.006 s
17/12/14 12:01:03 INFO DAGScheduler: Job 11 finished: first at ReadWrite.scala:379, took 0.009716 s
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 238.7 KB, free 363.8 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.3 KB, free 363.8 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 23 from textFile at ReadWrite.scala:379
17/12/14 12:01:03 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:03 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:03 INFO DAGScheduler: Got job 12 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:03 INFO DAGScheduler: Final stage: ResultStage 14 (first at ReadWrite.scala:379)
17/12/14 12:01:03 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:03 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:03 INFO DAGScheduler: Submitting ResultStage 14 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/0_r_formula_22b821e83bb4/metadata MapPartitionsRDD[44] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 3.3 KB, free 363.8 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 2035.0 B, free 363.7 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:54675 (size: 2035.0 B, free: 366.0 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/0_r_formula_22b821e83bb4/metadata MapPartitionsRDD[44] at textFile at ReadWrite.scala:379)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6158 bytes)
17/12/14 12:01:03 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
17/12/14 12:01:03 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/0_r_formula_22b821e83bb4/metadata/part-00000:0+197
17/12/14 12:01:03 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1194 bytes result sent to driver
17/12/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/14 12:01:03 INFO DAGScheduler: ResultStage 14 (first at ReadWrite.scala:379) finished in 0.006 s
17/12/14 12:01:03 INFO DAGScheduler: Job 12 finished: first at ReadWrite.scala:379, took 0.010117 s
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 238.7 KB, free 363.5 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 23.3 KB, free 363.5 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 25 from textFile at ReadWrite.scala:379
17/12/14 12:01:03 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:03 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:03 INFO DAGScheduler: Got job 13 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:03 INFO DAGScheduler: Final stage: ResultStage 15 (first at ReadWrite.scala:379)
17/12/14 12:01:03 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:03 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:03 INFO DAGScheduler: Submitting ResultStage 15 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/metadata MapPartitionsRDD[46] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 3.4 KB, free 363.5 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.0 KB, free 363.5 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:54675 (size: 2.0 KB, free: 366.0 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/metadata MapPartitionsRDD[46] at textFile at ReadWrite.scala:379)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/12/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6167 bytes)
17/12/14 12:01:03 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
17/12/14 12:01:03 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/metadata/part-00000:0+167
17/12/14 12:01:03 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1085 bytes result sent to driver
17/12/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/12/14 12:01:03 INFO DAGScheduler: ResultStage 15 (first at ReadWrite.scala:379) finished in 0.005 s
17/12/14 12:01:03 INFO DAGScheduler: Job 13 finished: first at ReadWrite.scala:379, took 0.008508 s
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 238.7 KB, free 363.3 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 23.3 KB, free 363.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 27 from textFile at ReadWrite.scala:379
17/12/14 12:01:03 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:03 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:03 INFO DAGScheduler: Got job 14 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:03 INFO DAGScheduler: Final stage: ResultStage 16 (first at ReadWrite.scala:379)
17/12/14 12:01:03 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:03 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:03 INFO DAGScheduler: Submitting ResultStage 16 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/metadata MapPartitionsRDD[48] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 3.4 KB, free 363.2 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.0 KB, free 363.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:54675 (size: 2.0 KB, free: 366.0 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/metadata MapPartitionsRDD[48] at textFile at ReadWrite.scala:379)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6168 bytes)
17/12/14 12:01:03 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
17/12/14 12:01:03 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/metadata/part-00000:0+167
17/12/14 12:01:03 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1085 bytes result sent to driver
17/12/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/14 12:01:03 INFO DAGScheduler: ResultStage 16 (first at ReadWrite.scala:379) finished in 0.004 s
17/12/14 12:01:03 INFO DAGScheduler: Job 14 finished: first at ReadWrite.scala:379, took 0.008447 s
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:54675 in memory (size: 2024.0 B, free: 366.0 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:54675 in memory (size: 2025.0 B, free: 366.0 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:54675 in memory (size: 2026.0 B, free: 366.0 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:54675 in memory (size: 2025.0 B, free: 366.1 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:54675 in memory (size: 2035.0 B, free: 366.1 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:54675 in memory (size: 2035.0 B, free: 366.1 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:54675 in memory (size: 2.0 KB, free: 366.1 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:54675 in memory (size: 24.7 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:54675 in memory (size: 4.7 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:54675 in memory (size: 2030.0 B, free: 366.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:54675 in memory (size: 2.0 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:54675 in memory (size: 25.4 KB, free: 366.3 MB)
17/12/14 12:01:03 INFO ContextCleaner: Cleaned accumulator 560
17/12/14 12:01:03 INFO ContextCleaner: Cleaned accumulator 561
17/12/14 12:01:03 INFO ContextCleaner: Cleaned accumulator 562
17/12/14 12:01:03 INFO SparkContext: Starting job: parquet at RFormula.scala:503
17/12/14 12:01:03 INFO DAGScheduler: Got job 15 (parquet at RFormula.scala:503) with 1 output partitions
17/12/14 12:01:03 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:503)
17/12/14 12:01:03 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:03 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:03 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[50] at parquet at RFormula.scala:503), which has no missing parents
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 71.3 KB, free 365.9 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 25.4 KB, free 365.9 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:54675 (size: 25.4 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[50] at parquet at RFormula.scala:503)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/12/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6324 bytes)
17/12/14 12:01:03 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
17/12/14 12:01:03 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1668 bytes result sent to driver
17/12/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 11 ms on localhost (executor driver) (1/1)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/12/14 12:01:03 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:503) finished in 0.011 s
17/12/14 12:01:03 INFO DAGScheduler: Job 15 finished: parquet at RFormula.scala:503, took 0.022044 s
17/12/14 12:01:03 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:01:03 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:01:03 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
17/12/14 12:01:03 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:01:03 INFO CodeGenerator: Code generated in 9.865252 ms
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 283.7 KB, free 365.6 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.6 KB, free 365.6 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:54675 (size: 24.6 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 30 from head at RFormula.scala:503
17/12/14 12:01:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:01:03 INFO SparkContext: Starting job: head at RFormula.scala:503
17/12/14 12:01:03 INFO DAGScheduler: Got job 16 (head at RFormula.scala:503) with 1 output partitions
17/12/14 12:01:03 INFO DAGScheduler: Final stage: ResultStage 18 (head at RFormula.scala:503)
17/12/14 12:01:03 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:03 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:03 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[53] at head at RFormula.scala:503), which has no missing parents
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.3 KB, free 365.6 MB)
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 4.8 KB, free 365.6 MB)
17/12/14 12:01:03 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:54675 (size: 4.8 KB, free: 366.2 MB)
17/12/14 12:01:03 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[53] at head at RFormula.scala:503)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 6666 bytes)
17/12/14 12:01:03 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
17/12/14 12:01:03 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/1_vectorAttrRewriter_972b64bf14c9/data/part-00000-1bade327-bf64-4c26-80b0-83808bccf74f.snappy.parquet, range: 0-812, partition values: [empty row]
17/12/14 12:01:03 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
17/12/14 12:01:03 INFO CodeGenerator: Code generated in 7.992132 ms
17/12/14 12:01:03 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1367 bytes result sent to driver
17/12/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 21 ms on localhost (executor driver) (1/1)
17/12/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/14 12:01:03 INFO DAGScheduler: ResultStage 18 (head at RFormula.scala:503) finished in 0.022 s
17/12/14 12:01:03 INFO DAGScheduler: Job 16 finished: head at RFormula.scala:503, took 0.025089 s
17/12/14 12:01:03 INFO CodeGenerator: Code generated in 13.829827 ms
17/12/14 12:01:03 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 238.7 KB, free 365.3 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.3 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 32 from textFile at ReadWrite.scala:379
17/12/14 12:01:04 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:04 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:04 INFO DAGScheduler: Got job 17 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:04 INFO DAGScheduler: Final stage: ResultStage 19 (first at ReadWrite.scala:379)
17/12/14 12:01:04 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:04 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:04 INFO DAGScheduler: Submitting ResultStage 19 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/metadata MapPartitionsRDD[55] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 3.4 KB, free 365.3 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.0 KB, free 365.3 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:54675 (size: 2.0 KB, free: 366.2 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/metadata MapPartitionsRDD[55] at textFile at ReadWrite.scala:379)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/14 12:01:04 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6162 bytes)
17/12/14 12:01:04 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
17/12/14 12:01:04 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/metadata/part-00000:0+150
17/12/14 12:01:04 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1155 bytes result sent to driver
17/12/14 12:01:04 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/14 12:01:04 INFO DAGScheduler: ResultStage 19 (first at ReadWrite.scala:379) finished in 0.004 s
17/12/14 12:01:04 INFO DAGScheduler: Job 17 finished: first at ReadWrite.scala:379, took 0.007723 s
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 238.7 KB, free 365.1 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.1 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 34 from textFile at ReadWrite.scala:379
17/12/14 12:01:04 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:04 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:04 INFO DAGScheduler: Got job 18 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:04 INFO DAGScheduler: Final stage: ResultStage 20 (first at ReadWrite.scala:379)
17/12/14 12:01:04 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:04 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:04 INFO DAGScheduler: Submitting ResultStage 20 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/metadata MapPartitionsRDD[57] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 3.4 KB, free 365.1 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.0 KB, free 365.1 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:54675 (size: 2.0 KB, free: 366.2 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/metadata MapPartitionsRDD[57] at textFile at ReadWrite.scala:379)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/12/14 12:01:04 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 6162 bytes)
17/12/14 12:01:04 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
17/12/14 12:01:04 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/metadata/part-00000:0+150
17/12/14 12:01:04 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1068 bytes result sent to driver
17/12/14 12:01:04 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/12/14 12:01:04 INFO DAGScheduler: ResultStage 20 (first at ReadWrite.scala:379) finished in 0.006 s
17/12/14 12:01:04 INFO DAGScheduler: Job 18 finished: first at ReadWrite.scala:379, took 0.009009 s
17/12/14 12:01:04 INFO SparkContext: Starting job: parquet at RFormula.scala:412
17/12/14 12:01:04 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:412) with 1 output partitions
17/12/14 12:01:04 INFO DAGScheduler: Final stage: ResultStage 21 (parquet at RFormula.scala:412)
17/12/14 12:01:04 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:04 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:04 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[59] at parquet at RFormula.scala:412), which has no missing parents
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 71.3 KB, free 365.0 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 25.4 KB, free 365.0 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:54675 (size: 25.4 KB, free: 366.1 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[59] at parquet at RFormula.scala:412)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/12/14 12:01:04 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6318 bytes)
17/12/14 12:01:04 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
17/12/14 12:01:04 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1604 bytes result sent to driver
17/12/14 12:01:04 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 10 ms on localhost (executor driver) (1/1)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/14 12:01:04 INFO DAGScheduler: ResultStage 21 (parquet at RFormula.scala:412) finished in 0.010 s
17/12/14 12:01:04 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:412, took 0.020907 s
17/12/14 12:01:04 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:01:04 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:01:04 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
17/12/14 12:01:04 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:01:04 INFO CodeGenerator: Code generated in 7.412702 ms
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 283.4 KB, free 364.7 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.5 KB, free 364.7 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:54675 (size: 24.5 KB, free: 366.1 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 37 from head at RFormula.scala:412
17/12/14 12:01:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:01:04 INFO SparkContext: Starting job: head at RFormula.scala:412
17/12/14 12:01:04 INFO DAGScheduler: Got job 20 (head at RFormula.scala:412) with 1 output partitions
17/12/14 12:01:04 INFO DAGScheduler: Final stage: ResultStage 22 (head at RFormula.scala:412)
17/12/14 12:01:04 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:04 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:04 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[62] at head at RFormula.scala:412), which has no missing parents
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 8.2 KB, free 364.7 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.3 KB, free 364.6 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:54675 (size: 4.3 KB, free: 366.1 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[62] at head at RFormula.scala:412)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/12/14 12:01:04 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
17/12/14 12:01:04 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
17/12/14 12:01:04 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/Documents/ml_pipeline/new_model/stages/1_r_formula_22b821e83bb4/pipelineModel/stages/2_columnPruner_3afc4cb373a9/data/part-00000-c555fd52-5722-419a-b41f-8297f6a71e58.snappy.parquet, range: 0-461, partition values: [empty row]
17/12/14 12:01:04 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
17/12/14 12:01:04 INFO CodeGenerator: Code generated in 5.244735 ms
17/12/14 12:01:04 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1351 bytes result sent to driver
17/12/14 12:01:04 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 14 ms on localhost (executor driver) (1/1)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/12/14 12:01:04 INFO DAGScheduler: ResultStage 22 (head at RFormula.scala:412) finished in 0.015 s
17/12/14 12:01:04 INFO DAGScheduler: Job 20 finished: head at RFormula.scala:412, took 0.018279 s
17/12/14 12:01:04 INFO CodeGenerator: Code generated in 8.873409 ms
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 238.7 KB, free 364.4 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.4 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 39 from textFile at ReadWrite.scala:379
17/12/14 12:01:04 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:04 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:04 INFO DAGScheduler: Got job 21 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:04 INFO DAGScheduler: Final stage: ResultStage 23 (first at ReadWrite.scala:379)
17/12/14 12:01:04 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:04 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:04 INFO DAGScheduler: Submitting ResultStage 23 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/metadata MapPartitionsRDD[64] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 3.3 KB, free 364.4 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 2035.0 B, free 364.4 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:54675 (size: 2035.0 B, free: 366.1 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/metadata MapPartitionsRDD[64] at textFile at ReadWrite.scala:379)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/12/14 12:01:04 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6122 bytes)
17/12/14 12:01:04 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
17/12/14 12:01:04 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/metadata/part-00000:0+473
17/12/14 12:01:04 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1394 bytes result sent to driver
17/12/14 12:01:04 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/12/14 12:01:04 INFO DAGScheduler: ResultStage 23 (first at ReadWrite.scala:379) finished in 0.004 s
17/12/14 12:01:04 INFO DAGScheduler: Job 21 finished: first at ReadWrite.scala:379, took 0.006884 s
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 238.7 KB, free 364.2 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.1 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:54675 (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 41 from textFile at ReadWrite.scala:379
17/12/14 12:01:04 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:01:04 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:01:04 INFO DAGScheduler: Got job 22 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:01:04 INFO DAGScheduler: Final stage: ResultStage 24 (first at ReadWrite.scala:379)
17/12/14 12:01:04 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:04 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:04 INFO DAGScheduler: Submitting ResultStage 24 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/metadata MapPartitionsRDD[66] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 3.3 KB, free 364.1 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 2035.0 B, free 364.1 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:54675 (size: 2035.0 B, free: 366.1 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/metadata MapPartitionsRDD[66] at textFile at ReadWrite.scala:379)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/12/14 12:01:04 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6122 bytes)
17/12/14 12:01:04 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
17/12/14 12:01:04 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/metadata/part-00000:0+473
17/12/14 12:01:04 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1394 bytes result sent to driver
17/12/14 12:01:04 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/12/14 12:01:04 INFO DAGScheduler: ResultStage 24 (first at ReadWrite.scala:379) finished in 0.004 s
17/12/14 12:01:04 INFO DAGScheduler: Job 22 finished: first at ReadWrite.scala:379, took 0.007055 s
17/12/14 12:01:04 INFO SparkContext: Starting job: load at LogisticRegression.scala:979
17/12/14 12:01:04 INFO DAGScheduler: Got job 23 (load at LogisticRegression.scala:979) with 1 output partitions
17/12/14 12:01:04 INFO DAGScheduler: Final stage: ResultStage 25 (load at LogisticRegression.scala:979)
17/12/14 12:01:04 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:04 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:04 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[68] at load at LogisticRegression.scala:979), which has no missing parents
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 71.3 KB, free 364.1 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 25.4 KB, free 364.0 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:54675 (size: 25.4 KB, free: 366.0 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[68] at load at LogisticRegression.scala:979)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/12/14 12:01:04 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6279 bytes)
17/12/14 12:01:04 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
17/12/14 12:01:04 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2080 bytes result sent to driver
17/12/14 12:01:04 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 17 ms on localhost (executor driver) (1/1)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/12/14 12:01:04 INFO DAGScheduler: ResultStage 25 (load at LogisticRegression.scala:979) finished in 0.019 s
17/12/14 12:01:04 INFO DAGScheduler: Job 23 finished: load at LogisticRegression.scala:979, took 0.030018 s
17/12/14 12:01:04 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:01:04 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:01:04 INFO FileSourceStrategy: Output Data Schema: struct<numClasses: int, numFeatures: int, interceptVector: vector, coefficientMatrix: matrix, isMultinomial: boolean ... 3 more fields>
17/12/14 12:01:04 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:01:04 INFO CodeGenerator: Code generated in 13.273723 ms
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 289.1 KB, free 363.7 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 25.4 KB, free 363.7 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:54675 (size: 25.4 KB, free: 366.0 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 44 from head at LogisticRegression.scala:997
17/12/14 12:01:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:01:04 INFO SparkContext: Starting job: head at LogisticRegression.scala:997
17/12/14 12:01:04 INFO DAGScheduler: Got job 24 (head at LogisticRegression.scala:997) with 1 output partitions
17/12/14 12:01:04 INFO DAGScheduler: Final stage: ResultStage 26 (head at LogisticRegression.scala:997)
17/12/14 12:01:04 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:04 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:04 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[71] at head at LogisticRegression.scala:997), which has no missing parents
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 17.3 KB, free 363.7 MB)
17/12/14 12:01:04 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 6.2 KB, free 363.7 MB)
17/12/14 12:01:04 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:54675 (size: 6.2 KB, free: 366.0 MB)
17/12/14 12:01:04 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[71] at head at LogisticRegression.scala:997)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/12/14 12:01:04 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
17/12/14 12:01:04 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
17/12/14 12:01:04 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/Documents/ml_pipeline/new_model/stages/2_logistic_regression_22b83a2c52da/data/part-00000-dffbb5fa-d72b-4e1e-846b-f064d1a788c3.snappy.parquet, range: 0-3705, partition values: [empty row]
17/12/14 12:01:04 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

Catalyst form:
StructType(StructField(numClasses,IntegerType,true), StructField(numFeatures,IntegerType,true), StructField(interceptVector,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(coefficientMatrix,org.apache.spark.ml.linalg.MatrixUDT@e59e0c69,true), StructField(isMultinomial,BooleanType,true))
       
17/12/14 12:01:04 INFO CodeGenerator: Code generated in 12.814658 ms
17/12/14 12:01:04 INFO CodeGenerator: Code generated in 9.355334 ms
17/12/14 12:01:04 INFO CodeGenerator: Code generated in 9.41645 ms
17/12/14 12:01:04 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1436 bytes result sent to driver
17/12/14 12:01:04 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 51 ms on localhost (executor driver) (1/1)
17/12/14 12:01:04 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/12/14 12:01:04 INFO DAGScheduler: ResultStage 26 (head at LogisticRegression.scala:997) finished in 0.052 s
17/12/14 12:01:04 INFO DAGScheduler: Job 24 finished: head at LogisticRegression.scala:997, took 0.055888 s
17/12/14 12:01:04 INFO CodeGenerator: Code generated in 8.240327 ms
17/12/14 12:01:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:01:04 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:01:04 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:01:04 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:01:04 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:01:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:01:04 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:01:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars`
17/12/14 12:01:05 INFO SparkSqlParser: Parsing command: sparklyr_tmp_22b83d8c35db
17/12/14 12:01:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b83d8c35db` AS `zzz7`
WHERE (0 = 1)
17/12/14 12:01:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:01:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22b83d8c35db`
LIMIT 25
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 900
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:54675 in memory (size: 4.8 KB, free: 366.0 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:54675 in memory (size: 2.0 KB, free: 366.0 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:54675 in memory (size: 25.4 KB, free: 366.1 MB)
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 1094
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 1096
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:54675 in memory (size: 24.5 KB, free: 366.1 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:54675 in memory (size: 6.2 KB, free: 366.1 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:54675 in memory (size: 25.4 KB, free: 366.1 MB)
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 899
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 901
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:54675 in memory (size: 24.6 KB, free: 366.1 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:54675 in memory (size: 2.0 KB, free: 366.1 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 1095
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:54675 in memory (size: 4.3 KB, free: 366.2 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:54675 in memory (size: 2035.0 B, free: 366.2 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:54675 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:54675 in memory (size: 2035.0 B, free: 366.2 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:54675 in memory (size: 25.4 KB, free: 366.2 MB)
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 1289
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 1290
17/12/14 12:01:05 INFO ContextCleaner: Cleaned accumulator 1291
17/12/14 12:01:05 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:54675 in memory (size: 25.4 KB, free: 366.3 MB)
17/12/14 12:01:05 INFO CodeGenerator: Code generated in 41.447495 ms
17/12/14 12:01:05 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:01:05 INFO DAGScheduler: Got job 25 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:01:05 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:210)
17/12/14 12:01:05 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:01:05 INFO DAGScheduler: Missing parents: List()
17/12/14 12:01:05 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[76] at collect at utils.scala:210), which has no missing parents
17/12/14 12:01:05 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 64.7 KB, free 365.9 MB)
17/12/14 12:01:05 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 22.1 KB, free 365.9 MB)
17/12/14 12:01:05 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:54675 (size: 22.1 KB, free: 366.3 MB)
17/12/14 12:01:05 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
17/12/14 12:01:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[76] at collect at utils.scala:210)
17/12/14 12:01:05 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/12/14 12:01:05 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6594 bytes)
17/12/14 12:01:05 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
17/12/14 12:01:05 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:01:06 INFO CodeGenerator: Code generated in 16.099031 ms
17/12/14 12:01:06 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/12/14 12:01:06 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
17/12/14 12:01:06 WARN Executor: 1 block locks were not released by TID = 27:
[rdd_9_0]
17/12/14 12:01:06 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 3736 bytes result sent to driver
17/12/14 12:01:06 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 64 ms on localhost (executor driver) (1/1)
17/12/14 12:01:06 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/12/14 12:01:06 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:210) finished in 0.065 s
17/12/14 12:01:06 INFO DAGScheduler: Job 25 finished: collect at utils.scala:210, took 0.072678 s
17/12/14 12:01:06 INFO CodeGenerator: Code generated in 12.076607 ms
17/12/14 12:02:06 INFO SparkContext: Invoking stop() from shutdown hook
17/12/14 12:02:06 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/14 12:02:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/14 12:02:06 INFO MemoryStore: MemoryStore cleared
17/12/14 12:02:06 INFO BlockManager: BlockManager stopped
17/12/14 12:02:06 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/14 12:02:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/14 12:02:06 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3\userFiles-e909ba03-7d27-477d-9332-5939cfca316d
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3\userFiles-e909ba03-7d27-477d-9332-5939cfca316d
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:02:06 INFO SparkContext: Successfully stopped SparkContext
17/12/14 12:02:06 INFO ShutdownHookManager: Shutdown hook called
17/12/14 12:02:06 INFO ShutdownHookManager: Deleting directory C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3\userFiles-e909ba03-7d27-477d-9332-5939cfca316d
17/12/14 12:02:06 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3\userFiles-e909ba03-7d27-477d-9332-5939cfca316d
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3\userFiles-e909ba03-7d27-477d-9332-5939cfca316d
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:02:06 INFO ShutdownHookManager: Deleting directory C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3
17/12/14 12:02:06 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-04e7b415-1aaa-4baa-bc69-795e9a149bd3
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:08:23 INFO SparkContext: Running Spark version 2.1.0
17/12/14 12:08:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/14 12:08:24 INFO SecurityManager: Changing view acls to: edgar
17/12/14 12:08:24 INFO SecurityManager: Changing modify acls to: edgar
17/12/14 12:08:24 INFO SecurityManager: Changing view acls groups to: 
17/12/14 12:08:24 INFO SecurityManager: Changing modify acls groups to: 
17/12/14 12:08:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(edgar); groups with view permissions: Set(); users  with modify permissions: Set(edgar); groups with modify permissions: Set()
17/12/14 12:08:24 INFO Utils: Successfully started service 'sparkDriver' on port 54865.
17/12/14 12:08:24 INFO SparkEnv: Registering MapOutputTracker
17/12/14 12:08:24 INFO SparkEnv: Registering BlockManagerMaster
17/12/14 12:08:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/14 12:08:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/14 12:08:24 INFO DiskBlockManager: Created local directory at C:\Users\edgar\AppData\Local\Temp\blockmgr-e70a9452-6fe0-4a9f-ab22-219df78f7b28
17/12/14 12:08:24 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/12/14 12:08:24 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/14 12:08:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/14 12:08:24 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/14 12:08:24 INFO SparkContext: Added JAR file:/C:/Users/edgar/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:54865/jars/sparklyr-2.1-2.11.jar with timestamp 1513274904426
17/12/14 12:08:24 INFO Executor: Starting executor ID driver on host localhost
17/12/14 12:08:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54906.
17/12/14 12:08:24 INFO NettyBlockTransferService: Server created on 127.0.0.1:54906
17/12/14 12:08:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/14 12:08:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54906, None)
17/12/14 12:08:24 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54906 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54906, None)
17/12/14 12:08:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54906, None)
17/12/14 12:08:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54906, None)
17/12/14 12:08:24 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/14 12:08:24 INFO SharedState: Warehouse path is 'C:UsersedgarAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/14 12:08:24 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/14 12:08:25 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/14 12:08:25 INFO ObjectStore: ObjectStore, initialize called
17/12/14 12:08:25 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/14 12:08:25 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/14 12:08:26 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/14 12:08:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:27 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/14 12:08:27 INFO ObjectStore: Initialized ObjectStore
17/12/14 12:08:27 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/14 12:08:27 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/14 12:08:28 INFO HiveMetaStore: Added admin role in metastore
17/12/14 12:08:28 INFO HiveMetaStore: Added public role in metastore
17/12/14 12:08:28 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/14 12:08:28 INFO HiveMetaStore: 0: get_all_databases
17/12/14 12:08:28 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/14 12:08:28 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/14 12:08:28 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/14 12:08:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:28 INFO SessionState: Created local directory: C:/Users/edgar/AppData/Local/Temp/65990677-2e05-464f-aa88-308e975a6613_resources
17/12/14 12:08:28 INFO SessionState: Created HDFS directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/edgar/65990677-2e05-464f-aa88-308e975a6613
17/12/14 12:08:28 INFO SessionState: Created local directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/65990677-2e05-464f-aa88-308e975a6613
17/12/14 12:08:28 INFO SessionState: Created HDFS directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/edgar/65990677-2e05-464f-aa88-308e975a6613/_tmp_space.db
17/12/14 12:08:28 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersedgarAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/14 12:08:28 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:08:28 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:08:28 INFO HiveMetaStore: 0: get_database: global_temp
17/12/14 12:08:28 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/14 12:08:28 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/14 12:08:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:08:30 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:08:30 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:08:30 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:08:30 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:08:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:08:30 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:08:30 INFO CodeGenerator: Code generated in 201.209433 ms
17/12/14 12:08:30 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/14 12:08:30 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/14 12:08:30 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/14 12:08:30 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:30 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:30 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
17/12/14 12:08:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/12/14 12:08:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/12/14 12:08:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54906 (size: 4.6 KB, free: 366.3 MB)
17/12/14 12:08:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
17/12/14 12:08:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/14 12:08:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/14 12:08:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/14 12:08:30 INFO Executor: Fetching spark://127.0.0.1:54865/jars/sparklyr-2.1-2.11.jar with timestamp 1513274904426
17/12/14 12:08:31 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54865 after 10 ms (0 ms spent in bootstraps)
17/12/14 12:08:31 INFO Utils: Fetching spark://127.0.0.1:54865/jars/sparklyr-2.1-2.11.jar to C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10\userFiles-c685d52a-35eb-461c-9266-8b8bbafd3251\fetchFileTemp5555793908598911753.tmp
17/12/14 12:08:31 INFO Executor: Adding file:/C:/Users/edgar/AppData/Local/Temp/spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10/userFiles-c685d52a-35eb-461c-9266-8b8bbafd3251/sparklyr-2.1-2.11.jar to class loader
17/12/14 12:08:31 INFO CodeGenerator: Code generated in 9.64365 ms
17/12/14 12:08:31 INFO CodeGenerator: Code generated in 9.68937 ms
17/12/14 12:08:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/14 12:08:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 280 ms on localhost (executor driver) (1/1)
17/12/14 12:08:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/14 12:08:31 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.296 s
17/12/14 12:08:31 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.428470 s
17/12/14 12:08:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:31 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:54906 in memory (size: 4.6 KB, free: 366.3 MB)
17/12/14 12:08:31 INFO SparkSqlParser: Parsing command: mtcars
17/12/14 12:08:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:31 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
17/12/14 12:08:31 INFO SparkSqlParser: Parsing command: `mtcars`
17/12/14 12:08:31 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:08:31 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:08:31 INFO FileSourceStrategy: Output Data Schema: struct<mpg: double, cyl: double, disp: double, hp: double, drat: double ... 9 more fields>
17/12/14 12:08:31 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:08:31 INFO CodeGenerator: Code generated in 6.56315 ms
17/12/14 12:08:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/12/14 12:08:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/12/14 12:08:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54906 (size: 23.9 KB, free: 366.3 MB)
17/12/14 12:08:31 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/14 12:08:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:08:31 INFO CodeGenerator: Code generated in 9.720628 ms
17/12/14 12:08:31 INFO CodeGenerator: Code generated in 7.274142 ms
17/12/14 12:08:31 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/14 12:08:31 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
17/12/14 12:08:31 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/14 12:08:31 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
17/12/14 12:08:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/12/14 12:08:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/12/14 12:08:31 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
17/12/14 12:08:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 23.2 KB, free 366.0 MB)
17/12/14 12:08:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KB, free 366.0 MB)
17/12/14 12:08:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54906 (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:08:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0)
17/12/14 12:08:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/14 12:08:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/14 12:08:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/14 12:08:31 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/AppData/Local/Temp/RtmpQNqBnQ/spark_serialize_600df8759318fe0d3e7cd227dfb889264b9395236a2336b9c1d32f83ed509279.csv, range: 0-1336, partition values: [empty row]
17/12/14 12:08:31 INFO CodeGenerator: Code generated in 10.538455 ms
17/12/14 12:08:31 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
17/12/14 12:08:31 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:54906 (size: 4.2 KB, free: 366.3 MB)
17/12/14 12:08:31 INFO CodeGenerator: Code generated in 3.28624 ms
17/12/14 12:08:31 INFO CodeGenerator: Code generated in 15.30313 ms
17/12/14 12:08:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2820 bytes result sent to driver
17/12/14 12:08:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 192 ms on localhost (executor driver) (1/1)
17/12/14 12:08:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/14 12:08:32 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.193 s
17/12/14 12:08:32 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:32 INFO DAGScheduler: running: Set()
17/12/14 12:08:32 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/12/14 12:08:32 INFO DAGScheduler: failed: Set()
17/12/14 12:08:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/14 12:08:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/12/14 12:08:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/12/14 12:08:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54906 (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:08:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/14 12:08:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/12/14 12:08:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/14 12:08:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/14 12:08:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
17/12/14 12:08:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1865 bytes result sent to driver
17/12/14 12:08:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 32 ms on localhost (executor driver) (1/1)
17/12/14 12:08:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/14 12:08:32 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.032 s
17/12/14 12:08:32 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.274088 s
17/12/14 12:08:32 INFO CodeGenerator: Code generated in 7.138848 ms
17/12/14 12:08:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:32 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
17/12/14 12:08:32 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:32 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:210)
17/12/14 12:08:32 INFO DAGScheduler: Got job 2 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:08:32 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:210)
17/12/14 12:08:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/12/14 12:08:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/12/14 12:08:32 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 23.2 KB, free 365.9 MB)
17/12/14 12:08:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/12/14 12:08:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54906 (size: 11.0 KB, free: 366.2 MB)
17/12/14 12:08:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210)
17/12/14 12:08:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/14 12:08:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/12/14 12:08:32 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/12/14 12:08:32 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:08:32 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1853 bytes result sent to driver
17/12/14 12:08:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/14 12:08:32 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:210) finished in 0.016 s
17/12/14 12:08:32 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:32 INFO DAGScheduler: running: Set()
17/12/14 12:08:32 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/12/14 12:08:32 INFO DAGScheduler: failed: Set()
17/12/14 12:08:32 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/12/14 12:08:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/12/14 12:08:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54906 (size: 3.7 KB, free: 366.2 MB)
17/12/14 12:08:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210)
17/12/14 12:08:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/12/14 12:08:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/14 12:08:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/12/14 12:08:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:32 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1794 bytes result sent to driver
17/12/14 12:08:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on localhost (executor driver) (1/1)
17/12/14 12:08:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/12/14 12:08:32 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:210) finished in 0.019 s
17/12/14 12:08:32 INFO DAGScheduler: Job 2 finished: collect at utils.scala:210, took 0.080848 s
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 54
17/12/14 12:08:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54906 in memory (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:08:32 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:54906 in memory (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:08:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:54906 in memory (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 163
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 57
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 58
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 59
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 60
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 61
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 62
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 63
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 64
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 65
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 66
17/12/14 12:08:32 INFO ContextCleaner: Cleaned shuffle 0
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 55
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 56
17/12/14 12:08:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz1`
WHERE (0 = 1)
17/12/14 12:08:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars`
17/12/14 12:08:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1794403a6a9b
17/12/14 12:08:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1794403a6a9b` AS `zzz2`
WHERE (0 = 1)
17/12/14 12:08:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_179424152a6d
17/12/14 12:08:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_179424152a6d` AS `zzz3`
WHERE (0 = 1)
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 1
17/12/14 12:08:32 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:54906 in memory (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:08:32 INFO ContextCleaner: Cleaned accumulator 0
17/12/14 12:08:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1794403a6a9b`
17/12/14 12:08:33 INFO CodeGenerator: Code generated in 45.698053 ms
17/12/14 12:08:33 INFO CodeGenerator: Code generated in 23.46508 ms
17/12/14 12:08:33 INFO Instrumentation: LogisticRegression-logistic_regression_1794617a7030-1524733723-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
17/12/14 12:08:33 INFO Instrumentation: LogisticRegression-logistic_regression_1794617a7030-1524733723-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
17/12/14 12:08:33 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:352
17/12/14 12:08:33 INFO DAGScheduler: Got job 3 (treeAggregate at LogisticRegression.scala:352) with 1 output partitions
17/12/14 12:08:33 INFO DAGScheduler: Final stage: ResultStage 5 (treeAggregate at LogisticRegression.scala:352)
17/12/14 12:08:33 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:33 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[34] at treeAggregate at LogisticRegression.scala:352), which has no missing parents
17/12/14 12:08:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 41.3 KB, free 365.9 MB)
17/12/14 12:08:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:08:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:08:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[34] at treeAggregate at LogisticRegression.scala:352)
17/12/14 12:08:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/12/14 12:08:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:08:33 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/14 12:08:33 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:08:33 INFO CodeGenerator: Code generated in 19.521499 ms
17/12/14 12:08:33 INFO CodeGenerator: Code generated in 24.191001 ms
17/12/14 12:08:33 INFO CodeGenerator: Code generated in 7.818117 ms
17/12/14 12:08:33 INFO CodeGenerator: Code generated in 5.477533 ms
17/12/14 12:08:33 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 688.0 B, free 365.9 MB)
17/12/14 12:08:33 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:54906 (size: 688.0 B, free: 366.3 MB)
17/12/14 12:08:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 3699 bytes result sent to driver
17/12/14 12:08:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 126 ms on localhost (executor driver) (1/1)
17/12/14 12:08:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/14 12:08:33 INFO DAGScheduler: ResultStage 5 (treeAggregate at LogisticRegression.scala:352) finished in 0.126 s
17/12/14 12:08:33 INFO DAGScheduler: Job 3 finished: treeAggregate at LogisticRegression.scala:352, took 0.131453 s
17/12/14 12:08:33 INFO Instrumentation: LogisticRegression-logistic_regression_1794617a7030-1524733723-1: {"numClasses":2}
17/12/14 12:08:33 INFO Instrumentation: LogisticRegression-logistic_regression_1794617a7030-1524733723-1: {"numFeatures":2}
17/12/14 12:08:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 56.0 B, free 365.9 MB)
17/12/14 12:08:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 85.0 B, free 365.9 MB)
17/12/14 12:08:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54906 (size: 85.0 B, free: 366.3 MB)
17/12/14 12:08:33 INFO SparkContext: Created broadcast 7 from broadcast at LogisticRegression.scala:435
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 153.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54906 (size: 153.0 B, free: 366.3 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 8 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 4 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 6 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[35] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 41.5 KB, free 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[35] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 3377 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 6 (treeAggregate at LogisticRegression.scala:1670) finished in 0.016 s
17/12/14 12:08:34 INFO DAGScheduler: Job 4 finished: treeAggregate at LogisticRegression.scala:1670, took 0.020172 s
17/12/14 12:08:34 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/12/14 12:08:34 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(8) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:54906 in memory (size: 153.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 10 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 5 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 7 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[36] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[36] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 3396 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 7 (treeAggregate at LogisticRegression.scala:1670) finished in 0.016 s
17/12/14 12:08:34 INFO DAGScheduler: Job 5 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009942 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(10) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 12 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 6 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 8 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 8 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 6 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011276 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO StrongWolfeLineSearch: Line search t: 0.23603867255820976 fval: 0.6236880395237512 rhs: 0.6615559383063949 cdd: -0.008918409604628424
17/12/14 12:08:34 INFO LBFGS: Step Size: 0.2360
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.623688 (rel: 0.0573) 0.128084
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 14 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 7 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 9 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.7 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 3396 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 15 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 9 (treeAggregate at LogisticRegression.scala:1670) finished in 0.015 s
17/12/14 12:08:34 INFO DAGScheduler: Job 7 finished: treeAggregate at LogisticRegression.scala:1670, took 0.012421 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(14) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 80.0 B, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.7 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 16 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 8 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[39] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 18.1 KB, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54906 (size: 18.1 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[39] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 10 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 8 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009207 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(16) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 18 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 9 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 11 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[40] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[40] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:54906 in memory (size: 18.1 KB, free: 366.3 MB)
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 3306 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 11 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
17/12/14 12:08:34 INFO DAGScheduler: Job 9 finished: treeAggregate at LogisticRegression.scala:1670, took 0.012319 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(18) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.3 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.3 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 20 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 10 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 12 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 41.5 KB, free 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6656 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 12 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 10 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009747 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(20) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 22 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 11 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 13 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 13 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 11 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011312 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(22) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 5.063
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.604466 (rel: 0.0308) 0.156839
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 24 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 14 (treeAggregate at LogisticRegression.scala:1670) finished in 0.016 s
17/12/14 12:08:34 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009834 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(24) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.388439 (rel: 0.357) 0.474302
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 26 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 15 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.7 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 3396 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 15 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 15 (treeAggregate at LogisticRegression.scala:1670) finished in 0.015 s
17/12/14 12:08:34 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010097 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(26) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.231865 (rel: 0.403) 0.393581
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 80.0 B, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.7 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 28 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 16 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008902 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(28) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.139087 (rel: 0.400) 0.254625
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 30 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 17 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 41.5 KB, free 365.6 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 17 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010945 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(30) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.0863003 (rel: 0.380) 0.159122
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 32 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 41.5 KB, free 365.5 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.5 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 3396 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 18 (treeAggregate at LogisticRegression.scala:1670) finished in 0.016 s
17/12/14 12:08:34 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011946 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(32) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.0510227 (rel: 0.409) 0.0866745
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 80.0 B, free 365.5 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.5 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 34 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 19 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 41.5 KB, free 365.5 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.5 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 19 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1670, took 0.011019 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(34) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.0284916 (rel: 0.442) 0.0369749
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 80.0 B, free 365.5 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.5 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 20 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 41.5 KB, free 365.4 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.4 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 20 (treeAggregate at LogisticRegression.scala:1670) finished in 0.016 s
17/12/14 12:08:34 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010268 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.0154500 (rel: 0.458) 0.0100746
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 80.0 B, free 365.4 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.4 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 38 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 21 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 41.5 KB, free 365.4 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.3 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 3377 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 15 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 21 (treeAggregate at LogisticRegression.scala:1670) finished in 0.015 s
17/12/14 12:08:34 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009224 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.00835676 (rel: 0.459) 0.00170405
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 80.0 B, free 365.3 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.3 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 40 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 41.5 KB, free 365.3 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.3 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008727 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(40) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.00448685 (rel: 0.463) 0.00408747
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 80.0 B, free 365.3 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.3 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 41.5 KB, free 365.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1670, took 0.010078 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.00430706 (rel: 0.0401) 0.0159143
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 80.0 B, free 365.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 44 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 41.5 KB, free 365.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007428 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(44) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.00125308 (rel: 0.709) 0.00411243
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 80.0 B, free 365.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 46 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 41.5 KB, free 365.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.1 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007189 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.000783685 (rel: 0.375) 0.00237017
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 80.0 B, free 365.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.1 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 41.5 KB, free 365.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.1 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007465 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.000378859 (rel: 0.517) 0.000961061
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 80.0 B, free 365.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.1 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 50 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 41.5 KB, free 365.0 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.0 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009030 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.000203665 (rel: 0.462) 0.000418382
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 80.0 B, free 365.0 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.0 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 52 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 41.5 KB, free 365.0 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007244 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(52) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 0.000105274 (rel: 0.483) 0.000157706
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 80.0 B, free 364.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 54 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 41.5 KB, free 364.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007275 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 5.51162e-05 (rel: 0.476) 5.22221e-05
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 80.0 B, free 364.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 365.9 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 56 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 41.5 KB, free 364.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007259 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 2.84529e-05 (rel: 0.484) 1.29487e-05
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 80.0 B, free 364.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 365.9 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 58 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 41.5 KB, free 364.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 3385 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
17/12/14 12:08:34 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009104 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(58) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 1.44695e-05 (rel: 0.491) 2.65588e-06
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 80.0 B, free 364.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 365.9 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 60 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 41.5 KB, free 364.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 18.0 KB, free 364.7 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008217 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(60) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 365.9 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 7.18643e-06 (rel: 0.503) 2.15668e-06
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 80.0 B, free 364.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 162.0 B, free 364.7 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 365.9 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 62 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 31 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 41.5 KB, free 365.0 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.1 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 31 finished: treeAggregate at LogisticRegression.scala:1670, took 0.009336 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(62) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 64 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 32 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 41.5 KB, free 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 32 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006953 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(64) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO StrongWolfeLineSearch: Line search t: 0.18371940831922506 fval: 6.884990683532303E-6 rhs: 7.186315853485074E-6 cdd: 2.692528950115482E-6
17/12/14 12:08:34 INFO LBFGS: Step Size: 0.1837
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 6.88499e-06 (rel: 0.0419) 1.29796e-05
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 80.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.9 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 66 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 33 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 35.0 (TID 35)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 33 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006689 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(66) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 3.32520e-06 (rel: 0.517) 3.26833e-06
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 68 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 34 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 41.5 KB, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 34 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006476 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(68) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 1.73349e-06 (rel: 0.479) 1.58506e-06
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 80.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.8 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 70 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 35 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.7 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 37.0 (TID 37)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 37.0 (TID 37). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 35 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007105 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(70) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 8.54906e-07 (rel: 0.507) 7.49519e-07
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 80.0 B, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.7 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 72 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 36 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 41.5 KB, free 365.7 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 38.0 (TID 38)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 38.0 (TID 38). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 36 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006695 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(72) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 4.30591e-07 (rel: 0.496) 3.66293e-07
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.2 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 74 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 37 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 41.5 KB, free 365.6 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 39.0 (TID 39)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 39.0 (TID 39). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 37 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006725 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(74) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 2.15066e-07 (rel: 0.326) 1.78245e-07
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 80.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.6 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 76 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 38 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 41.5 KB, free 365.5 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.5 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 40.0 (TID 40)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 40.0 (TID 40). 3306 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 40) in 3 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
17/12/14 12:08:34 INFO DAGScheduler: Job 38 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006838 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 1.07746e-07 (rel: 0.162) 8.72196e-08
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 80.0 B, free 365.5 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.5 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 78 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 39 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 41.5 KB, free 365.5 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.5 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 41.0 (TID 41)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 41.0 (TID 41). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 41) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 41 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 39 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007305 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(78) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 5.39069e-08 (rel: 0.0814) 4.26866e-08
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 80.0 B, free 365.5 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.5 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 80 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 40 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 41.5 KB, free 365.4 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.4 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 42.0 (TID 42)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 42.0 (TID 42). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 42) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 42 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 40 finished: treeAggregate at LogisticRegression.scala:1670, took 0.008331 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(80) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 2.69804e-08 (rel: 0.0407) 2.09259e-08
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 80.0 B, free 365.4 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.4 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 82 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 41 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 43 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 41.5 KB, free 365.4 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 18.0 KB, free 365.3 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:54906 (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 43.0 (TID 43)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 43.0 (TID 43). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 43) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 43 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 41 finished: treeAggregate at LogisticRegression.scala:1670, took 0.007214 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(82) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 1.34999e-08 (rel: 0.0204) 1.02673e-08
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 80.0 B, free 365.3 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 162.0 B, free 365.3 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:54906 (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 84 from broadcast at LogisticRegression.scala:1657
17/12/14 12:08:34 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
17/12/14 12:08:34 INFO DAGScheduler: Got job 42 (treeAggregate at LogisticRegression.scala:1670) with 1 output partitions
17/12/14 12:08:34 INFO DAGScheduler: Final stage: ResultStage 44 (treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:34 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:34 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 41.5 KB, free 365.3 MB)
17/12/14 12:08:34 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 18.1 KB, free 365.3 MB)
17/12/14 12:08:34 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:54906 (size: 18.1 KB, free: 366.1 MB)
17/12/14 12:08:34 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1670)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
17/12/14 12:08:34 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 6657 bytes)
17/12/14 12:08:34 INFO Executor: Running task 0.0 in stage 44.0 (TID 44)
17/12/14 12:08:34 INFO BlockManager: Found block rdd_33_0 locally
17/12/14 12:08:34 INFO Executor: Finished task 0.0 in stage 44.0 (TID 44). 3219 bytes result sent to driver
17/12/14 12:08:34 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 44) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:34 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
17/12/14 12:08:34 INFO DAGScheduler: ResultStage 44 (treeAggregate at LogisticRegression.scala:1670) finished in 0.000 s
17/12/14 12:08:34 INFO DAGScheduler: Job 42 finished: treeAggregate at LogisticRegression.scala:1670, took 0.006734 s
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(84) (from destroy at LogisticRegression.scala:1711)
17/12/14 12:08:34 INFO LBFGS: Step Size: 1.000
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:54906 in memory (size: 162.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO LBFGS: Val and Grad Norm: 6.75477e-09 (rel: 0.0102) 5.04411e-09
17/12/14 12:08:34 INFO LBFGS: Converged because gradient converged
17/12/14 12:08:34 INFO TorrentBroadcast: Destroying Broadcast(7) (from destroy at LogisticRegression.scala:566)
17/12/14 12:08:34 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54906 in memory (size: 85.0 B, free: 366.1 MB)
17/12/14 12:08:34 INFO MapPartitionsRDD: Removing RDD 33 from persistence list
17/12/14 12:08:34 INFO BlockManager: Removing RDD 33
17/12/14 12:08:35 INFO CodeGenerator: Code generated in 21.479527 ms
17/12/14 12:08:35 INFO Instrumentation: LogisticRegression-logistic_regression_1794617a7030-1524733723-1: training finished
17/12/14 12:08:35 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
17/12/14 12:08:35 INFO DAGScheduler: Registering RDD 78 (map at LogisticRegression.scala:1176)
17/12/14 12:08:35 INFO DAGScheduler: Registering RDD 79 (combineByKey at BinaryClassificationMetrics.scala:151)
17/12/14 12:08:35 INFO DAGScheduler: Got job 43 (count at BinaryClassificationMetrics.scala:163) with 1 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 47 (count at BinaryClassificationMetrics.scala:163)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
17/12/14 12:08:35 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[78] at map at LogisticRegression.scala:1176), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 50.9 KB, free 365.2 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 22.0 KB, free 365.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:54906 (size: 22.0 KB, free: 366.0 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[78] at map at LogisticRegression.scala:1176)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6554 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 45.0 (TID 45)
17/12/14 12:08:35 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:08:35 INFO CodeGenerator: Code generated in 4.584128 ms
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 2345 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 38 ms on localhost (executor driver) (1/1)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ShuffleMapStage 45 (map at LogisticRegression.scala:1176) finished in 0.038 s
17/12/14 12:08:35 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:35 INFO DAGScheduler: running: Set()
17/12/14 12:08:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 46, ResultStage 47)
17/12/14 12:08:35 INFO DAGScheduler: failed: Set()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ShuffleMapStage 46 (ShuffledRDD[79] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 3.4 KB, free 365.2 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 1886.0 B, free 365.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:54906 (size: 1886.0 B, free: 366.0 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (ShuffledRDD[79] at combineByKey at BinaryClassificationMetrics.scala:151)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 46, localhost, executor driver, partition 0, ANY, 5715 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 46.0 (TID 46)
17/12/14 12:08:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 46.0 (TID 46). 1869 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 46) in 31 ms on localhost (executor driver) (1/1)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ShuffleMapStage 46 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.031 s
17/12/14 12:08:35 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:35 INFO DAGScheduler: running: Set()
17/12/14 12:08:35 INFO DAGScheduler: waiting: Set(ResultStage 47)
17/12/14 12:08:35 INFO DAGScheduler: failed: Set()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 47 (ShuffledRDD[80] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 3.1 KB, free 365.2 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 1842.0 B, free 365.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:54906 (size: 1842.0 B, free: 366.0 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (ShuffledRDD[80] at sortByKey at BinaryClassificationMetrics.scala:155)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 47, localhost, executor driver, partition 0, ANY, 5726 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 47.0 (TID 47)
17/12/14 12:08:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 47.0 (TID 47). 1591 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 47) in 7 ms on localhost (executor driver) (1/1)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 47 (count at BinaryClassificationMetrics.scala:163) finished in 0.007 s
17/12/14 12:08:35 INFO DAGScheduler: Job 43 finished: count at BinaryClassificationMetrics.scala:163, took 0.098089 s
17/12/14 12:08:35 INFO BinaryClassificationMetrics: Curve is too small (5) for 100 bins to be useful
17/12/14 12:08:35 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
17/12/14 12:08:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 143 bytes
17/12/14 12:08:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
17/12/14 12:08:35 INFO DAGScheduler: Got job 44 (collect at BinaryClassificationMetrics.scala:192) with 1 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 50 (collect at BinaryClassificationMetrics.scala:192)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[82] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 4.0 KB, free 365.2 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 2.2 KB, free 365.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:54906 (size: 2.2 KB, free: 366.0 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[82] at mapPartitions at BinaryClassificationMetrics.scala:188)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 48, localhost, executor driver, partition 0, ANY, 5812 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 50.0 (TID 48)
17/12/14 12:08:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 50.0 (TID 48). 1552 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 48) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 50 (collect at BinaryClassificationMetrics.scala:192) finished in 0.000 s
17/12/14 12:08:35 INFO DAGScheduler: Job 44 finished: collect at BinaryClassificationMetrics.scala:192, took 0.012539 s
17/12/14 12:08:35 INFO BinaryClassificationMetrics: Total counts: {numPos: 5, numNeg: 3}
17/12/14 12:08:35 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
17/12/14 12:08:35 INFO DAGScheduler: Got job 45 (collect at SlidingRDD.scala:81) with 3 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 53 (collect at SlidingRDD.scala:81)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[90] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 6.0 KB, free 365.2 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 3.1 KB, free 365.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:54906 (size: 3.1 KB, free: 366.0 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 53 (MapPartitionsRDD[90] at mapPartitions at SlidingRDD.scala:78)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 53.0 with 3 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6251 bytes)
17/12/14 12:08:35 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 50, localhost, executor driver, partition 2, PROCESS_LOCAL, 6251 bytes)
17/12/14 12:08:35 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 51, localhost, executor driver, partition 1, ANY, 5923 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 53.0 (TID 49)
17/12/14 12:08:35 INFO Executor: Running task 2.0 in stage 53.0 (TID 50)
17/12/14 12:08:35 INFO Executor: Running task 1.0 in stage 53.0 (TID 51)
17/12/14 12:08:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 53.0 (TID 49). 824 bytes result sent to driver
17/12/14 12:08:35 INFO MemoryStore: Block rdd_83_0 stored as values in memory (estimated size 440.0 B, free 365.2 MB)
17/12/14 12:08:35 INFO Executor: Finished task 2.0 in stage 53.0 (TID 50). 824 bytes result sent to driver
17/12/14 12:08:35 INFO BlockManagerInfo: Added rdd_83_0 in memory on 127.0.0.1:54906 (size: 440.0 B, free: 366.0 MB)
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 49) in 16 ms on localhost (executor driver) (1/3)
17/12/14 12:08:35 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 50) in 16 ms on localhost (executor driver) (2/3)
17/12/14 12:08:35 INFO Executor: Finished task 1.0 in stage 53.0 (TID 51). 2501 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 51) in 16 ms on localhost (executor driver) (3/3)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 53 (collect at SlidingRDD.scala:81) finished in 0.016 s
17/12/14 12:08:35 INFO DAGScheduler: Job 45 finished: collect at SlidingRDD.scala:81, took 0.014454 s
17/12/14 12:08:35 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
17/12/14 12:08:35 INFO DAGScheduler: Got job 46 (aggregate at AreaUnderCurve.scala:45) with 2 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 56 (aggregate at AreaUnderCurve.scala:45)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 56 (SlidingRDD[89] at RDD at SlidingRDD.scala:50), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 6.1 KB, free 365.2 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 3.2 KB, free 365.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:54906 (size: 3.2 KB, free: 366.0 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 56 (SlidingRDD[89] at RDD at SlidingRDD.scala:50)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 56.0 with 2 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 52, localhost, executor driver, partition 1, PROCESS_LOCAL, 6462 bytes)
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/12/14 12:08:35 INFO Executor: Running task 1.0 in stage 56.0 (TID 52)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 56.0 (TID 53)
17/12/14 12:08:35 INFO BlockManager: Found block rdd_83_0 locally
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 56.0 (TID 53). 630 bytes result sent to driver
17/12/14 12:08:35 INFO Executor: Finished task 1.0 in stage 56.0 (TID 52). 790 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 53) in 0 ms on localhost (executor driver) (1/2)
17/12/14 12:08:35 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 52) in 0 ms on localhost (executor driver) (2/2)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 56 (aggregate at AreaUnderCurve.scala:45) finished in 0.000 s
17/12/14 12:08:35 INFO DAGScheduler: Job 46 finished: aggregate at AreaUnderCurve.scala:45, took 0.009067 s
17/12/14 12:08:35 INFO CodeGenerator: Code generated in 6.667186 ms
17/12/14 12:08:35 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:35 INFO DAGScheduler: Got job 47 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:210)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[94] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 10.0 KB, free 365.2 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 4.7 KB, free 365.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:54906 (size: 4.7 KB, free: 366.0 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[94] at collect at utils.scala:210)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 59.0 (TID 54)
17/12/14 12:08:35 INFO BlockManager: Found block rdd_83_0 locally
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 59.0 (TID 54). 1202 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 54) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:210) finished in 0.000 s
17/12/14 12:08:35 INFO DAGScheduler: Job 47 finished: collect at utils.scala:210, took 0.010002 s
17/12/14 12:08:35 INFO CodeGenerator: Code generated in 4.796865 ms
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 272
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.0 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.1 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:54906 in memory (size: 18.1 KB, free: 366.1 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:54906 in memory (size: 22.0 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:54906 in memory (size: 1886.0 B, free: 366.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:54906 in memory (size: 1842.0 B, free: 366.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:54906 in memory (size: 2.2 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:54906 in memory (size: 3.1 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:54906 in memory (size: 3.2 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:54906 in memory (size: 4.7 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 273
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 274
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 275
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 276
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 277
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 278
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 279
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 280
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 281
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 282
17/12/14 12:08:35 INFO ContextCleaner: Cleaned accumulator 283
17/12/14 12:08:35 INFO DAGScheduler: Got job 48 (collect at utils.scala:210) with 2 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:210)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO BlockManager: Removing RDD 33
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[100] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 10.7 KB, free 365.7 MB)
17/12/14 12:08:35 INFO ContextCleaner: Cleaned RDD 33
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 5.1 KB, free 365.7 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:54906 (size: 5.1 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 62 (MapPartitionsRDD[100] at collect at utils.scala:210)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 55, localhost, executor driver, partition 1, PROCESS_LOCAL, 5950 bytes)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 62.0 (TID 56)
17/12/14 12:08:35 INFO Executor: Running task 1.0 in stage 62.0 (TID 55)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:54906 in memory (size: 18.0 KB, free: 366.3 MB)
17/12/14 12:08:35 INFO BlockManager: Found block rdd_83_0 locally
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 62.0 (TID 56). 961 bytes result sent to driver
17/12/14 12:08:35 INFO Executor: Finished task 1.0 in stage 62.0 (TID 55). 1174 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 56) in 0 ms on localhost (executor driver) (1/2)
17/12/14 12:08:35 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 55) in 0 ms on localhost (executor driver) (2/2)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:210) finished in 0.000 s
17/12/14 12:08:35 INFO DAGScheduler: Job 48 finished: collect at utils.scala:210, took 0.007871 s
17/12/14 12:08:35 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:35 INFO DAGScheduler: Got job 49 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:210)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[104] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 9.9 KB, free 366.0 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 4.7 KB, free 366.0 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:54906 (size: 4.7 KB, free: 366.3 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[104] at collect at utils.scala:210)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 65.0 (TID 57)
17/12/14 12:08:35 INFO BlockManager: Found block rdd_83_0 locally
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 65.0 (TID 57). 1196 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 57) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:210) finished in 0.000 s
17/12/14 12:08:35 INFO DAGScheduler: Job 49 finished: collect at utils.scala:210, took 0.006822 s
17/12/14 12:08:35 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17942c0910f9
17/12/14 12:08:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17942c0910f9` AS `zzz4`
WHERE (0 = 1)
17/12/14 12:08:35 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:35 INFO DAGScheduler: Got job 50 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:210)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[109] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 9.9 KB, free 365.9 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 4.7 KB, free 365.9 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:54906 (size: 4.7 KB, free: 366.3 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[109] at collect at utils.scala:210)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 68.0 (TID 58)
17/12/14 12:08:35 INFO BlockManager: Found block rdd_83_0 locally
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 68.0 (TID 58). 1188 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 58) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 68 (collect at utils.scala:210) finished in 0.000 s
17/12/14 12:08:35 INFO DAGScheduler: Job 50 finished: collect at utils.scala:210, took 0.006062 s
17/12/14 12:08:35 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:35 INFO DAGScheduler: Got job 51 (collect at utils.scala:210) with 3 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:210)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[116] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 10.8 KB, free 365.9 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 5.1 KB, free 365.9 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:54906 (size: 5.1 KB, free: 366.3 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 71 (MapPartitionsRDD[116] at collect at utils.scala:210)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 71.0 with 3 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 59, localhost, executor driver, partition 1, PROCESS_LOCAL, 5950 bytes)
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
17/12/14 12:08:35 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 61, localhost, executor driver, partition 2, PROCESS_LOCAL, 6278 bytes)
17/12/14 12:08:35 INFO Executor: Running task 1.0 in stage 71.0 (TID 59)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 71.0 (TID 60)
17/12/14 12:08:35 INFO Executor: Running task 2.0 in stage 71.0 (TID 61)
17/12/14 12:08:35 INFO BlockManager: Found block rdd_83_0 locally
17/12/14 12:08:35 INFO Executor: Finished task 2.0 in stage 71.0 (TID 61). 968 bytes result sent to driver
17/12/14 12:08:35 INFO Executor: Finished task 1.0 in stage 71.0 (TID 59). 1164 bytes result sent to driver
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 71.0 (TID 60). 960 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 61) in 0 ms on localhost (executor driver) (1/3)
17/12/14 12:08:35 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 59) in 0 ms on localhost (executor driver) (2/3)
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 60) in 0 ms on localhost (executor driver) (3/3)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:210) finished in 0.016 s
17/12/14 12:08:35 INFO DAGScheduler: Job 51 finished: collect at utils.scala:210, took 0.007830 s
17/12/14 12:08:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_179424152a6d`
17/12/14 12:08:35 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1794625a93f
17/12/14 12:08:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1794625a93f` AS `zzz5`
WHERE (0 = 1)
17/12/14 12:08:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1794625a93f`
LIMIT 25
17/12/14 12:08:35 INFO CodeGenerator: Code generated in 36.880629 ms
17/12/14 12:08:35 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:35 INFO DAGScheduler: Got job 52 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:08:35 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:210)
17/12/14 12:08:35 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:35 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:35 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[120] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 71.6 KB, free 365.9 MB)
17/12/14 12:08:35 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 26.0 KB, free 365.8 MB)
17/12/14 12:08:35 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:54906 (size: 26.0 KB, free: 366.2 MB)
17/12/14 12:08:35 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[120] at collect at utils.scala:210)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
17/12/14 12:08:35 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 6594 bytes)
17/12/14 12:08:35 INFO Executor: Running task 0.0 in stage 72.0 (TID 62)
17/12/14 12:08:35 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:08:35 INFO Executor: Finished task 0.0 in stage 72.0 (TID 62). 3928 bytes result sent to driver
17/12/14 12:08:35 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 62) in 15 ms on localhost (executor driver) (1/1)
17/12/14 12:08:35 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
17/12/14 12:08:35 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:210) finished in 0.015 s
17/12/14 12:08:35 INFO DAGScheduler: Job 52 finished: collect at utils.scala:210, took 0.018827 s
17/12/14 12:08:35 INFO CodeGenerator: Code generated in 10.906081 ms
17/12/14 12:08:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:36 INFO SparkSqlParser: Parsing command: SELECT `guzzler`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_1794625a93f`
GROUP BY `guzzler`, `prediction`
LIMIT 10
17/12/14 12:08:36 INFO CodeGenerator: Code generated in 16.80909 ms
17/12/14 12:08:36 INFO CodeGenerator: Code generated in 35.736229 ms
17/12/14 12:08:36 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:36 INFO DAGScheduler: Registering RDD 123 (collect at utils.scala:210)
17/12/14 12:08:36 INFO DAGScheduler: Got job 53 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:08:36 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:210)
17/12/14 12:08:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
17/12/14 12:08:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)
17/12/14 12:08:36 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[123] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 57.5 KB, free 365.8 MB)
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 25.2 KB, free 365.8 MB)
17/12/14 12:08:36 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:54906 (size: 25.2 KB, free: 366.2 MB)
17/12/14 12:08:36 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[123] at collect at utils.scala:210)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
17/12/14 12:08:36 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 6583 bytes)
17/12/14 12:08:36 INFO Executor: Running task 0.0 in stage 73.0 (TID 63)
17/12/14 12:08:36 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:08:36 INFO CodeGenerator: Code generated in 3.542365 ms
17/12/14 12:08:36 INFO CodeGenerator: Code generated in 3.289972 ms
17/12/14 12:08:36 INFO CodeGenerator: Code generated in 3.847476 ms
17/12/14 12:08:36 INFO CodeGenerator: Code generated in 6.533292 ms
17/12/14 12:08:36 INFO CodeGenerator: Code generated in 3.466321 ms
17/12/14 12:08:36 INFO Executor: Finished task 0.0 in stage 73.0 (TID 63). 2624 bytes result sent to driver
17/12/14 12:08:36 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 63) in 63 ms on localhost (executor driver) (1/1)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
17/12/14 12:08:36 INFO DAGScheduler: ShuffleMapStage 73 (collect at utils.scala:210) finished in 0.063 s
17/12/14 12:08:36 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:36 INFO DAGScheduler: running: Set()
17/12/14 12:08:36 INFO DAGScheduler: waiting: Set(ResultStage 74)
17/12/14 12:08:36 INFO DAGScheduler: failed: Set()
17/12/14 12:08:36 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[126] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 31.1 KB, free 365.7 MB)
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 14.1 KB, free 365.7 MB)
17/12/14 12:08:36 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:54906 (size: 14.1 KB, free: 366.2 MB)
17/12/14 12:08:36 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[126] at collect at utils.scala:210)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
17/12/14 12:08:36 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
17/12/14 12:08:36 INFO Executor: Running task 0.0 in stage 74.0 (TID 64)
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
17/12/14 12:08:36 INFO Executor: Finished task 0.0 in stage 74.0 (TID 64). 2925 bytes result sent to driver
17/12/14 12:08:36 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 64) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
17/12/14 12:08:36 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:210) finished in 0.016 s
17/12/14 12:08:36 INFO DAGScheduler: Job 53 finished: collect at utils.scala:210, took 0.083336 s
17/12/14 12:08:36 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 149 bytes
17/12/14 12:08:36 INFO DAGScheduler: Got job 54 (collect at utils.scala:210) with 4 output partitions
17/12/14 12:08:36 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:210)
17/12/14 12:08:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
17/12/14 12:08:36 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:36 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[126] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 31.1 KB, free 365.7 MB)
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 14.1 KB, free 365.7 MB)
17/12/14 12:08:36 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:54906 (size: 14.1 KB, free: 366.2 MB)
17/12/14 12:08:36 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 76 (MapPartitionsRDD[126] at collect at utils.scala:210)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Adding task set 76.0 with 4 tasks
17/12/14 12:08:36 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 65, localhost, executor driver, partition 2, PROCESS_LOCAL, 5860 bytes)
17/12/14 12:08:36 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 66, localhost, executor driver, partition 3, PROCESS_LOCAL, 5860 bytes)
17/12/14 12:08:36 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 67, localhost, executor driver, partition 4, PROCESS_LOCAL, 5860 bytes)
17/12/14 12:08:36 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 68, localhost, executor driver, partition 1, ANY, 5860 bytes)
17/12/14 12:08:36 INFO Executor: Running task 1.0 in stage 76.0 (TID 65)
17/12/14 12:08:36 INFO Executor: Running task 2.0 in stage 76.0 (TID 66)
17/12/14 12:08:36 INFO Executor: Running task 3.0 in stage 76.0 (TID 67)
17/12/14 12:08:36 INFO Executor: Running task 0.0 in stage 76.0 (TID 68)
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:36 INFO Executor: Finished task 1.0 in stage 76.0 (TID 65). 2925 bytes result sent to driver
17/12/14 12:08:36 INFO Executor: Finished task 3.0 in stage 76.0 (TID 67). 2925 bytes result sent to driver
17/12/14 12:08:36 INFO Executor: Finished task 2.0 in stage 76.0 (TID 66). 2925 bytes result sent to driver
17/12/14 12:08:36 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 65) in 15 ms on localhost (executor driver) (1/4)
17/12/14 12:08:36 INFO Executor: Finished task 0.0 in stage 76.0 (TID 68). 2945 bytes result sent to driver
17/12/14 12:08:36 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 67) in 15 ms on localhost (executor driver) (2/4)
17/12/14 12:08:36 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 66) in 15 ms on localhost (executor driver) (3/4)
17/12/14 12:08:36 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 68) in 15 ms on localhost (executor driver) (4/4)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
17/12/14 12:08:36 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:210) finished in 0.015 s
17/12/14 12:08:36 INFO DAGScheduler: Job 54 finished: collect at utils.scala:210, took 0.013932 s
17/12/14 12:08:36 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:36 INFO DAGScheduler: Got job 55 (collect at utils.scala:210) with 3 output partitions
17/12/14 12:08:36 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:210)
17/12/14 12:08:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
17/12/14 12:08:36 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:36 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[126] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 31.1 KB, free 365.6 MB)
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 14.1 KB, free 365.6 MB)
17/12/14 12:08:36 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:54906 (size: 14.1 KB, free: 366.2 MB)
17/12/14 12:08:36 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:36 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 78 (MapPartitionsRDD[126] at collect at utils.scala:210)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Adding task set 78.0 with 3 tasks
17/12/14 12:08:36 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 69, localhost, executor driver, partition 5, PROCESS_LOCAL, 5860 bytes)
17/12/14 12:08:36 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 70, localhost, executor driver, partition 7, PROCESS_LOCAL, 5860 bytes)
17/12/14 12:08:36 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 71, localhost, executor driver, partition 6, ANY, 5860 bytes)
17/12/14 12:08:36 INFO Executor: Running task 1.0 in stage 78.0 (TID 71)
17/12/14 12:08:36 INFO Executor: Running task 2.0 in stage 78.0 (TID 70)
17/12/14 12:08:36 INFO Executor: Running task 0.0 in stage 78.0 (TID 69)
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:36 INFO Executor: Finished task 2.0 in stage 78.0 (TID 70). 2925 bytes result sent to driver
17/12/14 12:08:36 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 70) in 18 ms on localhost (executor driver) (1/3)
17/12/14 12:08:36 INFO Executor: Finished task 0.0 in stage 78.0 (TID 69). 2925 bytes result sent to driver
17/12/14 12:08:36 INFO Executor: Finished task 1.0 in stage 78.0 (TID 71). 2957 bytes result sent to driver
17/12/14 12:08:36 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 69) in 18 ms on localhost (executor driver) (2/3)
17/12/14 12:08:36 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 71) in 18 ms on localhost (executor driver) (3/3)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
17/12/14 12:08:36 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:210) finished in 0.019 s
17/12/14 12:08:36 INFO DAGScheduler: Job 55 finished: collect at utils.scala:210, took 0.011781 s
17/12/14 12:08:36 INFO CodeGenerator: Code generated in 4.131593 ms
17/12/14 12:08:36 INFO PipelineModel$PipelineModelWriter: Path C:\Users\edgar\Documents\sparklyr_pipeline\new_model already exists. It will be overwritten.
17/12/14 12:08:36 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/12/14 12:08:36 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/12/14 12:08:36 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/12/14 12:08:36 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/12/14 12:08:36 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/12/14 12:08:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:36 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:08:36 INFO DAGScheduler: Got job 56 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:08:36 INFO DAGScheduler: Final stage: ResultStage 79 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:36 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:36 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:36 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[128] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 72.1 KB, free 365.5 MB)
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.5 MB)
17/12/14 12:08:36 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:54906 (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:08:36 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[128] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
17/12/14 12:08:36 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 6263 bytes)
17/12/14 12:08:36 INFO Executor: Running task 0.0 in stage 79.0 (TID 72)
17/12/14 12:08:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:36 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120836_0079_m_000000_72' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/metadata/_temporary/0/task_20171214120836_0079_m_000000
17/12/14 12:08:36 INFO SparkHadoopMapRedUtil: attempt_20171214120836_0079_m_000000_72: Committed
17/12/14 12:08:36 INFO Executor: Finished task 0.0 in stage 79.0 (TID 72). 1003 bytes result sent to driver
17/12/14 12:08:36 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 72) in 121 ms on localhost (executor driver) (1/1)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
17/12/14 12:08:36 INFO DAGScheduler: ResultStage 79 (saveAsTextFile at ReadWrite.scala:275) finished in 0.121 s
17/12/14 12:08:36 INFO DAGScheduler: Job 56 finished: saveAsTextFile at ReadWrite.scala:275, took 0.146350 s
17/12/14 12:08:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:36 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:08:36 INFO DAGScheduler: Got job 57 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:08:36 INFO DAGScheduler: Final stage: ResultStage 80 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:36 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:36 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:36 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[130] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 72.1 KB, free 365.5 MB)
17/12/14 12:08:36 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.4 MB)
17/12/14 12:08:36 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:54906 (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:08:36 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[130] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
17/12/14 12:08:36 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
17/12/14 12:08:36 INFO Executor: Running task 0.0 in stage 80.0 (TID 73)
17/12/14 12:08:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:36 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120836_0080_m_000000_73' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/0_binarizer_179436bf21f6/metadata/_temporary/0/task_20171214120836_0080_m_000000
17/12/14 12:08:36 INFO SparkHadoopMapRedUtil: attempt_20171214120836_0080_m_000000_73: Committed
17/12/14 12:08:36 INFO Executor: Finished task 0.0 in stage 80.0 (TID 73). 916 bytes result sent to driver
17/12/14 12:08:36 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 73) in 120 ms on localhost (executor driver) (1/1)
17/12/14 12:08:36 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
17/12/14 12:08:36 INFO DAGScheduler: ResultStage 80 (saveAsTextFile at ReadWrite.scala:275) finished in 0.120 s
17/12/14 12:08:36 INFO DAGScheduler: Job 57 finished: saveAsTextFile at ReadWrite.scala:275, took 0.130487 s
17/12/14 12:08:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:37 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:08:37 INFO DAGScheduler: Got job 58 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:08:37 INFO DAGScheduler: Final stage: ResultStage 81 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:37 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:37 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:37 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[132] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:08:37 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 72.1 KB, free 365.4 MB)
17/12/14 12:08:37 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.3 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:54906 (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:08:37 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[132] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:37 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
17/12/14 12:08:37 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 6217 bytes)
17/12/14 12:08:37 INFO Executor: Running task 0.0 in stage 81.0 (TID 74)
17/12/14 12:08:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:37 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120836_0081_m_000000_74' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/metadata/_temporary/0/task_20171214120836_0081_m_000000
17/12/14 12:08:37 INFO SparkHadoopMapRedUtil: attempt_20171214120836_0081_m_000000_74: Committed
17/12/14 12:08:37 INFO Executor: Finished task 0.0 in stage 81.0 (TID 74). 1093 bytes result sent to driver
17/12/14 12:08:37 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 74) in 118 ms on localhost (executor driver) (1/1)
17/12/14 12:08:37 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
17/12/14 12:08:37 INFO DAGScheduler: ResultStage 81 (saveAsTextFile at ReadWrite.scala:275) finished in 0.118 s
17/12/14 12:08:37 INFO DAGScheduler: Job 58 finished: saveAsTextFile at ReadWrite.scala:275, took 0.117954 s
17/12/14 12:08:37 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:54906 in memory (size: 4.7 KB, free: 366.1 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:54906 in memory (size: 5.1 KB, free: 366.1 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:54906 in memory (size: 4.7 KB, free: 366.1 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:54906 in memory (size: 5.1 KB, free: 366.1 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:54906 in memory (size: 26.0 KB, free: 366.1 MB)
17/12/14 12:08:37 INFO ContextCleaner: Cleaned accumulator 2946
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:54906 in memory (size: 25.2 KB, free: 366.2 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:54906 in memory (size: 14.1 KB, free: 366.2 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:54906 in memory (size: 14.1 KB, free: 366.2 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:54906 in memory (size: 14.1 KB, free: 366.2 MB)
17/12/14 12:08:37 INFO CodeGenerator: Code generated in 22.372465 ms
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:54906 in memory (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:54906 in memory (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:54906 in memory (size: 25.9 KB, free: 366.3 MB)
17/12/14 12:08:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:37 INFO SparkContext: Starting job: parquet at RFormula.scala:325
17/12/14 12:08:37 INFO DAGScheduler: Registering RDD 135 (parquet at RFormula.scala:325)
17/12/14 12:08:37 INFO DAGScheduler: Got job 59 (parquet at RFormula.scala:325) with 1 output partitions
17/12/14 12:08:37 INFO DAGScheduler: Final stage: ResultStage 83 (parquet at RFormula.scala:325)
17/12/14 12:08:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
17/12/14 12:08:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 82)
17/12/14 12:08:37 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[135] at parquet at RFormula.scala:325), which has no missing parents
17/12/14 12:08:37 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 4.9 KB, free 366.0 MB)
17/12/14 12:08:37 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 2.9 KB, free 366.0 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:54906 (size: 2.9 KB, free: 366.3 MB)
17/12/14 12:08:37 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[135] at parquet at RFormula.scala:325)
17/12/14 12:08:37 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
17/12/14 12:08:37 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 6340 bytes)
17/12/14 12:08:37 INFO Executor: Running task 0.0 in stage 82.0 (TID 75)
17/12/14 12:08:37 INFO Executor: Finished task 0.0 in stage 82.0 (TID 75). 1219 bytes result sent to driver
17/12/14 12:08:37 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 75) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:37 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
17/12/14 12:08:37 INFO DAGScheduler: ShuffleMapStage 82 (parquet at RFormula.scala:325) finished in 0.000 s
17/12/14 12:08:37 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:37 INFO DAGScheduler: running: Set()
17/12/14 12:08:37 INFO DAGScheduler: waiting: Set(ResultStage 83)
17/12/14 12:08:37 INFO DAGScheduler: failed: Set()
17/12/14 12:08:37 INFO DAGScheduler: Submitting ResultStage 83 (ShuffledRowRDD[136] at parquet at RFormula.scala:325), which has no missing parents
17/12/14 12:08:37 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 77.2 KB, free 365.9 MB)
17/12/14 12:08:37 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 28.7 KB, free 365.9 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:54906 (size: 28.7 KB, free: 366.2 MB)
17/12/14 12:08:37 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (ShuffledRowRDD[136] at parquet at RFormula.scala:325)
17/12/14 12:08:37 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
17/12/14 12:08:37 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 76, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/12/14 12:08:37 INFO Executor: Running task 0.0 in stage 83.0 (TID 76)
17/12/14 12:08:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
17/12/14 12:08:37 INFO CodecPool: Got brand-new compressor [.snappy]
17/12/14 12:08:37 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120837_0083_m_000000_0' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/data/_temporary/0/task_20171214120837_0083_m_000000
17/12/14 12:08:37 INFO SparkHadoopMapRedUtil: attempt_20171214120837_0083_m_000000_0: Committed
17/12/14 12:08:37 INFO Executor: Finished task 0.0 in stage 83.0 (TID 76). 2022 bytes result sent to driver
17/12/14 12:08:37 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 76) in 352 ms on localhost (executor driver) (1/1)
17/12/14 12:08:37 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
17/12/14 12:08:37 INFO DAGScheduler: ResultStage 83 (parquet at RFormula.scala:325) finished in 0.353 s
17/12/14 12:08:37 INFO DAGScheduler: Job 59 finished: parquet at RFormula.scala:325, took 0.367719 s
17/12/14 12:08:37 INFO FileFormatWriter: Job null committed.
17/12/14 12:08:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:37 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:08:37 INFO DAGScheduler: Got job 60 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:08:37 INFO DAGScheduler: Final stage: ResultStage 84 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:37 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:37 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:37 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[139] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:08:37 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 72.1 KB, free 365.8 MB)
17/12/14 12:08:37 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.8 MB)
17/12/14 12:08:37 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:54906 (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:08:37 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[139] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:37 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
17/12/14 12:08:37 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 6265 bytes)
17/12/14 12:08:37 INFO Executor: Running task 0.0 in stage 84.0 (TID 77)
17/12/14 12:08:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120837_0084_m_000000_77' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/metadata/_temporary/0/task_20171214120837_0084_m_000000
17/12/14 12:08:38 INFO SparkHadoopMapRedUtil: attempt_20171214120837_0084_m_000000_77: Committed
17/12/14 12:08:38 INFO Executor: Finished task 0.0 in stage 84.0 (TID 77). 916 bytes result sent to driver
17/12/14 12:08:38 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 77) in 122 ms on localhost (executor driver) (1/1)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
17/12/14 12:08:38 INFO DAGScheduler: ResultStage 84 (saveAsTextFile at ReadWrite.scala:275) finished in 0.122 s
17/12/14 12:08:38 INFO DAGScheduler: Job 60 finished: saveAsTextFile at ReadWrite.scala:275, took 0.133409 s
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:08:38 INFO DAGScheduler: Got job 61 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:08:38 INFO DAGScheduler: Final stage: ResultStage 85 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:38 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:38 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:38 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[141] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:08:38 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 72.1 KB, free 365.7 MB)
17/12/14 12:08:38 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.7 MB)
17/12/14 12:08:38 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:54906 (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:08:38 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[141] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
17/12/14 12:08:38 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 6223 bytes)
17/12/14 12:08:38 INFO Executor: Running task 0.0 in stage 85.0 (TID 78)
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120838_0085_m_000000_78' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/0_r_formula_1794180aa2a/metadata/_temporary/0/task_20171214120838_0085_m_000000
17/12/14 12:08:38 INFO SparkHadoopMapRedUtil: attempt_20171214120838_0085_m_000000_78: Committed
17/12/14 12:08:38 INFO Executor: Finished task 0.0 in stage 85.0 (TID 78). 1003 bytes result sent to driver
17/12/14 12:08:38 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 78) in 96 ms on localhost (executor driver) (1/1)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
17/12/14 12:08:38 INFO DAGScheduler: ResultStage 85 (saveAsTextFile at ReadWrite.scala:275) finished in 0.096 s
17/12/14 12:08:38 INFO DAGScheduler: Job 61 finished: saveAsTextFile at ReadWrite.scala:275, took 0.122640 s
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:08:38 INFO DAGScheduler: Got job 62 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:08:38 INFO DAGScheduler: Final stage: ResultStage 86 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:38 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:38 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:38 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[143] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:08:38 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 72.1 KB, free 365.6 MB)
17/12/14 12:08:38 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.6 MB)
17/12/14 12:08:38 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:54906 (size: 25.9 KB, free: 366.2 MB)
17/12/14 12:08:38 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[143] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
17/12/14 12:08:38 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 6194 bytes)
17/12/14 12:08:38 INFO Executor: Running task 0.0 in stage 86.0 (TID 79)
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120838_0086_m_000000_79' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/metadata/_temporary/0/task_20171214120838_0086_m_000000
17/12/14 12:08:38 INFO SparkHadoopMapRedUtil: attempt_20171214120838_0086_m_000000_79: Committed
17/12/14 12:08:38 INFO Executor: Finished task 0.0 in stage 86.0 (TID 79). 916 bytes result sent to driver
17/12/14 12:08:38 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 79) in 126 ms on localhost (executor driver) (1/1)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
17/12/14 12:08:38 INFO DAGScheduler: ResultStage 86 (saveAsTextFile at ReadWrite.scala:275) finished in 0.126 s
17/12/14 12:08:38 INFO DAGScheduler: Job 62 finished: saveAsTextFile at ReadWrite.scala:275, took 0.129940 s
17/12/14 12:08:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:38 INFO CodeGenerator: Code generated in 8.816959 ms
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:38 INFO SparkContext: Starting job: parquet at RFormula.scala:490
17/12/14 12:08:38 INFO DAGScheduler: Registering RDD 146 (parquet at RFormula.scala:490)
17/12/14 12:08:38 INFO DAGScheduler: Got job 63 (parquet at RFormula.scala:490) with 1 output partitions
17/12/14 12:08:38 INFO DAGScheduler: Final stage: ResultStage 88 (parquet at RFormula.scala:490)
17/12/14 12:08:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
17/12/14 12:08:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 87)
17/12/14 12:08:38 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[146] at parquet at RFormula.scala:490), which has no missing parents
17/12/14 12:08:38 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 4.8 KB, free 365.6 MB)
17/12/14 12:08:38 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 2.9 KB, free 365.6 MB)
17/12/14 12:08:38 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:54906 (size: 2.9 KB, free: 366.2 MB)
17/12/14 12:08:38 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[146] at parquet at RFormula.scala:490)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
17/12/14 12:08:38 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 6261 bytes)
17/12/14 12:08:38 INFO Executor: Running task 0.0 in stage 87.0 (TID 80)
17/12/14 12:08:38 INFO Executor: Finished task 0.0 in stage 87.0 (TID 80). 1377 bytes result sent to driver
17/12/14 12:08:38 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 80) in 20 ms on localhost (executor driver) (1/1)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
17/12/14 12:08:38 INFO DAGScheduler: ShuffleMapStage 87 (parquet at RFormula.scala:490) finished in 0.020 s
17/12/14 12:08:38 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:38 INFO DAGScheduler: running: Set()
17/12/14 12:08:38 INFO DAGScheduler: waiting: Set(ResultStage 88)
17/12/14 12:08:38 INFO DAGScheduler: failed: Set()
17/12/14 12:08:38 INFO DAGScheduler: Submitting ResultStage 88 (ShuffledRowRDD[147] at parquet at RFormula.scala:490), which has no missing parents
17/12/14 12:08:38 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 77.2 KB, free 365.5 MB)
17/12/14 12:08:38 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 28.7 KB, free 365.5 MB)
17/12/14 12:08:38 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:54906 (size: 28.7 KB, free: 366.1 MB)
17/12/14 12:08:38 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (ShuffledRowRDD[147] at parquet at RFormula.scala:490)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
17/12/14 12:08:38 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 81, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/14 12:08:38 INFO Executor: Running task 0.0 in stage 88.0 (TID 81)
17/12/14 12:08:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
17/12/14 12:08:38 INFO CodecPool: Got brand-new compressor [.snappy]
17/12/14 12:08:38 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120838_0088_m_000000_0' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/data/_temporary/0/task_20171214120838_0088_m_000000
17/12/14 12:08:38 INFO SparkHadoopMapRedUtil: attempt_20171214120838_0088_m_000000_0: Committed
17/12/14 12:08:38 INFO Executor: Finished task 0.0 in stage 88.0 (TID 81). 1856 bytes result sent to driver
17/12/14 12:08:38 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 81) in 115 ms on localhost (executor driver) (1/1)
17/12/14 12:08:38 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
17/12/14 12:08:38 INFO DAGScheduler: ResultStage 88 (parquet at RFormula.scala:490) finished in 0.115 s
17/12/14 12:08:38 INFO DAGScheduler: Job 63 finished: parquet at RFormula.scala:490, took 0.141423 s
17/12/14 12:08:38 INFO FileFormatWriter: Job null committed.
17/12/14 12:08:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:08:39 INFO DAGScheduler: Got job 64 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:08:39 INFO DAGScheduler: Final stage: ResultStage 89 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:39 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:39 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:39 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[150] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 72.1 KB, free 365.4 MB)
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.4 MB)
17/12/14 12:08:39 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:54906 (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:08:39 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[150] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
17/12/14 12:08:39 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 6177 bytes)
17/12/14 12:08:39 INFO Executor: Running task 0.0 in stage 89.0 (TID 82)
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120838_0089_m_000000_82' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/metadata/_temporary/0/task_20171214120838_0089_m_000000
17/12/14 12:08:39 INFO SparkHadoopMapRedUtil: attempt_20171214120838_0089_m_000000_82: Committed
17/12/14 12:08:39 INFO Executor: Finished task 0.0 in stage 89.0 (TID 82). 837 bytes result sent to driver
17/12/14 12:08:39 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 82) in 134 ms on localhost (executor driver) (1/1)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
17/12/14 12:08:39 INFO DAGScheduler: ResultStage 89 (saveAsTextFile at ReadWrite.scala:275) finished in 0.134 s
17/12/14 12:08:39 INFO DAGScheduler: Job 64 finished: saveAsTextFile at ReadWrite.scala:275, took 0.144634 s
17/12/14 12:08:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO CodeGenerator: Code generated in 7.27041 ms
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO SparkContext: Starting job: parquet at RFormula.scala:399
17/12/14 12:08:39 INFO DAGScheduler: Registering RDD 153 (parquet at RFormula.scala:399)
17/12/14 12:08:39 INFO DAGScheduler: Got job 65 (parquet at RFormula.scala:399) with 1 output partitions
17/12/14 12:08:39 INFO DAGScheduler: Final stage: ResultStage 91 (parquet at RFormula.scala:399)
17/12/14 12:08:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
17/12/14 12:08:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
17/12/14 12:08:39 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[153] at parquet at RFormula.scala:399), which has no missing parents
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 4.8 KB, free 365.4 MB)
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 2.9 KB, free 365.4 MB)
17/12/14 12:08:39 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:54906 (size: 2.9 KB, free: 366.1 MB)
17/12/14 12:08:39 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[153] at parquet at RFormula.scala:399)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
17/12/14 12:08:39 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 6229 bytes)
17/12/14 12:08:39 INFO Executor: Running task 0.0 in stage 90.0 (TID 83)
17/12/14 12:08:39 INFO Executor: Finished task 0.0 in stage 90.0 (TID 83). 1219 bytes result sent to driver
17/12/14 12:08:39 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 83) in 31 ms on localhost (executor driver) (1/1)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
17/12/14 12:08:39 INFO DAGScheduler: ShuffleMapStage 90 (parquet at RFormula.scala:399) finished in 0.031 s
17/12/14 12:08:39 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:39 INFO DAGScheduler: running: Set()
17/12/14 12:08:39 INFO DAGScheduler: waiting: Set(ResultStage 91)
17/12/14 12:08:39 INFO DAGScheduler: failed: Set()
17/12/14 12:08:39 INFO DAGScheduler: Submitting ResultStage 91 (ShuffledRowRDD[154] at parquet at RFormula.scala:399), which has no missing parents
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 77.0 KB, free 365.3 MB)
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 28.6 KB, free 365.3 MB)
17/12/14 12:08:39 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:54906 (size: 28.6 KB, free: 366.1 MB)
17/12/14 12:08:39 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (ShuffledRowRDD[154] at parquet at RFormula.scala:399)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
17/12/14 12:08:39 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 84, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/14 12:08:39 INFO Executor: Running task 0.0 in stage 91.0 (TID 84)
17/12/14 12:08:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
17/12/14 12:08:39 INFO CodecPool: Got brand-new compressor [.snappy]
17/12/14 12:08:39 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120839_0091_m_000000_0' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/data/_temporary/0/task_20171214120839_0091_m_000000
17/12/14 12:08:39 INFO SparkHadoopMapRedUtil: attempt_20171214120839_0091_m_000000_0: Committed
17/12/14 12:08:39 INFO Executor: Finished task 0.0 in stage 91.0 (TID 84). 1935 bytes result sent to driver
17/12/14 12:08:39 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 84) in 124 ms on localhost (executor driver) (1/1)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
17/12/14 12:08:39 INFO DAGScheduler: ResultStage 91 (parquet at RFormula.scala:399) finished in 0.124 s
17/12/14 12:08:39 INFO DAGScheduler: Job 65 finished: parquet at RFormula.scala:399, took 0.158116 s
17/12/14 12:08:39 INFO FileFormatWriter: Job null committed.
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/12/14 12:08:39 INFO DAGScheduler: Got job 66 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/12/14 12:08:39 INFO DAGScheduler: Final stage: ResultStage 92 (saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:39 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:39 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:39 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[157] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 72.1 KB, free 365.2 MB)
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 25.9 KB, free 365.2 MB)
17/12/14 12:08:39 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:54906 (size: 25.9 KB, free: 366.1 MB)
17/12/14 12:08:39 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[157] at saveAsTextFile at ReadWrite.scala:275)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
17/12/14 12:08:39 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
17/12/14 12:08:39 INFO Executor: Running task 0.0 in stage 92.0 (TID 85)
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120839_0092_m_000000_85' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/metadata/_temporary/0/task_20171214120839_0092_m_000000
17/12/14 12:08:39 INFO SparkHadoopMapRedUtil: attempt_20171214120839_0092_m_000000_85: Committed
17/12/14 12:08:39 INFO Executor: Finished task 0.0 in stage 92.0 (TID 85). 837 bytes result sent to driver
17/12/14 12:08:39 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 85) in 106 ms on localhost (executor driver) (1/1)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
17/12/14 12:08:39 INFO DAGScheduler: ResultStage 92 (saveAsTextFile at ReadWrite.scala:275) finished in 0.106 s
17/12/14 12:08:39 INFO DAGScheduler: Job 66 finished: saveAsTextFile at ReadWrite.scala:275, took 0.127923 s
17/12/14 12:08:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO CodeGenerator: Code generated in 12.729282 ms
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO SparkContext: Starting job: parquet at LogisticRegression.scala:965
17/12/14 12:08:39 INFO DAGScheduler: Registering RDD 160 (parquet at LogisticRegression.scala:965)
17/12/14 12:08:39 INFO DAGScheduler: Got job 67 (parquet at LogisticRegression.scala:965) with 1 output partitions
17/12/14 12:08:39 INFO DAGScheduler: Final stage: ResultStage 94 (parquet at LogisticRegression.scala:965)
17/12/14 12:08:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)
17/12/14 12:08:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 93)
17/12/14 12:08:39 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[160] at parquet at LogisticRegression.scala:965), which has no missing parents
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 5.1 KB, free 365.2 MB)
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 3.0 KB, free 365.2 MB)
17/12/14 12:08:39 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:54906 (size: 3.0 KB, free: 366.1 MB)
17/12/14 12:08:39 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[160] at parquet at LogisticRegression.scala:965)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
17/12/14 12:08:39 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 6413 bytes)
17/12/14 12:08:39 INFO Executor: Running task 0.0 in stage 93.0 (TID 86)
17/12/14 12:08:39 INFO Executor: Finished task 0.0 in stage 93.0 (TID 86). 1298 bytes result sent to driver
17/12/14 12:08:39 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 86) in 10 ms on localhost (executor driver) (1/1)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
17/12/14 12:08:39 INFO DAGScheduler: ShuffleMapStage 93 (parquet at LogisticRegression.scala:965) finished in 0.010 s
17/12/14 12:08:39 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:39 INFO DAGScheduler: running: Set()
17/12/14 12:08:39 INFO DAGScheduler: waiting: Set(ResultStage 94)
17/12/14 12:08:39 INFO DAGScheduler: failed: Set()
17/12/14 12:08:39 INFO DAGScheduler: Submitting ResultStage 94 (ShuffledRowRDD[161] at parquet at LogisticRegression.scala:965), which has no missing parents
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 78.7 KB, free 365.1 MB)
17/12/14 12:08:39 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 29.1 KB, free 365.1 MB)
17/12/14 12:08:39 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:54906 (size: 29.1 KB, free: 366.0 MB)
17/12/14 12:08:39 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (ShuffledRowRDD[161] at parquet at LogisticRegression.scala:965)
17/12/14 12:08:39 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
17/12/14 12:08:39 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 87, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/14 12:08:39 INFO Executor: Running task 0.0 in stage 94.0 (TID 87)
17/12/14 12:08:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/14 12:08:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/12/14 12:08:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "numClasses",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "numFeatures",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "interceptVector",
    "type" : {
      "type" : "udt",
      "class" : "org.apache.spark.ml.linalg.VectorUDT",
      "pyClass" : "pyspark.ml.linalg.VectorUDT",
      "sqlType" : {
        "type" : "struct",
        "fields" : [ {
          "name" : "type",
          "type" : "byte",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "size",
          "type" : "integer",
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "indices",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "values",
          "type" : {
            "type" : "array",
            "elementType" : "double",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        } ]
      }
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "coefficientMatrix",
    "type" : {
      "type" : "udt",
      "class" : "org.apache.spark.ml.linalg.MatrixUDT",
      "pyClass" : "pyspark.ml.linalg.MatrixUDT",
      "sqlType" : {
        "type" : "struct",
        "fields" : [ {
          "name" : "type",
          "type" : "byte",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "numRows",
          "type" : "integer",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "numCols",
          "type" : "integer",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "colPtrs",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "rowIndices",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "values",
          "type" : {
            "type" : "array",
            "elementType" : "double",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "isTransposed",
          "type" : "boolean",
          "nullable" : false,
          "metadata" : { }
        } ]
      }
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isMultinomial",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

       
17/12/14 12:08:40 INFO CodecPool: Got brand-new compressor [.snappy]
17/12/14 12:08:40 INFO FileOutputCommitter: Saved output of task 'attempt_20171214120839_0094_m_000000_0' to file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/data/_temporary/0/task_20171214120839_0094_m_000000
17/12/14 12:08:40 INFO SparkHadoopMapRedUtil: attempt_20171214120839_0094_m_000000_0: Committed
17/12/14 12:08:40 INFO Executor: Finished task 0.0 in stage 94.0 (TID 87). 1758 bytes result sent to driver
17/12/14 12:08:40 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 87) in 153 ms on localhost (executor driver) (1/1)
17/12/14 12:08:40 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
17/12/14 12:08:40 INFO DAGScheduler: ResultStage 94 (parquet at LogisticRegression.scala:965) finished in 0.153 s
17/12/14 12:08:40 INFO DAGScheduler: Job 67 finished: parquet at LogisticRegression.scala:965, took 0.174197 s
17/12/14 12:08:40 INFO FileFormatWriter: Job null committed.
17/12/14 12:08:40 INFO SparkContext: Invoking stop() from shutdown hook
17/12/14 12:08:40 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/14 12:08:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/14 12:08:40 INFO MemoryStore: MemoryStore cleared
17/12/14 12:08:40 INFO BlockManager: BlockManager stopped
17/12/14 12:08:40 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/14 12:08:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/14 12:08:40 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10\userFiles-c685d52a-35eb-461c-9266-8b8bbafd3251
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10\userFiles-c685d52a-35eb-461c-9266-8b8bbafd3251
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:08:40 INFO SparkContext: Successfully stopped SparkContext
17/12/14 12:08:40 INFO ShutdownHookManager: Shutdown hook called
17/12/14 12:08:40 INFO ShutdownHookManager: Deleting directory C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10\userFiles-c685d52a-35eb-461c-9266-8b8bbafd3251
17/12/14 12:08:40 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10\userFiles-c685d52a-35eb-461c-9266-8b8bbafd3251
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10\userFiles-c685d52a-35eb-461c-9266-8b8bbafd3251
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:08:40 INFO ShutdownHookManager: Deleting directory C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10
17/12/14 12:08:40 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-ae5efe7a-97a3-4247-a7af-56f1fea62e10
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:08:44 INFO SparkContext: Running Spark version 2.1.0
17/12/14 12:08:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/14 12:08:44 INFO SecurityManager: Changing view acls to: edgar
17/12/14 12:08:44 INFO SecurityManager: Changing modify acls to: edgar
17/12/14 12:08:44 INFO SecurityManager: Changing view acls groups to: 
17/12/14 12:08:44 INFO SecurityManager: Changing modify acls groups to: 
17/12/14 12:08:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(edgar); groups with view permissions: Set(); users  with modify permissions: Set(edgar); groups with modify permissions: Set()
17/12/14 12:08:44 INFO Utils: Successfully started service 'sparkDriver' on port 54968.
17/12/14 12:08:44 INFO SparkEnv: Registering MapOutputTracker
17/12/14 12:08:44 INFO SparkEnv: Registering BlockManagerMaster
17/12/14 12:08:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/14 12:08:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/14 12:08:44 INFO DiskBlockManager: Created local directory at C:\Users\edgar\AppData\Local\Temp\blockmgr-22347d60-0f25-4bf2-a207-7122ffdd3aae
17/12/14 12:08:44 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/12/14 12:08:44 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/14 12:08:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/14 12:08:44 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/14 12:08:45 INFO SparkContext: Added JAR file:/C:/Users/edgar/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:54968/jars/sparklyr-2.1-2.11.jar with timestamp 1513274925010
17/12/14 12:08:45 INFO Executor: Starting executor ID driver on host localhost
17/12/14 12:08:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55009.
17/12/14 12:08:45 INFO NettyBlockTransferService: Server created on 127.0.0.1:55009
17/12/14 12:08:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/14 12:08:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 55009, None)
17/12/14 12:08:45 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:55009 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 55009, None)
17/12/14 12:08:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 55009, None)
17/12/14 12:08:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 55009, None)
17/12/14 12:08:45 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/14 12:08:45 INFO SharedState: Warehouse path is 'C:UsersedgarAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/14 12:08:45 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/14 12:08:46 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/14 12:08:46 INFO ObjectStore: ObjectStore, initialize called
17/12/14 12:08:46 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/14 12:08:46 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/14 12:08:47 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/14 12:08:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:48 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/14 12:08:48 INFO ObjectStore: Initialized ObjectStore
17/12/14 12:08:48 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/14 12:08:48 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/14 12:08:49 INFO HiveMetaStore: Added admin role in metastore
17/12/14 12:08:49 INFO HiveMetaStore: Added public role in metastore
17/12/14 12:08:49 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/14 12:08:49 INFO HiveMetaStore: 0: get_all_databases
17/12/14 12:08:49 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/14 12:08:49 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/14 12:08:49 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/14 12:08:49 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/14 12:08:49 INFO SessionState: Created local directory: C:/Users/edgar/AppData/Local/Temp/b9e9640c-802f-46f7-be94-83af9b017afb_resources
17/12/14 12:08:49 INFO SessionState: Created HDFS directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/edgar/b9e9640c-802f-46f7-be94-83af9b017afb
17/12/14 12:08:49 INFO SessionState: Created local directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/b9e9640c-802f-46f7-be94-83af9b017afb
17/12/14 12:08:49 INFO SessionState: Created HDFS directory: C:/Users/edgar/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/edgar/b9e9640c-802f-46f7-be94-83af9b017afb/_tmp_space.db
17/12/14 12:08:49 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersedgarAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/14 12:08:49 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:08:49 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:08:49 INFO HiveMetaStore: 0: get_database: global_temp
17/12/14 12:08:49 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/14 12:08:49 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/14 12:08:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/14 12:08:51 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:08:51 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:08:51 INFO HiveMetaStore: 0: get_database: default
17/12/14 12:08:51 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_database: default	
17/12/14 12:08:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/14 12:08:51 INFO audit: ugi=edgar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/14 12:08:51 INFO CodeGenerator: Code generated in 201.990406 ms
17/12/14 12:08:51 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/14 12:08:51 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/14 12:08:51 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/14 12:08:51 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:51 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:51 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
17/12/14 12:08:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/12/14 12:08:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/12/14 12:08:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:55009 (size: 4.6 KB, free: 366.3 MB)
17/12/14 12:08:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
17/12/14 12:08:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/14 12:08:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/14 12:08:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/14 12:08:51 INFO Executor: Fetching spark://127.0.0.1:54968/jars/sparklyr-2.1-2.11.jar with timestamp 1513274925010
17/12/14 12:08:51 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54968 after 10 ms (0 ms spent in bootstraps)
17/12/14 12:08:51 INFO Utils: Fetching spark://127.0.0.1:54968/jars/sparklyr-2.1-2.11.jar to C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2\userFiles-87b296db-85e8-42c5-83d4-baf12945e2af\fetchFileTemp4835883222054947092.tmp
17/12/14 12:08:52 INFO Executor: Adding file:/C:/Users/edgar/AppData/Local/Temp/spark-10dfbf62-649f-41e8-9b20-258bce2035a2/userFiles-87b296db-85e8-42c5-83d4-baf12945e2af/sparklyr-2.1-2.11.jar to class loader
17/12/14 12:08:52 INFO CodeGenerator: Code generated in 10.449348 ms
17/12/14 12:08:52 INFO CodeGenerator: Code generated in 9.093144 ms
17/12/14 12:08:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/12/14 12:08:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 265 ms on localhost (executor driver) (1/1)
17/12/14 12:08:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/14 12:08:52 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.296 s
17/12/14 12:08:52 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.425221 s
17/12/14 12:08:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:52 INFO SparkSqlParser: Parsing command: mtcars
17/12/14 12:08:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:52 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
17/12/14 12:08:52 INFO SparkSqlParser: Parsing command: `mtcars`
17/12/14 12:08:52 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:08:52 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:08:52 INFO FileSourceStrategy: Output Data Schema: struct<mpg: double, cyl: double, disp: double, hp: double, drat: double ... 9 more fields>
17/12/14 12:08:52 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:08:52 INFO CodeGenerator: Code generated in 6.207653 ms
17/12/14 12:08:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/12/14 12:08:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/12/14 12:08:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:55009 (size: 23.9 KB, free: 366.3 MB)
17/12/14 12:08:52 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/14 12:08:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:08:52 INFO CodeGenerator: Code generated in 9.954826 ms
17/12/14 12:08:52 INFO CodeGenerator: Code generated in 7.904891 ms
17/12/14 12:08:52 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/14 12:08:52 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
17/12/14 12:08:52 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/14 12:08:52 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
17/12/14 12:08:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/12/14 12:08:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/12/14 12:08:52 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
17/12/14 12:08:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 23.2 KB, free 366.0 MB)
17/12/14 12:08:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/12/14 12:08:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:55009 (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:08:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0)
17/12/14 12:08:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/14 12:08:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/14 12:08:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/14 12:08:52 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/AppData/Local/Temp/RtmpQNqBnQ/spark_serialize_600df8759318fe0d3e7cd227dfb889264b9395236a2336b9c1d32f83ed509279.csv, range: 0-1336, partition values: [empty row]
17/12/14 12:08:52 INFO CodeGenerator: Code generated in 10.873424 ms
17/12/14 12:08:52 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 4.2 KB, free 365.9 MB)
17/12/14 12:08:52 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:55009 (size: 4.2 KB, free: 366.3 MB)
17/12/14 12:08:52 INFO CodeGenerator: Code generated in 5.943597 ms
17/12/14 12:08:52 INFO CodeGenerator: Code generated in 14.432118 ms
17/12/14 12:08:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2733 bytes result sent to driver
17/12/14 12:08:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 172 ms on localhost (executor driver) (1/1)
17/12/14 12:08:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/14 12:08:52 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.172 s
17/12/14 12:08:52 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:52 INFO DAGScheduler: running: Set()
17/12/14 12:08:52 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/12/14 12:08:52 INFO DAGScheduler: failed: Set()
17/12/14 12:08:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/14 12:08:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/12/14 12:08:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/12/14 12:08:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:55009 (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:08:52 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/14 12:08:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/12/14 12:08:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/14 12:08:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/14 12:08:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 32 ms
17/12/14 12:08:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:55009 in memory (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:08:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:55009 in memory (size: 4.6 KB, free: 366.3 MB)
17/12/14 12:08:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1938 bytes result sent to driver
17/12/14 12:08:52 INFO ContextCleaner: Cleaned accumulator 54
17/12/14 12:08:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 32 ms on localhost (executor driver) (1/1)
17/12/14 12:08:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/14 12:08:52 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.032 s
17/12/14 12:08:52 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.279640 s
17/12/14 12:08:53 INFO CodeGenerator: Code generated in 4.997474 ms
17/12/14 12:08:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:53 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
17/12/14 12:08:53 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:53 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:210)
17/12/14 12:08:53 INFO DAGScheduler: Got job 2 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:08:53 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:210)
17/12/14 12:08:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/12/14 12:08:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/12/14 12:08:53 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 23.2 KB, free 366.0 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:55009 (size: 11.0 KB, free: 366.3 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/14 12:08:53 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/12/14 12:08:53 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/12/14 12:08:53 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:08:53 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2109 bytes result sent to driver
17/12/14 12:08:53 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 26 ms on localhost (executor driver) (1/1)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/14 12:08:53 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:210) finished in 0.026 s
17/12/14 12:08:53 INFO DAGScheduler: looking for newly runnable stages
17/12/14 12:08:53 INFO DAGScheduler: running: Set()
17/12/14 12:08:53 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/12/14 12:08:53 INFO DAGScheduler: failed: Set()
17/12/14 12:08:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:55009 (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/12/14 12:08:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/14 12:08:53 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/12/14 12:08:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/14 12:08:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/14 12:08:53 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1873 bytes result sent to driver
17/12/14 12:08:53 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (executor driver) (1/1)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/12/14 12:08:53 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:210) finished in 0.005 s
17/12/14 12:08:53 INFO DAGScheduler: Job 2 finished: collect at utils.scala:210, took 0.035746 s
17/12/14 12:08:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz6`
WHERE (0 = 1)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 238.6 KB, free 365.7 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.7 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 6 from textFile at ReadWrite.scala:379
17/12/14 12:08:53 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:53 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:53 INFO DAGScheduler: Got job 3 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:53 INFO DAGScheduler: Final stage: ResultStage 5 (first at ReadWrite.scala:379)
17/12/14 12:08:53 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:53 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:53 INFO DAGScheduler: Submitting ResultStage 5 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/metadata MapPartitionsRDD[24] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.3 KB, free 365.7 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1992.0 B, free 365.7 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:55009 (size: 1992.0 B, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/metadata MapPartitionsRDD[24] at textFile at ReadWrite.scala:379)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/12/14 12:08:53 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6085 bytes)
17/12/14 12:08:53 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/14 12:08:53 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/metadata/part-00000:0+236
17/12/14 12:08:53 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/12/14 12:08:53 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/12/14 12:08:53 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/12/14 12:08:53 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/12/14 12:08:53 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/12/14 12:08:53 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1149 bytes result sent to driver
17/12/14 12:08:53 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (executor driver) (1/1)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/14 12:08:53 INFO DAGScheduler: ResultStage 5 (first at ReadWrite.scala:379) finished in 0.031 s
17/12/14 12:08:53 INFO DAGScheduler: Job 3 finished: first at ReadWrite.scala:379, took 0.027886 s
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 1
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 0
17/12/14 12:08:53 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:55009 in memory (size: 3.7 KB, free: 366.2 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:55009 in memory (size: 1992.0 B, free: 366.2 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:55009 in memory (size: 11.0 KB, free: 366.2 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.3 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:55009 in memory (size: 3.7 KB, free: 366.3 MB)
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 163
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 55
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 56
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 57
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 58
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 59
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 60
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 61
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 62
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 63
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 64
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 65
17/12/14 12:08:53 INFO ContextCleaner: Cleaned accumulator 66
17/12/14 12:08:53 INFO ContextCleaner: Cleaned shuffle 0
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 238.7 KB, free 365.8 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.7 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 8 from textFile at ReadWrite.scala:379
17/12/14 12:08:53 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:53 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:53 INFO DAGScheduler: Got job 4 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:53 INFO DAGScheduler: Final stage: ResultStage 6 (first at ReadWrite.scala:379)
17/12/14 12:08:53 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:53 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:53 INFO DAGScheduler: Submitting ResultStage 6 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/0_binarizer_179436bf21f6/metadata MapPartitionsRDD[26] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.3 KB, free 365.7 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 2025.0 B, free 365.7 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:55009 (size: 2025.0 B, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/0_binarizer_179436bf21f6/metadata MapPartitionsRDD[26] at textFile at ReadWrite.scala:379)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/14 12:08:53 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6117 bytes)
17/12/14 12:08:53 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
17/12/14 12:08:53 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/0_binarizer_179436bf21f6/metadata/part-00000:0+199
17/12/14 12:08:53 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 951 bytes result sent to driver
17/12/14 12:08:53 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/14 12:08:53 INFO DAGScheduler: ResultStage 6 (first at ReadWrite.scala:379) finished in 0.000 s
17/12/14 12:08:53 INFO DAGScheduler: Job 4 finished: first at ReadWrite.scala:379, took 0.012573 s
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 238.7 KB, free 365.5 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.5 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 10 from textFile at ReadWrite.scala:379
17/12/14 12:08:53 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:53 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:53 INFO DAGScheduler: Got job 5 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:53 INFO DAGScheduler: Final stage: ResultStage 7 (first at ReadWrite.scala:379)
17/12/14 12:08:53 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:53 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:53 INFO DAGScheduler: Submitting ResultStage 7 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/0_binarizer_179436bf21f6/metadata MapPartitionsRDD[28] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.3 KB, free 365.5 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2025.0 B, free 365.5 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:55009 (size: 2025.0 B, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/0_binarizer_179436bf21f6/metadata MapPartitionsRDD[28] at textFile at ReadWrite.scala:379)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/12/14 12:08:53 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6117 bytes)
17/12/14 12:08:53 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
17/12/14 12:08:53 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/0_binarizer_179436bf21f6/metadata/part-00000:0+199
17/12/14 12:08:53 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1109 bytes result sent to driver
17/12/14 12:08:53 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/12/14 12:08:53 INFO DAGScheduler: ResultStage 7 (first at ReadWrite.scala:379) finished in 0.016 s
17/12/14 12:08:53 INFO DAGScheduler: Job 5 finished: first at ReadWrite.scala:379, took 0.011064 s
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 238.7 KB, free 365.2 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.2 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 12 from textFile at ReadWrite.scala:379
17/12/14 12:08:53 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:53 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:53 INFO DAGScheduler: Got job 6 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:53 INFO DAGScheduler: Final stage: ResultStage 8 (first at ReadWrite.scala:379)
17/12/14 12:08:53 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:53 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:53 INFO DAGScheduler: Submitting ResultStage 8 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/metadata MapPartitionsRDD[30] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.3 KB, free 365.2 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2026.0 B, free 365.2 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:55009 (size: 2026.0 B, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/metadata MapPartitionsRDD[30] at textFile at ReadWrite.scala:379)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/14 12:08:53 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
17/12/14 12:08:53 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/14 12:08:53 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/metadata/part-00000:0+190
17/12/14 12:08:53 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1119 bytes result sent to driver
17/12/14 12:08:53 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:53 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/14 12:08:53 INFO DAGScheduler: ResultStage 8 (first at ReadWrite.scala:379) finished in 0.016 s
17/12/14 12:08:53 INFO DAGScheduler: Job 6 finished: first at ReadWrite.scala:379, took 0.010340 s
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 238.7 KB, free 365.0 MB)
17/12/14 12:08:53 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.9 MB)
17/12/14 12:08:53 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:53 INFO SparkContext: Created broadcast 14 from textFile at ReadWrite.scala:379
17/12/14 12:08:54 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:54 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:54 INFO DAGScheduler: Got job 7 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:54 INFO DAGScheduler: Final stage: ResultStage 9 (first at ReadWrite.scala:379)
17/12/14 12:08:54 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:54 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:54 INFO DAGScheduler: Submitting ResultStage 9 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/metadata MapPartitionsRDD[32] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.3 KB, free 364.9 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2025.0 B, free 364.9 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:55009 (size: 2025.0 B, free: 366.2 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/metadata MapPartitionsRDD[32] at textFile at ReadWrite.scala:379)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/12/14 12:08:54 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
17/12/14 12:08:54 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
17/12/14 12:08:54 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/metadata/part-00000:0+190
17/12/14 12:08:54 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 942 bytes result sent to driver
17/12/14 12:08:54 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/12/14 12:08:54 INFO DAGScheduler: ResultStage 9 (first at ReadWrite.scala:379) finished in 0.000 s
17/12/14 12:08:54 INFO DAGScheduler: Job 7 finished: first at ReadWrite.scala:379, took 0.009974 s
17/12/14 12:08:54 INFO SparkContext: Starting job: parquet at RFormula.scala:341
17/12/14 12:08:54 INFO DAGScheduler: Got job 8 (parquet at RFormula.scala:341) with 1 output partitions
17/12/14 12:08:54 INFO DAGScheduler: Final stage: ResultStage 10 (parquet at RFormula.scala:341)
17/12/14 12:08:54 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:54 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:54 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[34] at parquet at RFormula.scala:341), which has no missing parents
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.3 KB, free 364.9 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.4 KB, free 364.8 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:55009 (size: 25.4 KB, free: 366.1 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[34] at parquet at RFormula.scala:341)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/14 12:08:54 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6273 bytes)
17/12/14 12:08:54 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
17/12/14 12:08:54 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1824 bytes result sent to driver
17/12/14 12:08:54 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 101 ms on localhost (executor driver) (1/1)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/14 12:08:54 INFO DAGScheduler: ResultStage 10 (parquet at RFormula.scala:341) finished in 0.101 s
17/12/14 12:08:54 INFO DAGScheduler: Job 8 finished: parquet at RFormula.scala:341, took 0.103267 s
17/12/14 12:08:54 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:08:54 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:08:54 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
17/12/14 12:08:54 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:08:54 INFO CodeGenerator: Code generated in 11.030179 ms
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 284.0 KB, free 364.6 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 24.7 KB, free 364.5 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:55009 (size: 24.7 KB, free: 366.1 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 17 from head at RFormula.scala:341
17/12/14 12:08:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:08:54 INFO SparkContext: Starting job: head at RFormula.scala:341
17/12/14 12:08:54 INFO DAGScheduler: Got job 9 (head at RFormula.scala:341) with 1 output partitions
17/12/14 12:08:54 INFO DAGScheduler: Final stage: ResultStage 11 (head at RFormula.scala:341)
17/12/14 12:08:54 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:54 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:54 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[37] at head at RFormula.scala:341), which has no missing parents
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 9.8 KB, free 364.5 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.7 KB, free 364.5 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:55009 (size: 4.7 KB, free: 366.1 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[37] at head at RFormula.scala:341)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/12/14 12:08:54 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6616 bytes)
17/12/14 12:08:54 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/12/14 12:08:54 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/data/part-00000-3a6eeab3-6bac-4409-9ab3-de7e3b795ecf.snappy.parquet, range: 0-914, partition values: [empty row]
17/12/14 12:08:54 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
17/12/14 12:08:54 INFO CodeGenerator: Code generated in 9.21211 ms
17/12/14 12:08:54 INFO CodecPool: Got brand-new decompressor [.snappy]
17/12/14 12:08:54 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1331 bytes result sent to driver
17/12/14 12:08:54 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 199 ms on localhost (executor driver) (1/1)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/12/14 12:08:54 INFO DAGScheduler: ResultStage 11 (head at RFormula.scala:341) finished in 0.199 s
17/12/14 12:08:54 INFO DAGScheduler: Job 9 finished: head at RFormula.scala:341, took 0.217086 s
17/12/14 12:08:54 INFO CodeGenerator: Code generated in 17.660975 ms
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 238.7 KB, free 364.3 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.3 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 19 from textFile at ReadWrite.scala:379
17/12/14 12:08:54 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:54 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:54 INFO DAGScheduler: Got job 10 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:54 INFO DAGScheduler: Final stage: ResultStage 12 (first at ReadWrite.scala:379)
17/12/14 12:08:54 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:54 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:54 INFO DAGScheduler: Submitting ResultStage 12 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/metadata MapPartitionsRDD[39] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.3 KB, free 364.3 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 2031.0 B, free 364.3 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:55009 (size: 2031.0 B, free: 366.1 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/metadata MapPartitionsRDD[39] at textFile at ReadWrite.scala:379)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/14 12:08:54 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6130 bytes)
17/12/14 12:08:54 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/12/14 12:08:54 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/metadata/part-00000:0+238
17/12/14 12:08:54 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1249 bytes result sent to driver
17/12/14 12:08:54 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 20 ms on localhost (executor driver) (1/1)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/14 12:08:54 INFO DAGScheduler: ResultStage 12 (first at ReadWrite.scala:379) finished in 0.021 s
17/12/14 12:08:54 INFO DAGScheduler: Job 10 finished: first at ReadWrite.scala:379, took 0.011206 s
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 238.7 KB, free 364.0 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.0 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 21 from textFile at ReadWrite.scala:379
17/12/14 12:08:54 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:54 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:54 INFO DAGScheduler: Got job 11 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:54 INFO DAGScheduler: Final stage: ResultStage 13 (first at ReadWrite.scala:379)
17/12/14 12:08:54 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:54 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:54 INFO DAGScheduler: Submitting ResultStage 13 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/0_r_formula_1794180aa2a/metadata MapPartitionsRDD[41] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 3.4 KB, free 364.0 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 2036.0 B, free 364.0 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:55009 (size: 2036.0 B, free: 366.1 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/0_r_formula_1794180aa2a/metadata MapPartitionsRDD[41] at textFile at ReadWrite.scala:379)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/12/14 12:08:54 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6162 bytes)
17/12/14 12:08:54 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/12/14 12:08:54 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/0_r_formula_1794180aa2a/metadata/part-00000:0+196
17/12/14 12:08:54 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 948 bytes result sent to driver
17/12/14 12:08:54 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/12/14 12:08:54 INFO DAGScheduler: ResultStage 13 (first at ReadWrite.scala:379) finished in 0.000 s
17/12/14 12:08:54 INFO DAGScheduler: Job 11 finished: first at ReadWrite.scala:379, took 0.008850 s
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 238.7 KB, free 363.8 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.3 KB, free 363.8 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 23 from textFile at ReadWrite.scala:379
17/12/14 12:08:54 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:54 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:54 INFO DAGScheduler: Got job 12 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:54 INFO DAGScheduler: Final stage: ResultStage 14 (first at ReadWrite.scala:379)
17/12/14 12:08:54 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:54 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:54 INFO DAGScheduler: Submitting ResultStage 14 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/0_r_formula_1794180aa2a/metadata MapPartitionsRDD[43] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 3.4 KB, free 363.8 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 2036.0 B, free 363.7 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:55009 (size: 2036.0 B, free: 366.0 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/0_r_formula_1794180aa2a/metadata MapPartitionsRDD[43] at textFile at ReadWrite.scala:379)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/14 12:08:54 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6162 bytes)
17/12/14 12:08:54 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
17/12/14 12:08:54 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/0_r_formula_1794180aa2a/metadata/part-00000:0+196
17/12/14 12:08:54 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 948 bytes result sent to driver
17/12/14 12:08:54 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/14 12:08:54 INFO DAGScheduler: ResultStage 14 (first at ReadWrite.scala:379) finished in 0.016 s
17/12/14 12:08:54 INFO DAGScheduler: Job 12 finished: first at ReadWrite.scala:379, took 0.009729 s
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 238.7 KB, free 363.5 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 23.3 KB, free 363.5 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 25 from textFile at ReadWrite.scala:379
17/12/14 12:08:54 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:54 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:54 INFO DAGScheduler: Got job 13 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:54 INFO DAGScheduler: Final stage: ResultStage 15 (first at ReadWrite.scala:379)
17/12/14 12:08:54 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:54 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:54 INFO DAGScheduler: Submitting ResultStage 15 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/metadata MapPartitionsRDD[45] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 3.4 KB, free 363.5 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.0 KB, free 363.5 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:55009 (size: 2.0 KB, free: 366.0 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/metadata MapPartitionsRDD[45] at textFile at ReadWrite.scala:379)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/12/14 12:08:54 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6172 bytes)
17/12/14 12:08:54 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
17/12/14 12:08:54 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/metadata/part-00000:0+167
17/12/14 12:08:54 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1085 bytes result sent to driver
17/12/14 12:08:54 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 5 ms on localhost (executor driver) (1/1)
17/12/14 12:08:54 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/12/14 12:08:54 INFO DAGScheduler: ResultStage 15 (first at ReadWrite.scala:379) finished in 0.006 s
17/12/14 12:08:54 INFO DAGScheduler: Job 13 finished: first at ReadWrite.scala:379, took 0.009017 s
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 238.7 KB, free 363.3 MB)
17/12/14 12:08:54 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 23.3 KB, free 363.2 MB)
17/12/14 12:08:54 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:08:54 INFO SparkContext: Created broadcast 27 from textFile at ReadWrite.scala:379
17/12/14 12:08:55 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:55 INFO DAGScheduler: Got job 14 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 16 (first at ReadWrite.scala:379)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 16 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/metadata MapPartitionsRDD[47] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 3.4 KB, free 363.2 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.0 KB, free 363.2 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:55009 (size: 2.0 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/metadata MapPartitionsRDD[47] at textFile at ReadWrite.scala:379)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6173 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
17/12/14 12:08:55 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/metadata/part-00000:0+167
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 919 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 16 (first at ReadWrite.scala:379) finished in 0.000 s
17/12/14 12:08:55 INFO DAGScheduler: Job 14 finished: first at ReadWrite.scala:379, took 0.007457 s
17/12/14 12:08:55 INFO SparkContext: Starting job: parquet at RFormula.scala:503
17/12/14 12:08:55 INFO DAGScheduler: Got job 15 (parquet at RFormula.scala:503) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:503)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[49] at parquet at RFormula.scala:503), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 71.3 KB, free 363.2 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 25.4 KB, free 363.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:55009 (size: 25.4 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[49] at parquet at RFormula.scala:503)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6329 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:55009 in memory (size: 25.4 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:55009 in memory (size: 2036.0 B, free: 366.0 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:55009 in memory (size: 2.0 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:55009 in memory (size: 2.0 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:55009 in memory (size: 2025.0 B, free: 366.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:55009 in memory (size: 2025.0 B, free: 366.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:55009 in memory (size: 2026.0 B, free: 366.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1845 bytes result sent to driver
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:55009 in memory (size: 4.7 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 18 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:503) finished in 0.018 s
17/12/14 12:08:55 INFO DAGScheduler: Job 15 finished: parquet at RFormula.scala:503, took 0.042654 s
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:55009 in memory (size: 2031.0 B, free: 366.2 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:55009 in memory (size: 2036.0 B, free: 366.2 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO ContextCleaner: Cleaned accumulator 560
17/12/14 12:08:55 INFO ContextCleaner: Cleaned accumulator 561
17/12/14 12:08:55 INFO ContextCleaner: Cleaned accumulator 562
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:55009 in memory (size: 24.7 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:55009 in memory (size: 2025.0 B, free: 366.2 MB)
17/12/14 12:08:55 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:08:55 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:08:55 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
17/12/14 12:08:55 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 10.628963 ms
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 283.7 KB, free 365.6 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.6 KB, free 365.6 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:55009 (size: 24.6 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 30 from head at RFormula.scala:503
17/12/14 12:08:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:08:55 INFO SparkContext: Starting job: head at RFormula.scala:503
17/12/14 12:08:55 INFO DAGScheduler: Got job 16 (head at RFormula.scala:503) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 18 (head at RFormula.scala:503)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[52] at head at RFormula.scala:503), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.3 KB, free 365.6 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 4.8 KB, free 365.6 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:55009 (size: 4.8 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[52] at head at RFormula.scala:503)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 6671 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
17/12/14 12:08:55 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/1_vectorAttrRewriter_84a8c6062c4b/data/part-00000-c6d8cafe-5cea-48e1-af8d-406dab1f08fb.snappy.parquet, range: 0-812, partition values: [empty row]
17/12/14 12:08:55 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 8.245459 ms
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1280 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 18 (head at RFormula.scala:503) finished in 0.016 s
17/12/14 12:08:55 INFO DAGScheduler: Job 16 finished: head at RFormula.scala:503, took 0.023591 s
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 19.585413 ms
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 238.7 KB, free 365.3 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.3 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 32 from textFile at ReadWrite.scala:379
17/12/14 12:08:55 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:55 INFO DAGScheduler: Got job 17 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 19 (first at ReadWrite.scala:379)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 19 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/metadata MapPartitionsRDD[54] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 3.4 KB, free 365.3 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.0 KB, free 365.3 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:55009 (size: 2.0 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/metadata MapPartitionsRDD[54] at textFile at ReadWrite.scala:379)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6167 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
17/12/14 12:08:55 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/metadata/part-00000:0+150
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 902 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 19 (first at ReadWrite.scala:379) finished in 0.000 s
17/12/14 12:08:55 INFO DAGScheduler: Job 17 finished: first at ReadWrite.scala:379, took 0.008141 s
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 238.7 KB, free 365.1 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 23.3 KB, free 365.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 34 from textFile at ReadWrite.scala:379
17/12/14 12:08:55 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:55 INFO DAGScheduler: Got job 18 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 20 (first at ReadWrite.scala:379)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 20 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/metadata MapPartitionsRDD[56] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 3.4 KB, free 365.1 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.0 KB, free 365.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:55009 (size: 2.0 KB, free: 366.2 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/metadata MapPartitionsRDD[56] at textFile at ReadWrite.scala:379)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 6167 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
17/12/14 12:08:55 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/metadata/part-00000:0+150
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1060 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 20 (first at ReadWrite.scala:379) finished in 0.016 s
17/12/14 12:08:55 INFO DAGScheduler: Job 18 finished: first at ReadWrite.scala:379, took 0.009140 s
17/12/14 12:08:55 INFO SparkContext: Starting job: parquet at RFormula.scala:412
17/12/14 12:08:55 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:412) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 21 (parquet at RFormula.scala:412)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[58] at parquet at RFormula.scala:412), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 71.3 KB, free 365.0 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 25.4 KB, free 365.0 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:55009 (size: 25.4 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[58] at parquet at RFormula.scala:412)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6323 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1438 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 21 (parquet at RFormula.scala:412) finished in 0.000 s
17/12/14 12:08:55 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:412, took 0.018885 s
17/12/14 12:08:55 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:08:55 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:08:55 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
17/12/14 12:08:55 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 5.931001 ms
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 283.4 KB, free 364.7 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.5 KB, free 364.7 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:55009 (size: 24.5 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 37 from head at RFormula.scala:412
17/12/14 12:08:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:08:55 INFO SparkContext: Starting job: head at RFormula.scala:412
17/12/14 12:08:55 INFO DAGScheduler: Got job 20 (head at RFormula.scala:412) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 22 (head at RFormula.scala:412)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[61] at head at RFormula.scala:412), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 8.2 KB, free 364.7 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.3 KB, free 364.6 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:55009 (size: 4.3 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[61] at head at RFormula.scala:412)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6665 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
17/12/14 12:08:55 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/1_r_formula_1794180aa2a/pipelineModel/stages/2_columnPruner_cd0a068ab3b8/data/part-00000-7e2f4428-ae65-424f-9386-71faf496b2ef.snappy.parquet, range: 0-461, partition values: [empty row]
17/12/14 12:08:55 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 4.824391 ms
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1264 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 15 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 22 (head at RFormula.scala:412) finished in 0.015 s
17/12/14 12:08:55 INFO DAGScheduler: Job 20 finished: head at RFormula.scala:412, took 0.016129 s
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 7.790125 ms
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 238.7 KB, free 364.4 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.4 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 39 from textFile at ReadWrite.scala:379
17/12/14 12:08:55 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:55 INFO DAGScheduler: Got job 21 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 23 (first at ReadWrite.scala:379)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 23 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/metadata MapPartitionsRDD[63] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 3.3 KB, free 364.4 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 2034.0 B, free 364.4 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:55009 (size: 2034.0 B, free: 366.1 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/metadata MapPartitionsRDD[63] at textFile at ReadWrite.scala:379)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6128 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
17/12/14 12:08:55 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/metadata/part-00000:0+473
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1405 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 23 (first at ReadWrite.scala:379) finished in 0.016 s
17/12/14 12:08:55 INFO DAGScheduler: Job 21 finished: first at ReadWrite.scala:379, took 0.007194 s
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 238.7 KB, free 364.2 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 23.3 KB, free 364.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:55009 (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 41 from textFile at ReadWrite.scala:379
17/12/14 12:08:55 INFO FileInputFormat: Total input paths to process : 1
17/12/14 12:08:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
17/12/14 12:08:55 INFO DAGScheduler: Got job 22 (first at ReadWrite.scala:379) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 24 (first at ReadWrite.scala:379)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 24 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/metadata MapPartitionsRDD[65] at textFile at ReadWrite.scala:379), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 3.3 KB, free 364.1 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 2034.0 B, free 364.1 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:55009 (size: 2034.0 B, free: 366.1 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/metadata MapPartitionsRDD[65] at textFile at ReadWrite.scala:379)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6128 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
17/12/14 12:08:55 INFO HadoopRDD: Input split: file:/C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/metadata/part-00000:0+473
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1228 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 0 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 24 (first at ReadWrite.scala:379) finished in 0.000 s
17/12/14 12:08:55 INFO DAGScheduler: Job 22 finished: first at ReadWrite.scala:379, took 0.006920 s
17/12/14 12:08:55 INFO SparkContext: Starting job: load at LogisticRegression.scala:979
17/12/14 12:08:55 INFO DAGScheduler: Got job 23 (load at LogisticRegression.scala:979) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 25 (load at LogisticRegression.scala:979)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[67] at load at LogisticRegression.scala:979), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 71.3 KB, free 364.1 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 25.4 KB, free 364.0 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:55009 (size: 25.4 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[67] at load at LogisticRegression.scala:979)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6285 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
17/12/14 12:08:55 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1914 bytes result sent to driver
17/12/14 12:08:55 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 16 ms on localhost (executor driver) (1/1)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/12/14 12:08:55 INFO DAGScheduler: ResultStage 25 (load at LogisticRegression.scala:979) finished in 0.016 s
17/12/14 12:08:55 INFO DAGScheduler: Job 23 finished: load at LogisticRegression.scala:979, took 0.026381 s
17/12/14 12:08:55 INFO FileSourceStrategy: Pruning directories with: 
17/12/14 12:08:55 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/14 12:08:55 INFO FileSourceStrategy: Output Data Schema: struct<numClasses: int, numFeatures: int, interceptVector: vector, coefficientMatrix: matrix, isMultinomial: boolean ... 3 more fields>
17/12/14 12:08:55 INFO FileSourceStrategy: Pushed Filters: 
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 14.34861 ms
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 289.1 KB, free 363.7 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 25.4 KB, free 363.7 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:55009 (size: 25.4 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 44 from head at LogisticRegression.scala:997
17/12/14 12:08:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/14 12:08:55 INFO SparkContext: Starting job: head at LogisticRegression.scala:997
17/12/14 12:08:55 INFO DAGScheduler: Got job 24 (head at LogisticRegression.scala:997) with 1 output partitions
17/12/14 12:08:55 INFO DAGScheduler: Final stage: ResultStage 26 (head at LogisticRegression.scala:997)
17/12/14 12:08:55 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:55 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:55 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[70] at head at LogisticRegression.scala:997), which has no missing parents
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 17.3 KB, free 363.7 MB)
17/12/14 12:08:55 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 6.2 KB, free 363.7 MB)
17/12/14 12:08:55 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:55009 (size: 6.2 KB, free: 366.0 MB)
17/12/14 12:08:55 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[70] at head at LogisticRegression.scala:997)
17/12/14 12:08:55 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/12/14 12:08:55 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 6627 bytes)
17/12/14 12:08:55 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
17/12/14 12:08:55 INFO FileScanRDD: Reading File path: file:///C:/Users/edgar/Documents/sparklyr_pipeline/new_model/stages/2_logistic_regression_1794617a7030/data/part-00000-ba1a5a55-c35b-4c6a-8492-9380e91e60dd.snappy.parquet, range: 0-3705, partition values: [empty row]
17/12/14 12:08:55 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

Catalyst form:
StructType(StructField(numClasses,IntegerType,true), StructField(numFeatures,IntegerType,true), StructField(interceptVector,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(coefficientMatrix,org.apache.spark.ml.linalg.MatrixUDT@e59e0c69,true), StructField(isMultinomial,BooleanType,true))
       
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 18.335112 ms
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 8.067244 ms
17/12/14 12:08:55 INFO CodeGenerator: Code generated in 8.96858 ms
17/12/14 12:08:56 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1349 bytes result sent to driver
17/12/14 12:08:56 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 59 ms on localhost (executor driver) (1/1)
17/12/14 12:08:56 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/12/14 12:08:56 INFO DAGScheduler: ResultStage 26 (head at LogisticRegression.scala:997) finished in 0.059 s
17/12/14 12:08:56 INFO DAGScheduler: Job 24 finished: head at LogisticRegression.scala:997, took 0.062337 s
17/12/14 12:08:56 INFO CodeGenerator: Code generated in 5.876884 ms
17/12/14 12:08:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars`
17/12/14 12:08:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_179416fd7fc9
17/12/14 12:08:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_179416fd7fc9` AS `zzz7`
WHERE (0 = 1)
17/12/14 12:08:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/14 12:08:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_179416fd7fc9`
LIMIT 25
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:55009 in memory (size: 25.4 KB, free: 366.0 MB)
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 899
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 900
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 901
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:55009 in memory (size: 24.6 KB, free: 366.1 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:55009 in memory (size: 4.8 KB, free: 366.1 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:55009 in memory (size: 2.0 KB, free: 366.1 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.1 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:55009 in memory (size: 2.0 KB, free: 366.1 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:55009 in memory (size: 25.4 KB, free: 366.1 MB)
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 1094
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 1095
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 1096
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:55009 in memory (size: 24.5 KB, free: 366.2 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:55009 in memory (size: 4.3 KB, free: 366.2 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:55009 in memory (size: 2034.0 B, free: 366.2 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:55009 in memory (size: 23.3 KB, free: 366.2 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:55009 in memory (size: 2034.0 B, free: 366.2 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:55009 in memory (size: 25.4 KB, free: 366.2 MB)
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 1289
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 1290
17/12/14 12:08:56 INFO ContextCleaner: Cleaned accumulator 1291
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:55009 in memory (size: 25.4 KB, free: 366.3 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:55009 in memory (size: 6.2 KB, free: 366.3 MB)
17/12/14 12:08:56 INFO CodeGenerator: Code generated in 32.675323 ms
17/12/14 12:08:56 INFO SparkContext: Starting job: collect at utils.scala:210
17/12/14 12:08:56 INFO DAGScheduler: Got job 25 (collect at utils.scala:210) with 1 output partitions
17/12/14 12:08:56 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:210)
17/12/14 12:08:56 INFO DAGScheduler: Parents of final stage: List()
17/12/14 12:08:56 INFO DAGScheduler: Missing parents: List()
17/12/14 12:08:56 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[74] at collect at utils.scala:210), which has no missing parents
17/12/14 12:08:56 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 64.7 KB, free 365.9 MB)
17/12/14 12:08:56 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 22.1 KB, free 365.9 MB)
17/12/14 12:08:56 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:55009 (size: 22.1 KB, free: 366.3 MB)
17/12/14 12:08:56 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
17/12/14 12:08:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[74] at collect at utils.scala:210)
17/12/14 12:08:56 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/12/14 12:08:56 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6594 bytes)
17/12/14 12:08:56 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
17/12/14 12:08:56 INFO BlockManager: Found block rdd_9_0 locally
17/12/14 12:08:56 INFO CodeGenerator: Code generated in 12.86271 ms
17/12/14 12:08:56 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/12/14 12:08:56 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
17/12/14 12:08:56 WARN Executor: 1 block locks were not released by TID = 27:
[rdd_9_0]
17/12/14 12:08:56 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 3583 bytes result sent to driver
17/12/14 12:08:56 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 67 ms on localhost (executor driver) (1/1)
17/12/14 12:08:56 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/12/14 12:08:56 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:210) finished in 0.067 s
17/12/14 12:08:56 INFO DAGScheduler: Job 25 finished: collect at utils.scala:210, took 0.064845 s
17/12/14 12:08:56 INFO CodeGenerator: Code generated in 13.337172 ms
17/12/14 12:08:56 INFO SparkContext: Invoking stop() from shutdown hook
17/12/14 12:08:56 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/14 12:08:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/14 12:08:56 INFO MemoryStore: MemoryStore cleared
17/12/14 12:08:56 INFO BlockManager: BlockManager stopped
17/12/14 12:08:56 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/14 12:08:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/14 12:08:56 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2\userFiles-87b296db-85e8-42c5-83d4-baf12945e2af
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2\userFiles-87b296db-85e8-42c5-83d4-baf12945e2af
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:08:56 INFO SparkContext: Successfully stopped SparkContext
17/12/14 12:08:56 INFO ShutdownHookManager: Shutdown hook called
17/12/14 12:08:56 INFO ShutdownHookManager: Deleting directory C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2\userFiles-87b296db-85e8-42c5-83d4-baf12945e2af
17/12/14 12:08:56 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2\userFiles-87b296db-85e8-42c5-83d4-baf12945e2af
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2\userFiles-87b296db-85e8-42c5-83d4-baf12945e2af
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/14 12:08:56 INFO ShutdownHookManager: Deleting directory C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2
17/12/14 12:08:56 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2
java.io.IOException: Failed to delete: C:\Users\edgar\AppData\Local\Temp\spark-10dfbf62-649f-41e8-9b20-258bce2035a2
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
